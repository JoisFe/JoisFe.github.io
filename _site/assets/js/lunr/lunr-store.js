var store = [{
        "title": "수치 예측",
        "excerpt":"가장 먼저 딥러닝의 기초가 되는 머신러닝 알고리즘 중 가장 간단한 선형회귀를 만들어 볼 것이다.    직선의 그래프 y = ax + b  a : 기울기, b : 절편   선형 회귀(Linear Regression) :    위 선형 방정식의 기울기 a와 절편 b를 찾아내는 방법 즉 선형 방정식(선형 함수)를 예측하는 것  -&gt; 입력 데이터 x와 타깃 데이터 y를 통해 기울기 a와 절편 b를 찾는 것      경사 하강법(Gradient descent) :    위 선형회귀의 목표인 입력 데이터와 타깃 데이터가 주어질 때 그 관계를 잘 표현하는 직선의 방정식(선형 방정식)을 찾아내는 방법   -&gt; 기울기 a, 절편 b를 찾으면 직선의 방정식을 찾을 수 있겠지…  설명이 조금 애매함… 차후 좀더 구체적으로 설명할 것임    경사 하강법은 구체적으로 모델이 데이터를 잘 표현할 수 있도록 기울기(변화율)을 이용하여 모델을 조절하는 방식   -&gt; 즉 기울기를 이용한다는 점!!!! 무슨말인지 이해가 안되면 아래 예제 코드를 이용해 알아보면 된다.      선형 회귀를 푸는 알고리즘은 매우 많은 그 중의 하나가 경사 하강법임!!   from sklearn.datasets import load_diabetes #사이킷런에서 당뇨병 환자 데이터 가져옴 diabetes = load_diabetes()   print(diabetes.data.shape, diabetes.target.shape) # 입력 데이터와 타깃 데이터 크기   (442, 10) (442,)   diabetes.data[0:3] # 당뇨병 환자 데이터 앞부분 3개만   array([[ 0.03807591,  0.05068012,  0.06169621,  0.02187235, -0.0442235 ,         -0.03482076, -0.04340085, -0.00259226,  0.01990842, -0.01764613],        [-0.00188202, -0.04464164, -0.05147406, -0.02632783, -0.00844872,         -0.01916334,  0.07441156, -0.03949338, -0.06832974, -0.09220405],        [ 0.08529891,  0.05068012,  0.04445121, -0.00567061, -0.04559945,         -0.03419447, -0.03235593, -0.00259226,  0.00286377, -0.02593034]])   diabetes.target[:3] # 당뇨병 환자 타깃 데이터 앞부분 3개만   array([151.,  75., 141.])   import matplotlib.pyplot as plt plt.scatter(diabetes.data[:, 2], diabetes.target) plt.xlabel('x') plt.ylabel('y') plt.show() #x축은 입력 데이터, y축은 타깃 데이터로 나타낸 그래프      #훈련 데이터 준비 x = diabetes.data[:, 2] #입력 데이터의 세번재 특성 분리하여 x에 저장 y = diabetes.target  #타깃 데이터를 y에 저장   w = 1.0 b = 1.0 # 션형 회귀에서의 가중치(기울기) = w, 절편 = b 를 둘다 1로 임의로 지정  # y = w * x + b 형태   y_hat = x[0]*w + b # 입력 데이터의 첫번째 샘플 x[0]에 대한 예측 데이터 y_hat을 구해본다. print(y_hat)   1.0616962065186886   print(y[0]) # 첫 번째 샘플 데이터 x[0]에 대응하는 타깃값 y[0]을 출력   151.0   # y[0]과 우리가 예측한 y_hat과 차이가 너무 많이남 -&gt; 우리가 만든 선형 방정식은 현재 데이터에 맞지 않다는 뜻  # w, b를 바꿔야 한다.!! 어떻게 ? y_hat이 y[0]에 비슷해 지도록   w_inc = w + 0.1 # w를 변화시킨 값 w_inc는 w에 0.1을 더한다 (0.1은 아무 의미 x 그냥 더해보는 것) y_hat_inc = x[0] * w_inc + b # 이번 선형 방정식에 w 대신 w_inc로 바꾼다.  print(y_hat_inc) # w_inc로 가중치를 바꾸면서 나오게 된 에측 결과를 y_hat_inc   1.0678658271705574   #이전 예측값 y_hat보다 y_hat_inc가 좀더 y[0]에 가까워 지긴 했다.   #w가 0.1 증가하면서 y_hat이 얼마나 변했는지 확인해 보면  w_rate = (y_hat_inc - y_hat) / (w_inc - w) # w_rate는 예측값의 증가 정도를 나타낸다.  print(w_rate) # 이 w_rate를 훈련 데이터 x[0]에 대한 w의 변화율 이라고 한다.   0.061696206518688734   print(x[0]) # 뭐지 ??? x[0]값과 w_rate(x[0]에 대한 w의 변화율)이 같은 값이다....  # w가 1만큼 증가한다고 가정해보자 그러면 y_hat은 x[0]만큼 증가 할 것 아닌가 # w 변화율 = w가 1만큼 증가할 때 y_hat이 얼만큼 증가하는지에 대한 의미와 같으니 # 당연히 선형 방정식에서는 w 변화율은 x값과 같을 것이다. # 식으로도 증명 가능  #w_rate == (y_hat_inc - y_hat) / (w_inc - w) == {(x[0] * w_inc + b) - (x[0] * w + b)} / (w_inc - w) # = {x[0] * ((w + 0.1) - w)} / ((w + 0.1) - w) = x[0]   0.0616962065186885   # 이제는 가중치(기울기)를 업데이트 하는 방법에 대해 알아보자. (y_hat과 y가 비슷해지게 가중치를 업데이트 하는 방법ㅂ)  w_new = w + w_rate # 기존 가중치에 가중치의 변화율을 더하여 가중치를 업데이트 한다. print(w_new)  #왜 이런 방법을 ? # 1. 변화율이 양수일 때 : y_hat이 y에 미치지 못하는 상황에서 변화율이 양수이면 w를 증가 시켜야 y_hat이 증가한다. # 이때 w의 변화율이 양수이므로 w에 w의 변화율을 더해주면 w는 증가하게 된다.  # 2. 변화율이 음수일 때 : y_hat이 y에 미치지 못하는 상황에서 변화율이 음수이면 w를 감소 시켜야 y_hat이 증가한다. # 이때 w의 변화율이 음수이므로 w에 w의 변화율을 더해주면 w는 감소하게 된다.  # 즉 변화율이 양수이든 음수이든 w에 w변화율을 더해주면 y_hat이 y에 가까워지는 방향으로 w가 변한다.   1.0616962065186888   # 이전에는 w(가중치)를 변화시켰다면 b(절편)을 변화시켜 보자. # 절편도 마찬가지 예측값이 타깃값에 가까워지도록 변화시키는 것이 목적!!  b_inc = b + 0.1 # 절편 b에 0.1을 더해보자 (0.1은 아무 의미 없음 그냥 더해보는 것) y_hat_inc = x[0] * w + b_inc print(y_hat_inc) # y_hat_inc가 y_hat 보다 y에 가까움   1.1616962065186887   b_rate = (y_hat_inc - y_hat) / (b_inc - b) print(b_rate) #이번에 b의 변화율에 대해 구해보면 1이 나온다 딱 1!!!!  #선형 방정식에서 b가 1만큼 증가하면 y_hat또한 당연히 1만큼 증가하겠지 #식으로도 증명가능 #b_rate = (y_hat_inc - y_hat) / (b_inc - b) ={} (x[0] * w + b_inc) - (x[0] * w + b)} / (b_inc - b) # = {(b + 0.1) - b} / {(b + 0.1) - b} = 1   1.0   # w와 마찬가지로 b(절편) 또한 업데이트를 하여 좀 더 타깃값과 유사한 예측값을 내놓게 해야한다. b_new = b + b_rate # b_rate = 1 # w 업데이트와 같은방법으로 b(절편) 또한 기존 b에 b_rate를 더하여 b를 갱신한다. (b_rate 대신 1로 해도 됨)   ''' 위의 방법으로 w, b를 업데이트 한다고 생각해보자 w, b를 변화시켜도 y_hat이 매우 조금 변한다. 이 방법으로는 y와 y_hat의 차이가 매우 큰 경우 y_hat을 y와 유사한 값으로 업데이트 시키는 시간이 매우 오래 걸릴 것 이다.  따라서 위으 문제점을 해결하는 방법으로 \"오차 역전파\"를 이용한다.  오차 역전파 (backpropagation) '''   err = y[0] - y_hat # 에러 값을 구한다. 에러값(오차) = 실제 값 - 예측값  ''' 오차 역전파 :  이전에 w, b를 갱신할때 w에는 w_rate를 더해주고, b에는 b_rate를 더해줬음 하지만 오차 역전파 방법은 y와 y_hat의 차이를 이용하여 w와 b를 업데이트 한다. -&gt; 오차가 연이어 전파되는 모습으로 수행  w에 w_rate * 에러값, b에는 b_rate * 에러값 을 더해주는 방식으로 w와 b를 갱신한다. '''  w_new = w + w_rate * err # 일단 처음에 x[0]일때 w의 변화율과 b의 변화율에 오차를 곱하여 w변화율과 b변화율을 갱신 b_new = b + b_rate * err    print(w_new, b_new) # -&gt; 이전에 오차를 이용하지 않은 방법에 비해 w변화율과 b변화율이 매우 크게 변했음   911.1983904448475 156.2427820067777   y_hat = x[1] * w_new + b_new # 위 방식대로 x[1]에 대해 err = y[1] - y_hat w_rate = x[1] b_rate = 1  w_new = w_new + w_rate * err b_new = b_new + b_rate * err print(w_new, b_new)   14.132317616381767 75.52764127612664   # x[0], x[1]을 이용해 w, b를 갱신하였다. 하지만 모든 입력 샘플에 대해 적용하여 w, b를 갱신하자 # 많이 할수록 w, b가 실제 데이터 타겟에 맞게 갱신되지 않을까? for x_i, y_i in zip(x, y):   y_hat = x_i * w + b    err = y_i - y_hat    w_rate = x_i   w = w + w_rate * err    b_rate = 1   b = b + b_rate * err  print(w, b)   587.8654539985689 99.40935564531424   ''' 위 방식으로 갱신한 w, b를 이용해 선형함수가 과연 실제 입력 x에 대한 타깃 y를 잘 예측할지  그래프에 나타내 보자.  산점도 -&gt; 입력 x값에 대한 실제 타깃 y값  직선 -&gt; 우리가 구해본 선형 함수(y = w * x + b)  ''' plt.scatter(x, y) pt1 = (-0.1, -0.1 * w + b) pt2 = (0.15, 0.15 * w + b)  plt.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]]) plt.xlabel('x') plt.ylabel('y') plt.show()  #먼가 아쉬움.... 직선이 실제 입력과 타깃과의 관계를 정확히 나타내지는 못하는 것 같음..      ''' 어떻게 하면 좀더 입력에 대한 실제 타깃과의 관계를 정확히 타나내는 선형 방정식을 구할 수 있을까/ 즉 더 적합한 w, b를 구할 수 있을까?  보통 경사 하강법은 주어진 trainning data로 학습을 여러 번 반복함  이전 까지는 한번만 반복햇음... -&gt; 적합한 w, b를 찾는데 학습량이 부족했음..  에포크(epoch) : 이렇게 전체 훈련데이터를 모두 이용하여 한 단위 작업을 진행하는 것 ''' for i in range(0, 100): #100번의 에포크 진행해 보자!!!   for x_i, y_i in zip(x, y):     y_hat = x_i * w + b     err = y_i - y_hat      w_rate = x_i     w = w + w_rate * err      b_rate = 1     b = b + b_rate * err  print(w, b) #100번의 에포크를 진행하고 난 뒤의 갱신된 w, b가 이전과 달라져 있음   913.5973364345905 123.39414383177204   #에포크 100번 진행한 뒤의 갱신된 w, b가 실제 x와 타깃 y의 관계를 잘 나타내는 선형방정식을 보이는지 #그래프를 통해 보자.  plt.scatter(x, y)  pt1 = (-0.1, -0.1 * w + b) pt2 = (0.15, 0.15 * w + b) plt.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]]) plt.xlabel('x') plt.ylabel('y') plt.show()  #에포크 1번 보다 훨씬 실제 데이터의 입력과 타깃 관계를 잘 나타내는 선형 방정식을 보인다. #즉 에포크를 늘리니 더 적합한 w, b를 갱신할 수 있다는 것을 알게 되었다.      x_new = 0.18 #그러면 이전에 구한 갱신된 w, b로 구한 선형방정식으로 새로운 입력 x에 대한 타깃 y를 예측해 보자. y_pred = x_new * w + b print(y_pred)   287.8416643899983   plt.scatter(x, y)  plt.scatter(x_new, y_pred) #새로운 입력 x에 대해 갱신된 w, b로 구한 선형방정식으로 예측한 y를 그래프에 나타내 보자. plt.xlabel('x') plt.ylabel('y') plt.show()  # 주황색? 으로 나타난 점이 새로운 입력 x에 대한 예측 y 값이다.. 실제 데이터 산점도에 어색하지 않은 위치인 것을 보니 괜찮게 예측한 것 같다..      이전에 정의한 경사 하강법은 조금 애매한 설명…. 다시 설명하자면   경사 하강법(Gradient descent) :    손실 함수가 정의되었을 때 손실 함수의 값이 최소가 되는 지점 찾는 방법       손실함수가 뭔데???…   손실 함수(loss function) = 비용 함수(cost function) = 목적 함수(objective function):    예상한 값과 실제 타깃값의 차이를 함수로 정의한 것         앞에서 적합한 가중치와 절편을 찾기 위해 사용한 경사 하강법에서 쓰인 손실 함수는 무엇일까?  바로 제곱 오차라는 손실 함수이다.   제곱 오차(Squared error) : SE = (y-y_hat)$^2$   타깃 값에서 예측 값을 뺀 후 제곱한 값      앞에서는 제곱 오차라는 손실 함수를 미분하여 가중치와 절편을 갱신하엿음..    미분????   이 부분을 알기 위해 제곱 오차라는 손실 함수를 파해쳐 보자       위에서 경사하강법이 곧 손실 함수의 값이 최소가 되는 지점을 찾는 방법 이라고 하였다.  그러면 최솟값을 어떻게 찾지???    아니 아까 예제 코드에서 w(가중치)와 b(절편)값 조절 하면서 y_hat 구했잖아….  y_hat과 y의 차이 즉 예측값과 실제 타깃 값 차이가 적으면 제곱 오차 함수 값도 작겠네 y- y_hat의 제곱이 작아질 테니…      아무튼 우리 w, b 갱신할 때 w_rate, b_rate 구하던거 기억날 것임.. 즉 가중치 변화량과 절편 변화량을 이용하여 w, b 갱신했잖아..    이 방법과 유사한 방식으로 w_rate(가중치 변화량), b_rate(절편 변화량) 구하는 것과 유사하게 가중치에 대한 손실 함수의 변화율과 절편에 대한 손실 함수의 변화율로 가중치와 절편을 갱신할 것이다.   구체적인 방법은 아래에서 설명   가중치에 대한 손실 함수에 (여기선 제곱 오차 함수) 변화량을 구하기 위해서 손실 함수에 가중치에 대해 미분을, 절편에 대한 손실 함수의 변화량 구하기 위해선 손실 함수에 절편에 대해 미분을 해주는 것이다.      자 다시!! 제곱 오차 함수의 최솟값을 얻기 위해 … 가중치에 대해 미분과 절편에 대해 미분을 해보자..    가중치에 대한 제곱 오차 미분을 하자   제곱 오차 식에 가중치(w)에 대해 편미분하면   $\\frac{\\delta SE}{\\delta w} = \\frac{\\delta}{\\delta w}(y - $y_hat$)^2 = 2(y -$ y_hat$)(-\\frac{\\delta}{\\delta w}$y_hat$) = 2(y - $y_hat$)(-x) = -2(y - $y_hat$)x$      정리하면 $\\frac{\\delta SE}{\\delta w} = -2(y - $y_hat$)x$      만약에 처음에 제곱 오차 공식을 (y-y_hat)$^2$가 아닌 2(y-y_hat)$^2$였다면 미분시 2와 $\\frac{1}{2}$이 곱해지면서 1이 되어 훨씬 깔끔하게 표현 되었을 것이다. 따라서 보통은 제곱 오차 공식을 2로 나눈 함수를 편미분 하여  $\\frac{\\delta SE}{\\delta w} = -(y - $y_hat$)x$    이와 같은 방식으로 나타내기도 한다. 앞으로는 이렇게 나타낼 것임    이제는 가중치에 대한 제곱 오차 함수의 변화율을 구하였으니 이전 예제 코드에서 가중치 갱신에 변화율을 더했던 방법과 비슷한 방법으로 가중치를 갱신할 것이다.  이 방법에서는 기존 w에서 변화율을 뺄 것이다.    이전 예제 코드와 다르게 왜 여기선 w에서 변화율을 더하지 않고 빼냐??   -&gt; 손실 함수의 낮은 쪽으로 이동하기 위해서   아니 무슨말 ??   이전에는 단순히 예측값이 기존 타깃값보다 작았기 때문에 예측값을 크게해주기 위해 가중치나 절편을 늘려야 했기 때문에 가중치와 절편에 각자의 변화율을 더해준 것 이라면 지금은 손실함수를 적용하였음   손실함수의 최솟값을 구하는 것이 곧 예측값과 타깃값을 유사하게 만드는 것이니 손실함수값을 낮추기 위해 가중치와 절편에 손실 함수에 대한 각자의 변화율을 빼주는 것이다. !!!   w = w - $\\frac{\\delta SE}{\\delta w}$ = w + (y - y_hat)x    위 식은 이전 예제 코드에서 오파 역전파를 알아보면서 보았던 식임…. (w + w_rate * err)  (y - y_hat)이 err고 err에 w_rate곱한 값에 기존 w를 더하여 갱신된 w를 만든다.      가중치와 마찬가지로 절편에 대하여 제곱 오차 미분을 하면    제곱 오차 식에 절편(b)에 대해 편미분하면   $\\frac{\\delta SE}{\\delta b} = \\frac{\\delta}{\\delta b}\\frac{1}{2}(y - $y_hat$)^2 = (y -$ y_hat$)(-\\frac{\\delta}{\\delta b}$y_hat$) = (y - $y_hat$)(-(b - $b_hat$)) = (y - $y_hat$)(-1) = -(y - $y_hat$)1$     b - b_hat = 1 인 것은 이전에 설명 하였으니 이해가 될 것이다   정리 하면 $\\frac{\\delta SE}{\\delta b} = -(y - $y_hat)     가중치에서 가중치에 대한 제곱 오차 함수의 변화율을 뺀 방식과 유사하게 절편에서 절편에 대한 제곱 오차 함수의 변화율을 빼면   b = b - $\\frac{\\delta SE}{\\delta b} = b + (y - $y_hat)       이제부터 손실 함수에 대해 일일이 변화율의 값을 계산하는 대신 편미분 이용하여 변화율 계산할 것임…    변화율 = Gradient     ''' 위에서 경사 하강법을 이용하여 회귀 문제를 변화율을 직접 구하는 방식, 편미분을 이용한 방식(손실 함수) 두 가지 방식을 이용하였다. 아래 예제는 두 가지 방법 모두 사용한 방식으로 파이선 클래스를 만들어 볼 것임 ''' class Neuron:   def __init__(self):     self.w = 1.0     self.b = 1.0    def forpass(self, x): #정방향 계산을 위한 메서드 정의     y_hat = x * self.w + self.b      return y_hat    #정방향 계산 : 뉴런으로 도식화한 상태에서 y_hat을 구하는 방향으로의 계산    def backprop(self, x, err): #역방향 계산을 위한 메서드 정의      w_rate = x       b_rate = 1      w_grad = w_rate * err  #이전에 설명한 경사 하강법 이용     b_grad = b_rate * err      return w_grad, b_grad    #역방향 계산 : 이전에 계산한 y_hat으로 정방향 계산과 반대로 y_hat과 y의 오차를 이용해 w와 b를 갱신   # 즉 정방향 계산과 반대의 방향으로 계산되는 것을 알 수 있다.    #따라서 오차역전파(backpropagation)이라는 용어가 나오게 된 것!!!!!    def fit(self, x, y, epochs = 100): #훈련을 위한 메서드 구현     for i in range(epochs):       for x_i, y_i in zip(x, y):         y_hat = self.forpass(x_i) #forpass 메서드 이용해 y_hat구함                  err = -(y_i - y_hat) #타깃값과 예측값의 오차를 구함          w_grad, b_grad = self.backprop(x_i, err) #backprop 메서드를 이용해 w, b를 갱신          self.w -= w_grad         self.b -= b_grad  neuron = Neuron() #위에서 만든 클래스에 대한 객체를 만들고 neuron.fit(x, y) # 만든 객체를 이용해 입력 data x 와 타깃 data y를 전달하여 훈련함  # 학습이 완료된 결과 (w, b를 이용한 선형 함수)를 그래프에 나타내 보자 plt.scatter(x, y) pt1 = (-0.1, -0.1 * neuron.w + neuron.b) pt2 = (0.15, 0.15 * neuron.w + neuron.b)  plt.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]])  plt.xlabel('x') plt.ylabel('y')  plt.show()      Reference    박해선, 딥러닝 입문, 이지스퍼블리싱, 2019, 45~74pg  ","categories": ["Deep_Learning"],
        "tags": ["선형 회귀","경사 하강법","손실 함수","오차 역전파"],
        "url": "/deep_learning/Numerical_prediction/",
        "teaser": null
      },{
        "title": "스프링 프레임 워크가 왜 생겼을까???",
        "excerpt":"스프링 이란??  스프링은 너무 많은 기능을 제공해 주고 있어 정의하기 쉽지가 않다.   스프링은 프레임워크인데 주요 기능 및 특징을 간단히 정리해보면     기술 :  1. 의존 주입 (DI, Dependency Injection) 지원  2. AOP (Aspect - Oriented Programming) 지원  3. MVC 웹 프레임워크 제공 등등      언어 :  자바, 코틀린, 그루비      이 외에도 수많은 기능 및 특징이 있다.   이렇게 방대하고 많은 스프링 프레임워크를 편리하게 사용할 수 있도록 지원해주는 것 또한 존재하는데     스프링 부트 :  스프링을 편하게 사용할 수 있도록 지원한다. 따라서 최근에는 기본으로 많이 사용 한다고 한다.   기능 :  1. 단독으로 실행할 수 있는 스프링 애플리케이션 쉽게 생성  2. Tomcat 같은 웹 서버 내장해서 별도로 설치 안해도 됨  3. 손쉬운 빌드 구성을 위한 starter 종속성 제공  4. 스프링과 외부 라이브러리 (3rd parth) 자동 구성 등등      이제 스프링에 대해 대충 알았으니 스프링을 왜 생겨났는지 알아보자     스프링이 필요로 하는 가장 큰 이유 :  좋은 객체 지향 애플리케이션을 개발할 수 있게 도와주는 역할을 하기 때문     스프링이 어떻게 좋은 객체 지향 애플리케이션을 개발할 수 있게 도와줄까???   그 전에 좋은 객체 지향 프로그래밍이 뭐지 ??       좋은 객체 지향 프로그래밍이 뭔데?     먼저 객체 지향 프로그래밍이 뭘까?     객체 지향 프로그래밍 (OOP, Object Oriented Programming) :  실세계에 존재하는 정보 혹은 상황을 “객체” 들의 모임과 “객체들 간의 메시지”를 주고받는 관계로 보자는 것이다.     즉 기존에 컴퓨터 프로그램을 단순히 명령어의 목록으로 보지말고 객체들의 모임과 객체들이 메시지를 주고 받으며 데이터를 처리한다고 보는 프로그래밍 이다.       이렇게 하면 뭐가 좋은데 ??      프로그램을 유연하고 변경이 용이하게 만들 수 있다.  따라서 대규모 개발에 많이 쓰인다.      하 이거 또 추상적인 표현이 나왔네… 프로그램을 유연하고 변경이 용이하게???? 이게 무슨 뜻??   이 뜻을 이해하기 위해선 객체 지향 프로그래밍 특징을 알아야 한다.      객체 지향 프로그래밍의 특징을 보면   1. 다형성 :  하나의 클래스나 메서드가 다양한 방식으로 동작 가능   대표적으로 오버라이딩과 오버로딩이 있다.    오버라이딩 :  부모 클래스의 메서드를 자식 클래스에서 재정의 오버로딩 :  이름이 같은 메서드가 매개변수의 자료형 혹은 수에 따라 다르게 정의 가능      단, 하위 클래스는 인터페이스 규약을 꼭 지켜야 한다. 즉 오버로딩, 오버라이딩 하면서도 인터페이스의 규약을 지키는 선에서 다르게 재정의를 해야한다.!!     2. 추상화 :  공통의 속성이나 기능을 가진 것들의 공통점을 일반화하여 묶고 각각의 세부적인 특징을 제거하여 단순하게 묶는 것이다. 객체 지향적 관점에서는 클래스를 정의하여 공통의 속성이나 기능 등을 묶는 것이다.      3. 캡슐화 :  클래스 내에 있는 정보들을 캡슐로 감싸서 숨기는 것을 의미한다. (클래스의 접근 지정자 이용)    이렇게 하여 외부에서 클래스 내의 정보들에 접근을 막아 정보 은닉을 할 수 있다.     4. 상속:  클래스와 클래스 사이의 관계를 의미하는데 클래스 간의 상속으로 엮이면 자식 클래스는 부모 클래스의 정보들을 상속 받을 수 있다.     등등이 있다.         -&gt; 이 특징으로 인하여 프로그램을 역할과 구현으로 구분하기 쉽고 그로 인해 프래그램을 유연하고 용이하게 만들 수 있기 때문이다.     쉽게 생각하면 역할이 인터페이스이고 구현이 인터페이스를 구현(정의)한 객체라고 생각할 수 있다.   역할과 구현으로 분리 ??   현재 스프링 수업을 듣고 있는 김영한 강사님께서는 이 역할과 구현의 분리를 실세계에서 비유해주셨는데 훨씬 이해가 잘되었다. 만약 운전자와 자동차가 있다고 가정하자.   운전자의 역할과 자동차의 역할이 각자 있을 것이다.     그리고 자동차 종류가 매우 다양한데  자동차 역할을 여러 종류의 자동차들 각각을 따로 구현을 해야한다.   만약 자동차가 k3, 아반떼가 있다고 하자 k3를 운전할 줄 아는 운전자가 아반떼를 운전할 수 있을까? -&gt; 당연하다    -&gt; 자동차의 종류가 바뀌어도 운전자에게 영향을 주면 안된다.!!       유연하고 변경 용이하다 -&gt; 운전자가 k3를 운전하다가 아반떼를 타고싶을 때 쉽게 운전할 수 있어야 한다.      어떻게 이게 가능?? 자동차의 역할(인터페이스)를 다 따라서 각 종류의 자동차를 구현하였기 때문에     운전자는 자동차의 역할에 대해서만 알고 있지 자동차 구현에 대한 것은 알지 못한다.    자동차의 구체적인 구현이 바뀌더라도 자동차의 역할은 바뀌지 않고 운전자 입장에서 자동차 구현이 바뀌더라도 운전할 수 있어야 한다.!!   운전자 역할 -&gt; 자동차 역할     자동차 역할 &lt;- 자동차 구현 : k3, 아반떼….     웹 서비스 입장에서 생각해보자 웹 서비스를 사용하는 클라이언트들은 웹은 구체적인 구현에 대해 알 필요가 없다. 만약 구현을 알아야만 서비스를 사용할 수 있다면  너무 끔찍하다… 그저 서비스를 사용하기만 하면 될 뿐이다.   마찬가지이다 운전자는 자동차의 구현에대해 알 필요가 없다. 아니 알고 싶지도 않다.. 자동차의 역할만 안다면 자동차 구현이 다르든 바뀌던 아니면 새로운 종류의 자동차가 나오더라도 운전자는 운전을 할 수 있다.!!   또한 클라이언트(운전자)에 영향을 주지 않으면서 새로운 기능을 제공할 수도 있다. 즉 구현이 바뀌더라도 클라이언트는 그것을 배울 필요가 없다.      이 모든 것을 역할과 구현으로 나누었기 떄문에 가능하다!!      또 다른 예시로는 내가 재밌게 본 드라마 나의 아저씨를 예로 들어보자!!   나의아저씨에서 남자 주인공 역으로 “박동훈”, 여자 주인공 역으로 “이지안”이 있다.   이 “박동훈”, “이지안”역을 역할로 볼 수 있다.      하지만 이 “박동훈” 역할은 이선균 배우가  맡을 수 있지만 다른 배우가 맡을 수도 있다. Ex) 조정석 배우   마찬가지로 “이지안” 역할은 아이유 배우가 맡을 수 있지만 다른 배우가 맡을 수도 있어야 한다. Ex) 전지현 배우   즉 각 역할을 다른 배우로도 대체가 가능하다. (가능 해야한다)   이렇듯 “박동훈”, “이지안” 역할은 역할로 구현은 “박동훈”을 이선균 배우로 할지 조정석 배우로할지 “이지안”을 아이유 배우가 할지 전지현 배우가 할지로 나누어져 있기 때문에 배우들을 대체 가능하다!!!  배우가 바뀌어도 역할은 바뀌지 않는다. “박동훈”역할을 이선균 배우가 하고 있고 “이지안”역할을 아이유 배우가 하고 있다가 아이유 배우 대신 전지현 배우가 대체하엿다해서 이선균 배우에게 영향을 전혀 끼치지 않는다. 그냥 대본에 따른 연기를 하면 된다.   -&gt; “박동훈” 역할이 클라이언트 , “이지안”역할이 서버라고 가정하면 “이지안” 역할의 배우가 바뀐다해서(구현이 바뀐다해서) 클라이언트에게 영향을 끼치지 않는다.       이 모든 예가 객체 지향의 특징으로 유연하고 변경이 용이함을 보여준다.  정리 해보자    역할과 구현을 분리하면     클라이언트는 대상의 역할(인터페이스)만 알면 됨.     클라이언트는 구현 대상의 내부 구조를 몰라도 됨.     클라이언트는 구현 대상의 내부 구조가 바뀌어도 영향 X.     클라이언트는 심지어 구현 대상 자체를 변경해도 영향 X.      -&gt; 프로그램이 단순해지고 유연해지며 변경 또한 편리해지는        스프링 프레임워크는 자바 언어로 구성 되어있다.   그러면 자바 언어로 역할과 구현을 나누어 보자       역할 : 인터페이스  구현 : 인터페이스를 구현(정의)한 클래스, 구현 객체    =&gt; 따라서 객체를 설계할때 인터페이스(역할)를 먼저 부여를 한 후 그 역할을 수행하는 구현 객체를 만들자.(정의 하자)       객체간의 협력 관계을로 생각하자   클라이언트 : 요청   서버 : 응답     이라고 보면 수 많은 객체 클라이언트와 객체 서버는 서로 협력 관계를 가지게 된다!!!   어떻게 자바에선 역할과 구현을 나누는지 생각해보자      객체 지향의 특성 중 다형성 그 중에서도 오버라이딩을 생각해보면 어떤 인터페이스(역할)가 있고 그 인터페이스를 구현(정의)한 객체를 실행 시점에서 유연하게 변경할 수 있다. -&gt; 유연, 변경 편리       즉 다형성 특징을 통해 (특히 오버라이딩 역할) 클라이언트를 변경하지 않고 서버의 구현 기능을 유연하게 변경할 수 있다.        역할과 구현을 분리 한다는 것을 정리 해보면     실세계에서 존재하는 정보를 역할과 구현이라는 편리한 컨셉을 객체지향의 특징들을 이용해 프로그램의 객체 세상으로 가져올 수 있다.     유연하고 변경이 용이하다.    설계의 확장이 가능하다.     클라이언트에게 영향을 주지 않으면서 내부 구조를 바꿀 수 있다.      -&gt; 단 인터페이스(역할)을 안정적으로 잘 설계해야 역할을 기준으로 구현을 할 수 있기 때문에 역할을 잘 설계하는 것이 중요하다.!!      하지만 역할과 구현을 분리함에 있어서 문제점, 한계점은 없을까??   역할과 구현의 분리의 문제점(한계점)    역할(인터페이스) 자체가 변해버리면 클라이언ㅌ와 서버 모두에 큰 영향을 미친다. -&gt; 클라이언트, 서버 모두 큰 변경이 발생.    ex) 역할 : 자동차에서 =&gt; 비행기로 바꾼다면 ???   구현도 모두 바뀔 뿐더러 (여러 비행기 종류가 있게지 ex) 보잉 등등), 운전자 역할 또한 변경됨. 당연하지 자동차랑 비행기는 완전히 달라지니까 운전 방법 또한 다르겠지        자 지금까지 스프링이 왜 생기게 되었냐?   -&gt; 좋은 객체 지향 애플리케이션을 개발할 수 있게 도와주는 역할     좋은 객체 지향이 뭘 해주길래??   -&gt; 프로그램을 유연하고 변경이 용이하게 만들 수 있다      프로그램을 어떻게 유연하고 변경이 용이하게 하지??   -&gt; 객체 지향 특징을 통해 역할과 구현을 분리      여기서 의문 좋은 객체 지향을 어떻게 하는지? 의문이 든다..    좋은 객체 지향 설계의 5가지 원칙 (SOLID)  1. SRP(Single Responsibility Principle) 단일 책임 원칙 :    한 클래스는 하나의 책임만 가져야 한다는 원칙이다.   여기서 책임이 무슨 책임을 뜻하는 건지 모르겠다… 거기다가 굳이 하나의 책임 ???  이 것은 문맥과 상황에 따라 다르게 해석되기 때문에 모호하다.   하지만 중요한 기준을 세워두면 상황에 따라 해석할 수 있는데  “변경”  이 그 기준이 된다.   프로그램 내에서 “변경”이 일어났을때 파급 효과 (영향)이 적다면 SRP를 잘 따르는 것으로 보면 된다.  ex) 한 클래스에 어떤 데이터를 읽는 기능과 어떤 데이터를 쓰는 기능 둘다 존재한다고 하면 만약 데이터를 읽는 기능에 “변경”이 일어났을때 이 클래스에 영향을 끼칠 것이다. 또한 데이터를 쓰는 기능에 “변경”이 일어 났을때에도 이 클래스에 영향을 끼칠 것이다. 따라서 클래스는 SRP를 지키지 않은 코드이고, 데이터를 읽는 기능, 쓰는 기능 두가지를 나눠서 각각의 클래스로 나눠야 SRP를 지킨 코드가 될 것이다.     2. OCP(Open / Closed Principle) 개방 / 폐쇄 원칙 :    소프트웨어 요소는 확장에는 열려 있으나 변경에는 닫혀있다는 원칙이다.   먼가 이상하다.. 확장에는 열려있다고 했다. 확장을 하려면 코드를 변경에야 할 것 아닌가?? 근데 변경에는 닫혀있다니.. 통 이해가 되지 않는다.   -&gt; 이 문제는 이전에 설명한 객체 지향의 특징 중 다형성으로 충분히 해결이 가능하다   만약 어떤 확장을 해야하는 상황이라면  인터페이스를 구현한 새로운 클래스를 하나 만들어서 새로운 기능을 구현한다면 기존 코드를 변경하지 않으면서 확장이 가능하기 때문이다. (이것 또한 “역할과 구현의 분리”로 가능하네..)     하지만 OCP에 큰 문제점이 있다. 아래 예를 들어 보자  ex)  public class A {    private B b = new C();  }    -&gt; 확장    public class A {  //private B b = new C();    private B b = new D();  }     A : 클라이언트 코드   B : 서버 코드   라고 하자     만약 A 클라이언트가 구현 클래스를 직접 선택한다고 하자   B b = new C(); =&gt; 기존 코드   B b = new D(); =&gt; 변경 코드 일때     구현 객체를 변경하려면 클라이언트 코드를 변경해야 하는 상황이다. -&gt; 예시 코드에선 분명히 다형성을 적용 (역할과 구현을 확실히 분리함) 했지만 OCP를 지킬 수 없는 상황이다.  이걸 어떻게 해결하지 ?….   -&gt; 객체 생성하고 연관관계를 맺어주는 별도의 조립, 설정자가 필요한 상황이다.   이걸… 구현하기엔 너무 복잡한데…    그래서 Spring 프레임 워크가 생겨난 것임… -&gt; 위 문제를 Spring Container가 해결 해준다..       3. LSP(Liskov Substitution Principle) 리스코프 치환 원칙:  프로그램의 객체는 프로그램의 정확성을 깨뜨리지 않으면서 하위 타입의 인스턴스로 바꿀 수 있어야 한다는 원칙이다.   이 원칙을 보면 확실히 이전에 설명한 객체 지향의 특성을 지키기 위한 원칙임을 알 수 있다.   다형성의 특징을 보면 하위 클래스는 인터페이스 규약을 꼭 지켜야 한다고 했는데 이 것을 의미하는 원칙이 LSP 이다.   ex) 쉽게 자동차로 예를 들면 엑셀을 밟으면 앞으로 가야하는 기능을 다형성 특징으로 구현을 다양하게 하는 경우에 더 빨리 앞으로 가게 한다던지, 조금 천천히 앞으로 가게 한다던지 등등 앞으로 가는 기능은 지켜야 한다. 하지만 옆으로 가거나 뒤로 가게 하는 구현을 하면 안된다는 것이다.   오버라이딩 입장에서 이런 기능을 나타내는 메서드를 재정의 할때 엑셀을 밟았을때 앞으로 가야하는 기본 인터페이스 규약은 꼭 지켜야 한다는 뜻이다.      따라서 LSP를 잘 지키면 이너페이스가 명확해지고, 대체 가능성이 높아지는 프로그램이 된다.!!!        4. ISP(Interface Segregation Principle) 인터페이스 분리 원칙:  특정 클라이언트를 위한 인터페이서 여러 개가 범용 인터페이스 하나보다 낫다는 원칙이다. 어떤 한 인터페이스가 여러개의 역할을 담고 있다면 각자의 역할이 서로 엮이게 되면서 서로 영향을 주게 된다. 따라서 하나의 역할이 변하면  다른 역할에 영향을 끼치기 때문에 문제가 된다.   따라서 인터페이스는 최대한 각각의 역할에 따라 분리가 되어야 한다.   ex)  자동차 인터페이스 -&gt; 운전 인터페이스와 정비 인터페이스로 분리 하고   사용자 클라이언트를 -&gt; 운전자 클라이언트와 정비사 클리이언트로 분리 한다면   만약에 정비 인터페이스가 변한다고 해도 운전자 인터페이스에 영향을 끼치지 않기 때문에 인터페이스 훨씬 명확해지는 장점이 있다.     즉 ISP를 지키면 인터페이스가 명확해지고 대체 가능성이 높아진다.!!!         5. DIP(Dependency Inversion Principle) :  프로그래머는 “추상화에 의존해야하고 구체화에 의존해선 안된다.”라는 원칙이다.   이전에 잠깐 언급된 의존성 주입은 DIP를 따르는 방법중 하나이다.  이 말을 다르게 표현하면 구현 클래스에 의존하지 말고 인터페이스에 의존 해라는 의미이다.!      즉 DIP는 이전에 설명한 “역할과 구현의 분리” 중에서도 “역할”에 의존해야 한다는 것이다.   객체 세상도 클라이언트가 인터페이스에 의존해야 유연하게 여러 구현을 할수 있기 때문이다 (구현체를 변경할 수 있음.) -&gt; 유연하고 변경에 용이.      여기서 큰 문제가 있다.!!   OCP를 설명할때 예에서 A는 인터페이스에 의존하지만 구현 클래스도 동시에 의존하고 있다.   A 클라이언트가 구현 클래스를 직접 선택 하기 때문이다.   그럼 이전에 설명한 예시는 DIP를 위반하는 것으로 볼 수 있다.      정리 하자면..     객체 지향의 특성으로 개발이 편리하다.     다형성의 특성으로 구현 객체를 변경할 때 클라이언트 코드도 변경되는 문제가 존재했다.    -&gt; 따라서 다형성의 특성만으로는 OCP, DIP를 지킬 수 없었다. 이러한 문제를 해결할 방법을 찾아야 한다.      Spring에 대해 배우고자 하였지만 지금까지 Spring에 대한 이야기가 거의 없었다…   하지만 지금 까지 Spring이 왜 생겨 났는지를 알기 위해 이야기를 이어 왔다.   위의 정리 2에서  다형성의 특징만으로는 OCP, DIP를 지킬 수 없었다.  이 문제를 해결하기 위해 Spring이 생겨났다.     즉 OCP, DIP를 지키지 못했다는 것은 좋은 객체 지향 프로그래밍을 하지 못했다는 것이고 OCP, DIP를 지켜서 좋은 객체 지향 프로그래밍을 하게끔 도와주기 위해 Spring이 생겨난 것이다.      그럼 어떻게 Spring으로 OCP, DIP를 가능하게 하지??   스프링에서 OCP, DIP를 가능하게 하는 기술 :  1. DI(Dependency Injection) 의존관계, 의존성 주입  2. DI container 제공      -&gt; 이 기술로 클라이언트 코드의 변경없이 기능이 확장이 가능하게 된다. 따라서 쉽게 부품을 교체하듯이 개발이 가능하게 된다.!!!   위 DI에 대해서는 앞으로 차차 알아가게 될 것이다.       Spring이 존재하기 이전에 개발자들은 좋은 객체 지향 개발을 하기 위해서 특히 OCP, DIP를 지키면서 개발을 하기 위해서 너무 많은 고생을 하게 되었고 자연스럽게 이러한 문제를 해결하기 위해 Spring 프레임워크가 생기게 되었다. (정확히는 DI container가 생기게 되었다.)       지금 까지 Spring이 왜 생겨나게 되었는지 알게 되었다.     이후에는 Spring이 왜 생겨났는지 코드를 통해 느껴보고자 한다.     Reference :  김영한 강사님 스프링 핵심 원리 - 기본편  강의 중  ","categories": ["Spring"],
        "tags": ["스프링 프레임워크","스프링 부트","객체 지향 프로그래밍","SOLID"],
        "url": "/spring/spring_basic(1)/",
        "teaser": null
      },{
        "title": "이진 분류",
        "excerpt":"이진 분류(Binary Classification) :  임의의 샘플 데이터를 참 혹은 거짓으로 구분하는 문제를 말한다.   퍼셉트론(Perceptron) :  이전에 공부한 선형 회귀와 매우 유사함 하지만 퍼셉트론은 마지막 단계에서 샘플을 이진 분류하기 위해 계단 함수를 사용한다.   이후 계단 함수를 통과한 값을 다시 가중치와 절편을 갱신하도록 학습하는데 사용한다.       만약 뉴런은 입력 신호들을 받아 z를 만든다고 해보자  $w_1x_1 + w_2x_2 + b = z$라 하자  아니 이전에 공부한 선형 방정식과 다른 것 같은데 -&gt; 이전에는 wx + b = y였는데 이 것은 입력값이 한개 더 늘었을 뿐이다. (원래 x 한개에서 $x_1과x_2$ 2개의 featrue가 입력값)      자 이제 선형 함수의 출력값인 z를 계단함수에 적용해보자.. 그런데 계단함수가 뭐지?   계단 함수(step function) :  z가 0보다 크거나 같으면 1로 0보다 작으면 -1로 분류하는 함수  y = 1 (z &gt;= 0)  y = 0 (z &lt; 0)        image_reference : aistudy.co.kr/neural/activation_function.htm      정리 하자면 퍼셉트론은 선형 함수를 통과해서 얻은 결과값인 z를 계단함수에 입력하여 그 값이 0보다 클지 작을지에 대해 검사하여 크다면 1을 작다면 -1로 분류하는 간단한 알고리즘 이다.     퍼셉트론은 계단 함수의 결과를 사용하여 가중치와 절편을 업데이트 한다.      현재부터 여러 개의 특성(feature)을 사용해 보자  그러면 특성이 n개인 선형 함수를 나타내보면    $y=w_1x_1=w_2x_2+~~~+w_nx_n+b$         이 식을 sigma기호로 나타내면   $b + \\sum_{i=1}^{n} w_ix_i$     늘어난 입력 특성에 따라 가중치(w) 갯수도 따라 늘어나는군… 당연하지 입력(x)에 곱해지는 값이 가중치인데 물론 절편(b)은 1개 그대로임     지금까지 퍼셉트론에 대해 알아 보았다.  지금까지 퍼셉트론을 모두 구현해 왔지만 사이킷런 패키지에서 Perceptron이라는 이름의 클래스를 제공해 주기 때문에 이 것을 이용하면 직접 구현할 필요가 없다.   그럼 지금까지 뭐한거 ?? 어떻게 해당 클래스가 구성되어있는지 알면 그 클래스를 사용하거나 이해하기 좋으니까..   아달린(Adaline) :  퍼셉트론을 개선한 적응형 선형 뉴런(Adaptive Linear Neuron)       적응형 선형 뉴런 ??? 그냥 선형 뉴런과 무슨 차이 ??     아달린에 대해 알아보면 아달린은 선형 함수의 결과를 학습하는데 사용한다 (선형 함수의 가중치와 절편 갱신하는 학습). 그리고 계단 함수의 결과는 예측에만 활용한다….     이전에 배운 선형 뉴런 경우 선형 함수의 결과를 계단 함수에 입력하고 그 결과를 이용해 학습과 예측을 하였다. 하지만 아달린 경우에는 역방향 게산이 계단 함수 출력 이후가 아닌 선형 함수의 출력 이후에 진행된다는 차이점이 있다.        그런데 아달린을 하면 뭐가 더 좋아지나 보군.. 어떤것이??   아달린을 좀더 개선한 버전이 로지스틱 회귀이다.   로지스틱 회귀가 이전 선형 뉴런에 비해 어떤 점이 좋은지 알 수 있으면 위의 의문이 해결될 것이다.         로지스틱 회귀(logistic regression) :  아달린에서 좀더 발전한 형태이다.   로지스틱 회귀는 선형 함수를 통과시켜 얻은 z를 임계 함수에 보내기 전에 변형시키는데 이 변형 시켜주는 함수가 활성화 함수(activation function)이다.   선형 함수를 통과하여 얻은 z가 활성화 함수에 들어가여 그 결과로 a를 내놓는다고 하자 그리고 이 a는 임계 함수에 들어가 예측값을 얻게 된다.   또한 아달린과 유사하게 (좀 다름) a가 역방향 계산이 일어나 선형함수의 결과를 학습하는데 사용된다 (적합한 가중치와 절편 찾는 학습)   임계 함수는 아달린에서의 계단 함수와 역할 비슷하지만 활성화 함수의 출력값을 사용한다는 점이 차이다.       각 차이점을 정리 해보자    퍼셉트론 (일반 선형 뉴런) :  입력 -&gt; 선형 함수 -&gt; z -&gt; 계단 함수 -&gt; y_hat   예측 값인 y_hat가 다시 역방향 계산이 일어나 선형 함수의 결과를 학습하는데 사용 (적합한 가중치와 절편 찾는 학습)      아달린 (적응형 선형 뉴런) :  입력 값 -&gt; 선형 함수 -&gt; z -&gt; 계단 함수 -&gt; y_hat   선형 함수의 결과값인 z가 다시 역방향 계산이 일어나 선형 함수의 결과를 학습하는데 사용 (적합한 가중치와 절편 찾는 학습)      로지스틱 회귀 :  입력값 -&gt; 선형 함수 -&gt; z -&gt; 활성화 함수 -&gt; a -&gt; 게단 함수 -&gt; y_hat   활성화 함수의 결과값인 a가 다시 역방향 계산이 일어나 선형 함수의 결과를 학습하는데 사용 (적합한 가중치와 절편 찾는 학습)      활성화 함수는 비선형 함수를 사용해야 한다.!!  왜 활성화 함수로는 선형함수가 아닌 비선형 함수를 사용해야 하지 ??   ex) 만약 선형함수인 $y = w_1x_1 + w_2x_2 + …. + w_nx_n$에다가 활성화 함수 y = ka (선형 함수) 가 있다고 하자.   이 둘을 쌓은 수식은 $y = k(w_1x_1 + w_2x_2 + … + w_nx_n)$이 되고 이 결과는 다시 선형함수가 된다. 이렇게 되면 임계 함수 앞에 뉴런을 아무리 많이 쌓는다고 해도 그 결과가 선형함수일 것이고 그로 인해 큰 의미가 생기지 않게된다. 따라서 활성화 함수로 비선형 함수를 사용하는 것이다.       비선형 함수의 예로 $p = \\frac{1}{1 + e^{-z}}$ 이 있으며 이 외에도 다양한 함수가 존재한다.      그러면 로지스틱 회귀에서 사용되는 활성화 함수는 어떤 함수일까?   -&gt; 로지스특 회귀에서는 “시그모이드 함수(sigmoid function)”를 활성화 함수로 사용한다.       시그모이드 함수가 어떤 역할을 하며, 어떤 과정으로 만들어지겓 되었는지 알아보자   로지스틱 회귀에서 선형함수의 출력값 z는 $z = b + \\sum_{i=1}^{n} w_ix_i$인데 이 z 값을 활성화 함수를 통과시켜서 a가 되게 된다. 이때 시그모이드 함수는 z를 0 ~ 1 사이의 확률값으로 변환시켜주는 역할을 하게 한다.   예를들어 분류를 해야하는 경우에 시그모이드 함수의 결과인 a가 0.5(50%)보다 크면 양의 클래스, 그 이하가 되면 음의 클래스로 분류를 한다.      그럼 시그모이드 함수가 어떻게 만들어 지는지 과정에 대해 알아보자     오즈 비 -&gt; 로짓 함수 -&gt; 시그모이드 함수     오즈 비(odds ratio) :  성공 확률과 실패 확률의 비율을 나타내는 통계    OR(odds ratio) = $\\frac{p}{1 - p}$ (p = 성공 확률)    오즈피를 그래프로 나타내면      image_reference : https://kau-deeperent.tistory.com/90      로짓 함수(logit function) :  오즈 비에 로그함수를 취하여 만든 함수    logit(p) = $log(\\frac{p}{1 - p})$    로짓 함수는 p = 0.5일때 0이 되고 p가 0과 1일때 각각 무한대로 음수와 양수가 되는 특징을 가진 함수이다.   그래프로 나타내보면     image_reference : https://i-am-eden.tistory.com/21   로짓 함수의 세로 축을 z로 가로축을 p로 놓으면 확률 p가 0 에서 1까지 변할 때 z가 매우 큰 음수에서 매우 큰 양수로 증가하는 것을 볼 수 있다.   따라서 이 식을 다시 정리하면  z = log($\\frac{p}{1 - p}$)       로지스틱 함수(Logistic function) :  위 로직 함수 z에 대해 아래와 같이 정리하면 로지스틱 함수가 된다.    $p = \\frac{1}{1 + e^{-z}}$  이 식을 유도한 방법은 기존 로짓함수의 식에서 z = ~ 꼴이 아닌 p = ~꼴로 바꾸어 주는 것이다.  이렇게 정리한 이유는 기존 로잣함수의 가로 축이 p 였는데 가로 축을 z로 놓기 위해서 이다. (역함수 변환과 유사)      image_reference     이렇게 나타낸 로지스틱 함수를 그래프로 그려보자    로짓 함수의 가로와 세로축을 반대로 뒤집은 모양이 된다. -&gt; 로짓 함수의 역함수가 로지스틱 함수 (y = x 그래프 기준 대칭으로 보면 됨.)   그리고 이 그래프는 S자 형태를 띈다.    이 S자 형태를 착안해서 로지스틱 함수를  시그모이드 함수(Sigmoid Function) 이라고 부른다.      로지스틱 회귀를 정리 해보면   선형 함수 -&gt; z -&gt; 로지스틱 함수 -&gt; a -&gt; 임계 함수 -&gt; y_hat   a는 역방향 계산으로 선형함수의 가중치와 절편을 갱신함.   이때 z는 $-\\infty$ ~ $\\infty$의 범위를 가지는데 로지스틱 회귀는 이진 분류가 목적이기 때문에 z 범위를 조절해야 한다. 이 문제의 해결을 위해 시그모이드 함수를 활성화 함수로 사용하여 0 ~ 1사이의 값으로 범위를 조절하였다.   따라서 시그모이드 함수의 결과인 a값이 0 ~ 1 로 확률처럼 해석이 가능하게 되었다. a를 확률로 이해하면 a를 0과 1로 구분 (이진 분류) 하기 위해서 마지막에 임계 함수를 이용하였다.  임계 함수에서 a값이 0.5보다 큰지 혹은 이하인지에 따라 1 혹은 0으로 y_hat으로 결과를 내놓았다.     지금 까지 이진 분류를 어떻게 하는지는 알겠는데 그럼 a 값으로 역방향 계산을 통해 선형함수의 가중치와 절편을 어떻게 갱신하는지 궁금하다…   이 방법도 손실함수를 사용할 것이다. 그러면 로지스틱 회귀에서는 어떤 손실 함수를 사용해 가중치와 절편을 갱신할 수 있을까??   이전에 배운 선형회귀에서 손실 함수로 제곱 오차를 사용한 것처럼 로지스틱 회기에서도 적용 안되려나 ??   이전에 배운 선형회귀는 정답과 예상값의 오차 제곱이 최소가 되느 가중치와 절편을 찾는 방법을 이용하였다 (제곱 오차) 하지만 로지스틱 회귀에서는 선형 회귀와 목적이 다르다. 선형 회귀는 어떤 값을 찾는 거라면 로지스틱 회귀는 분류가 목적이다!!!   즉 올바르게 분류를 하는 비율을 높이는 것이 목표이다.       이전에 배운 방법인 경사 하강법의 손실함수를 사용하려고 하니 … 올바르게 분류된 샘플의 비율은 미분 가능한 함수가 아니기 때문에 이 방법은 불가능 하다. 그러면 다른 함수를 사용해야 한다..   -&gt; 이 함수가 바로 “로지스틱 손실 함수” 이다.     로지스틱 손실 함수 :  다중 분류를 위한 손실 함수인 크로스 엔트로피 (Cross Entropy) 손실 함수를 이진 분류 버전으로 만든 것   크로스 엔트로피 손실 함수는 이후에 배울 것이다.    L = -(ylog(a) + (1 - y)log(1 - a))      로지스틱 회귀는 이진분류에가 목적이기 때문에 y값 (타깃값)이 0 혹은 1이다. 따라서 위 손실함수 식에서 y값이 0 혹은 1이 되다.      y가 0인 경우 (음성 클래스) -&gt; L = -log(1 - a)   y가 1인 경우 (양성 클래스) -&gt; L = -log(a)      위 두 식의 값을 최소로 만들다 보면 a의 값이 원하는 목표의 값에 가까워 진다는 것을 알 수 있다.     음성 클래스 경우 (y = 0 경우) 로지스틱 손실 함수의 값(L)을 최소로 만들려면 a는 0에 가까워 지게 되고    양성 클래스 경우 (y = 1 경우) 로지스틱 손실 함수의 값(L)을 최소로 만들려면 a는 1에 가까워 지기 때문이다.     이 값들 (다시 을 계단 함수에 통과시키면 올바르게 분류 작업이 수행 하게 된다.        정리 하자면 로지스틱 손실 함수를 최소화 하면 a 값이 우리가 원하는 값이 되게 된다.     로지스틱 손실 함수의 미분   로지스틱 회귀의 가중치와 절편을 갱신하하기 위해 로지스틱 손실 함수를 미분해보자  미분 하는 이유는 나중에 알 수 있다.    가중치와 절편에 대한 로지스틱 손실 함수의 미분 결과는     $\\frac{\\delta}{\\delta w_i}L = -(y-a)x_i$    $\\frac{\\delta}{\\delta b }L = -(y-a)x_i$     이전 선형회귀 에서의 가중치와 절편에 대한 미분 결과와 유사하다   다만 y_hat 대신에 a가 있을 뿐이다.        로지스틱 회귀의 구현이 사실 선형 회귀와 큰 차이가 없는 것 같다.       우리는 로지스틱 손실함수의 가중치에 대한 미분, 절편에 대한 미분을 해야하는데  이 미분을 어떻게 해야할지 고민이다. 왜냐하면 로지스틱 손실함수(L)을 가중치(w)나 절편(b)로 바로 미분하는 것은 너무 복잡하기 때문이다.      미분의 연쇄 법칙을 이용한다면 이 문제를 해결할 수 있다.    미분의 연쇄법칙 :  $\\frac{\\delta y}{\\delta x} =\\frac{\\delta y}{\\delta u} \\frac{\\delta u}{\\delta x}$        미분의 연쇄 법칙을 적용하기 이전에 로지스틱 회귀의 과정을 다시 정리해보자  그 이유로는 역방향 계산 방향을 알아야 미분의 연쇄법칙을 적용할 수 있기 때문이다.     입력($x_1, x_2, … x_n$) -&gt; 선형 함수($w_1, w_2, —, w_n$, b) -&gt; z -&gt; 활성화 함수 -&gt; a -&gt; 계단함수 -&gt; y_hat      a에서 역방향 계산을 하여 선형 함수의 가중치와 절편을 갱신하고 그렇게 되면 더욱 타깃에 적합한 z-&gt;a-&gt;y_hat 값을 찾게 될 것이다.      이 과정을 보면 로지스틱 손실 함수에 대한 미분이 연쇄 법칙에 의해 진행되는 구조이다.   이러한 구조를 &lt;/b&gt; Gradient가 역전되었다 &lt;/b&gt;라고 표현한다.   그럼 이제 다시 본론으로 돌아와 미분의 연쇄법칙을 적용해 로지스틱 손실함수의 가중치, 절편에 대한 미분을 해보자     먼저 로지스틱 손실함수(L)을 활성화 함수의 출력값(a)에 대해 미분하고  활성화 함수의 출력값(a)은 선형 함수의 출력값(z)에 대하여 미분하고   선형 함수의 출력값(z)은 가중치(w) 또는 절편(b)에 대해 미분한다.   이 미분한 결과들을 서로 곱해주면 원하는 로지스틱 손실함수의 가중치 혹은 절편에 대해 미분한 결과가 된다.   이 과정이 미분의 연쇄법칙을 이용한 것이다.      이제 다시 정리해보면   로지스틱 손실 함수를 가중치에 대한 미분 :  $\\frac{\\delta}{\\delta w_i }L = \\frac{\\delta L}{\\delta a }\\frac{\\delta a}{\\delta z }\\frac{\\delta z}{\\delta w_i }$      로지스틱 손실 함수를 절편에 대한 미분 :  $\\frac{\\delta}{\\delta b}L = \\frac{\\delta L}{\\delta a }\\frac{\\delta a}{\\delta z }\\frac{\\delta z}{\\delta b }$      위 두 미분 계산 과정을 생략하고 식을 정리하면  $\\frac{\\delta}{\\delta w_i }L = -(y - a)x_i$  $\\frac{\\delta}{\\delta b}L = -(y - a)1$  이다.      이제 미분을 완료 하였으니 가중치와 절편을 갱신해보도록 하자.     로지스틱 회귀의 가중치 갱신  로지스틱 회귀의 가중치를 갱신하기 위해 로지스틱 손실 함수를 가중치에 대해 미분한 식을 가중치에서 뺀다.  $w_i = w_i - \\frac{\\delta L}{\\delta w_i} = w_i + (y-a)x_i$   로지스틱 회귀의 절편 갱신  가중치 갱시과 유사한 방법으로  $b = b - \\frac{\\delta L}{\\delta b} = (y-a)1$      이전에 가중치, 절편 갱신을 위해 왜 로지스틱 손실함수에 가중치와 절편에 대해 미분해야 했는지 이유를 위의 갱신하는 방법에서 쓰이기 때문인것을 알 수 있다. -&gt; 로지스틱 손실함수에 대한 가중치와 절편의 변화율을 이용   이전 선형 회귀에서 경사하강법을 기억할 것이다. 그때 왜 가중치(w), 절편(b)의 변화율을 이용하여 절편과 가중치를 갱신하는 이유를 설명하였다.      위에서 설명한 이진 분류를 이젠 직접 데이터를 이용해 구현해볼 것이다.   유방암 데이터를 이용할 것인데 이 유방암 데이터에는 특징이 10개가 존재한다.  평균, 표준오차, 최대 이상치 등이 잇는데 이를 이용해 유방암 데이터 샘플이 악성 종양(True)인지 정상 종양(False) 인지 판단해 볼 것이다. (이진 분류)     # 유방암 데이터 세트를 준비한다. from sklearn.datasets import load_breast_cancer cancer = load_breast_cancer()   print(cancer) # cancer를 보면 처음에 입력 데이터, 두번째 0, 1로 타겟 데이터, 세번쨰는 뭐지??   {'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,         1.189e-01],        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,         8.902e-02],        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,         8.758e-02],        ...,        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,         7.820e-02],        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,         1.240e-01],        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,         7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'target_names': array(['malignant', 'benign'], dtype='&lt;U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',        'mean smoothness', 'mean compactness', 'mean concavity',        'mean concave points', 'mean symmetry', 'mean fractal dimension',        'radius error', 'texture error', 'perimeter error', 'area error',        'smoothness error', 'compactness error', 'concavity error',        'concave points error', 'symmetry error',        'fractal dimension error', 'worst radius', 'worst texture',        'worst perimeter', 'worst area', 'worst smoothness',        'worst compactness', 'worst concavity', 'worst concave points',        'worst symmetry', 'worst fractal dimension'], dtype='&lt;U23'), 'filename': '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/breast_cancer.csv'}   # 입력 데이터를 확인해 보자. print(cancer.data.shape, cancer.target.shape) #입력 데이터의 data 크기를 출력한다.  #569개 샘플있고 30개의 특성이 있음을 확인할 수 있다.   (569, 30) (569,)   cancer.data[:3] #샘플 3개만 봐보자   #특성들이 실수 범위에 양수값이네 정도만 알 수 있다.  #이전 선형 회귀 처럼 산점도로 나타내서 특성간의 관계에 대해 보고 싶은데... 이게 30개나 되니까 산점도로 표현하기는 힘들듯..   array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,         3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,         8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,         3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,         1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01],        [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,         8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,         3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,         1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,         1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02],        [1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,         1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,         4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,         2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,         1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]])   import matplotlib.pyplot as plt  plt.boxplot(cancer.data) plt.xlabel('feature') plt.ylabel('value') plt.show()   # 산점도로 나타내기 힘드니 박스플롯으로 나타내 보았다. (박스플롯은 나중에 설명)  # 박스 플롯을 보면 4, 14, 24번째 특성에 대한 value값이 다른 특성들보다 분포가 훨씬 넓게 퍼저있음을 알 수 있다. # -&gt; 왜 이런지 한번 알아보자       cancer.feature_names[[3, 13, 23]]  # 4, 14, 24번째 (인덱스는 0부터니 코드랑 햇갈리지 말길)의 특성을 보면 # area : 넓이와 관련된 것임을 알 수 있다.  # 아 ... 주어진 데이터에서 세포들의 넓이가 다양하나 보다..    array(['mean area', 'area error', 'worst area'], dtype='&lt;U23')   박스 플롯 :     image_reference : http://demo.riamore.net/HTML5demo/chart/Docs/User%20Manual%20-%20html/box-plot-chart.html       위 그림에서 하위 표본 퀀타일이 1사분위, 표본 미디언이 2사분위, 사위 표본 퀀타일이 3사분위로 보면 된다.   박스 플롯은 1사분위와 3사분위 값으로 상자를 그리고 그 안에 2사분위값을 나타낸다.   1사분위와 3사분위 사이의 거리의 1.5배만큼 위아래 거리를 그려놓은 것이다.     import numpy as np  np.unique(cancer.target, return_counts = True) #타깃 데이터 확인  # 0과 1로만 우리어져 있고 0은 음성클래스 1은 양성클래스를 나타냄  # numpy의 unique()함수는 고유한 값을 찾아 반환하는 것이고 # 이때 return_counts = True로 매개변수 지정을 하면 고유한 값이 얼만큼 있는지 횟수를 반환 한다.  # -&gt; 결과를 통해 음성클래스(정상 종양) 212개, 양성클래스(악성 종양) 357개가 있음을 알 수 있다.  print(357 / 212)  # 양성클래스 : 음성클래스 비율이 대충 1.7 : 1 로 확인된다. -&gt; 이 비율 기억해두길 !!!    1.6839622641509433   # 훈련 데이터 세트 저장 x = cancer.data y = cancer.target    이전에 선형 회귀로 뉴런 클래스 만든 것 기억해보면 훈련 데이터 세트를 주어진 데이터 전체를 이용하여 모델을 훈련했다.   사실 웃긴 일이다. 모든 데이터로 훈련을 하면 어떤 데이터로 모델이 잘 훈련 되었는지 알 수 있을까?   훈련 데이터로 다시 훈련이 잘 되었는지 검증하는 것은 ??   예전에 읽은 책 중에 “혼자 공부하는 머신러닝, 딥러닝”에서 한 예시가 기억이 난다.   어떤 사람에게 특정 과목에 대해 잘 알 수 있게 훈련 문제들로 훈련을 시키고 과연 잘 공부 되었는지 확인하기위해 시험을 보았는데 시험 문제로 이전의 훈련 문제들로 시험문제를 낸다면 ?   해당 과목의 전체적인 공부가 잘 되지 않았더라도 훈련 문제만을 기억해서 풀어 모두 맞출수도 있기 떄문에 훈련이 잘 되었는지 제대로 확인할 수 없다.   이 예시와 마찬가지로 훈련 데이터로 검증을 한다?? 정확한 검증을 할 수 없다.    그러면 훈련 데이터의 모든 데이터를 모델을 훈련 시키기 위한 훈련 세트와 모델이 잘 훈련이 되었는지 검증할 테스트 세트로 나누면 될 것이다.     이렇게 나눈 것을  훈련 세트(training set)  테스트 세트(test set)  라고 한다.      그런데 어떻게 나눌까?? 그냥 주어진 데이터 반으로 딱 나누면 안되나?   -&gt; 아니다 훈련 데이터 세트를 훈련 세트와 테스트 세트로 나누는 2가지 규칙이 존재한다.     훈련 데이터 세트를 훈련 세트와 테스트 세트로 나누는 규칙     훈련 데이터 세트를 나눌 때는 테스트 세트보다 훈련 세트가 많아야 함    훈련 데이터 세트를 나누기 전에 양성 클래스와 음성 클래스가 훈련 세트나 테스트 세트 한쪽에 몰려선 안된다. (편향이 있어선 안된다.)       이러한 규칙을 지키지 않ㅇ면 데이터에 있는 패턴을 제대로 학습하지 못하기 때문에 잘못된 측정을 할 수 있다.      하… 이런 규칙을 지키면서 데이터 나누기 너무 귀찮은데..   -&gt; 사이킷런의 도구를 이용하면 편ㄴ하다.     사이킷런을 이용해 훈련 데이터 세트를 훈련 세트와 테스트 세트로 나누어 보자.   # 사이킷런을 이용해 훈련 데이터 세트를 훈련세트와 테스트 세트로 나누어 보자 from sklearn.model_selection import train_test_split   # sklearn.model_selection 모듈에 있는 train_test_split() 함수는 기본적으로 입력된 훈련 데이터 세트를 훈련 세트를 75%, 테스트 세트를 25% 비율로 나눈다.    x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42)  # 매개 변수에 대해서 알아보면   # 1. stratify = y : # stratify는 훈련 데이터를 나눌 때 클래스 비율을 동일하게 하는 매개변수이다. # train_test_split은 default로 데이터를 나누기 전에 섞지만 일부 클래스 비율이 균형이 맞지 않은 경우에 stratifyfmf y로 지정해야 한다.  # 2. test_size = 0.2 : # train_test_split()함수는 default로 훈련 데이터 세트를 75 : 25 비율로 나눈다. # 하지만 test_size 매개변수를 이용하면 이 비율을 조절할 수 있다. # 이 예제처럼 test_size = 0.2로 하면 훈련 데이터 세트를 80 : 20 비율로 나눌 수 있다.  # 3. random_state = 42 : # train_test_split() 함수는 무작위로 데이터 세트를 섞은 다음 나누는데 (랜덤하게),  # 이때 random_state는 rando seed를 세팅한다. # 랜덤 값은 사실 엄격한 랜덤값이 아니다.  # 어떤 특정한 시작 숫자를 정해 주면 컴퓨터가 정해진 알고리즘에 의해 마치 난수처럼 보이는 수열을 생성한다.  # 이런 시작 숫자를 시드(seed)라고 한다. # 예제와 같이 random_state = 42로 난수 초기값을 지정해 두면 데이터 세트를 섞는 결과가 항상 일정하게 나타난다.     # 훈련 데이터 세트가 잘 나누어졌는지 훈련 세트와 테스트 세트의 비율을 확인해 보자 print(x_train.shape, x_test.shape)  print(455 / 114)  # 결과를 확인해 보니 훈련 세트와 테스트 세트 80 : 20 비율로 잘 나누어져 있는것을 확인할 수 있다.   (455, 30) (114, 30) 3.991228070175439   # numpy의 unique()함수를 이용해서 훈련 세트의 타깃 안에 있는 클래스의 갯수를 확인해 보자.  np.unique(y_train, return_counts = True)  print(285 / 170)   #  확인해보니 전체 훈련 데이터 세트의 클래스 비율과 거의 비슷한 것을 알 수 있다. #  -&gt; 양성클래스 : 음성클래스 비율이 약 1.7 : 1 정도 됨   #  이전에 훈련 데이터를 나누기전에 양성클래스 : 음성클래스 비율을 기억해두라 한 적이 있다. 그 이유가 그때도 비율이 약 1.7 : 1 #  정도 였는데 train_test_split()함수가 훈련 데이터 세트를 훈련 세트와 테스트 세트로 나누는 규칙인 훈련 중 #  훈련 데이터 세트를 나누기 전에 양성, 음성 클래스가 훈련 세트나 테슽 ㅡ세트의 어느 한쪽에 몰리지 않도록 골고루 섞어야 한다는 규칙을  #  잘 지킨 것으로 확인된다.    1.6764705882352942   # 지금까지 배운 로지스틱 회귀를 이 데이터로 구현해보자  class LogisticNeuron:      def __init__(self):     self.w = None     self.b = None      # -&gt; 생성자에서 특이한점은 가중치와 절편을 미리 초기화 하지 않는다는 점이다.     # 그 이유는 입력 데이터의 특성 갯수를 알지 못하므로      # 가중치를 입력데이터가 들어오고 난 후 특성 개수에 맞게 결정    def forpass(self, x): # 선형 방정식 계산 (로지스틱 회귀에서 데이터가 정방향으로 흘러가는 과정)     z = np.sum(x * self.w) + self.b     return z    def backprop(self, x, err): # 역방향 계산 (가중치와 절편을 업데이트 하기 위해 데이터가 역방향으로 흘러가는 과정)     w_grad = x * err # 가중치에 대한 gradient 계산     b_grad = 1 * err # 절편에 대한 gradeint 계산      return w_grad, b_grad  # 훈련하는 메서드를 구현해보자  # 훈련 수행하는 fit() 메서드를 만들 것인데 이전 선형 회귀에서 구현한 Neuron 클래스에서 만든 함수와 같다 # 하지만 차이점으로는 activation()메서드가 추가되었음 -&gt; 당연 선형회귀와 로지스틱회귀의 차이점을 생각하면 알 수 있음    def fit(self, x, y, epochs = 100):     self.w = np.ones(x.shape[1]) #가중치를 초기화 한다. np.ones()함수를 이용해 1로 초기화     self.b = 0 #절편을 0으로 초기화      for i in range (epochs): # epochs만큼 반복       for x_i, y_i in zip(x, y):          z = self.forpass(x_i) # 선형함수식에 대입하여 z 구함          a = self.activation(z) # z를 활성화 함수에 대입하여 a 구함          err = -(y_i - a) # 오차를 계산함          w_grad, b_grad = self.backprop(x_i, err) # 역방향 계산으로 가중치 gradient와 절편 gradient 구함          self.w -= w_grad  # 가중치를 갱신한다.         self.b -= b_grad # 절편을 갱신한다.  # activation() 메서드를 만들어보자 # 로지스틱 회귀에서 사용할 활성화 함수는 시그모이드 함수이다. 따라서 시그모이드 함수를 구현하면 된다.    def activation(self, z):     a = 1 / (1 + np.exp(-z))      return a  # 예측값을 구해보자 (y_hat 구하기)  # 이전 선형 회귀 Neuron 클래스 구현에서 새로운 샘플에 대한 예측값 구할때 forpass() 메서드 사용했던것 기억할 것이다. # 근데 만약 에측해 볼 샘플이 많다면 forpass()메서드를 계속 호출해야하는 귀찮은 일이 생긴다. # 거기다가 로지스틱 회귀에서는 활성화 함수와 임계 함수까지 추가되니 어휴... 정말 귀찮다.  # -&gt; 이러한 문제를 해결해줄 predict()메서드를 만들어 보자 # 샘플에 대한 예측값을 계산해주는 predict() 메서드를 만들어 보자    def predict(self, x):     z = [self.forpass(x_i) for x_i in x] # 리스트 컴프리헨션으로 반복문으로 여러 샘플을 선형 함수에 대입 후 그 결과를 리스트에 저장      a = self.activation(np.array(z)) # 활성화 함수에 z 리스트 값 대입      return a &gt; 0.5 # 계단 함수를 적용 함!!!!  # predict()메서드의 매개변수 값으로 입력값 x가 2차원 배열로 전달 되었다고 가정하겠음 # -&gt; 매개변수 x에 이전에 만들어둔 x_train이 들어올 것인데 # x_train.shape = (455, 30) 즉 샘플 455개인데 각 샘플당 특성이 30개인 데이터 이므로 # 2차원 배열로 이루어 져 있을 것이다.[[샘플1], [샘플 2], [샘플 3], [] ~~~ ] (각 샘플당 30개의 특성) # ex) 샘플 1 = [1, 2, ~~~ , 30] (꼭 숫자가 1, 2, 3 ~~ 이 아니라 갯수를 나타낸 것임)    # 로지스틱 회귀 모델을 훈련시켜 보자  # 모델을 훈련해보자 neuron = LogisticNeuron() # LogisticNeuron에 대한 객체를 만듬 (객체를 모델이라고 부르기도 함) neuron.fit(x_train, y_train) # 이전에 만들어둔 훈련 세트로 (입력, 타깃 훈련 세트) 모델 훈련시키기   /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: RuntimeWarning: overflow encountered in exp   # 테스트 세트 사용해서 모델의 정확도를 평가해 보자  np.mean(neuron.predict(x_test) == y_test)  # predict() 메서드의 반환값은 Ture 혹은 False가 원소인 (m, ) 크기의 배열 # y_test는 0 또는 1이 원소인 (m, ) 크기의 배열이기 때문에 비교 가능  # np.mean() 함수 : 매개변수 값으로 전달한 비교문 결과의 평균값을 계산하여 반환 -&gt; 이것을 정확도(accuracy)라고 한다.   /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: RuntimeWarning: overflow encountered in exp      0.8245614035087719   지금까지 로지스틱 회귀에 대해 직접 구현해 보았다.   사실 지금 구현한 로지스틱 회귀 뉴런이 단일층 신경망이다.   구체적인 내용(층에 대한 내용 등등)은 이후에 설명해 볼 것이다.   또한 로지스틱 회귀를 구현하는데 생각보다 귀찮은데 이 부분 또한 사이킷런에서 제공하는 클래스를 이용하면 편리하다.   이 부분도 이후에 설명할 것이다.     Reference    박해선, 딥러닝 입문, 이지스퍼블리싱, 2019, 76~104pg   ","categories": ["Deep_Learning"],
        "tags": ["로지스틱 회귀","퍼셉트론","아달린","계단함수","활성화 함수","로지스틱 손실함수","미분 연쇄 법칙"],
        "url": "/deep_learning/Binary_Classification/",
        "teaser": null
      },{
        "title": "MySQL을 시작하면서..",
        "excerpt":"처음 MySQL을 배우려고 하는 이유는 백엔드든 AI든 데이터를 이용하고, 데이터를 전처리하고 가공할 줄 알아야 한다고 전해 들었기 때문이다.   많은 RDBMS 중 왜 하필 MySQL을 배우는지는 그냥 단순히 예전부터 많이 가장 많이 들어왔고 그렇기 때문에 가장 많이 쓰이지 않을까 해서이다..     MySQL을 배우기 이전에 MySQL이 뭔지?? 또 더 이전에 데이터베이스와 데이터베이스를 관리하는 DBMS에 대해 알아가면서 자연스럽게 MySQL에 대해 알아보려 한다.       데이터베이스(DB) :  데이터의 집합을 의미하며, 데이터의 저장공간 자체를 의미하기도 한다. 특히 MySQL에서는 데이터베이스를 자료가 저장되는 디스크 공간 (주로 파일로 구성되어 있는)으로 취급한다.     DBMS(DataBase Management System) :  데이터베이스를 관리, 운영하는 역할을 하는 소프트웨어의 개념   또한 여러명이 사용자나 응용 프로그램이 DBMS가 관리하는 데이터에 동시에 접속하고 데이터를 공유하게 되므로 DBMS에서 데이터가 집중적으로 관리되고 있을 것이다.   MySQL이 대표적인 DBMS 중 하나로   MySQL, MariaDB, Oracle, SQLite 등등 여러 회사의 DBMS 제품이 있다.     데이터베이스(DB) 와 DBMS의 특징   1. 데이터의 무결성 :  DB 안의 데이터는 어떤 경로를 통해 저장되었던 간에 데이터에 오류가 있어서는 안된다.   이러한 무결성의 특징을 지키기 위해 DB는 제약 조건(Constraint)이라는 특성을 가진다.     2. 데이터의 독립성 :  DB의 크기를 변경 혹은 데이터 파일의 저장소를 변경하더라도 기존에 작성된 응용프로그램에는 절대 영향을 끼쳐서는 안된다.   즉 서로 독립적인 관계여야 한다. (의존적 X)     3. 보안 :  DB안의 데이터에 아무나 접근할 수 있는 것이 아니라 데이ㅓ를 소유한 사람이거나 데이터에 접근 허가된 사람만 접근할 수 있어야 한다.   또한 사용자의 계정에 따라 다른 권한을 가짐!!     4. 데이터 중복의 최소화 :  동일한 데이터가 여러개 중복되어서 저장되면 안된다.     5. 응용 프로그램 제작 및 수정이 쉬움 :  기존에 존재하는 파일시스템을 사용할 때 각각 파일의 포매셍 맞춰 개발해야하는 응용 프로그램을 DB를 이용하면 통일된 방식으로 응용 프로그램 작성이 가능해지게 된다. 따라서 유지보수가 쉬워진다.   6. 데이터의 안정성 향상 :  대부분 DBMS가 제공하는 백업, 복원 기능을 제공하기 때문에 데이터에 문제가 생겼을 경우 복원 복구할 수 있다.       DBMS 유형 :  DBMS의 유형은 여러가지가 존재한다. 우리가 배울 MySQL은 어떤 한 유형의 DBMS에서 쓰인다.   1. 계층형 DBMS (Hierarchical DBMS) :  각 계층이 트리 형태를 가지며 1:N 관계를 가진다. ex)  노드 1   노드 1 밑에 노드 2-1 노드 2-2가 연결되어 잇고  노드 2-1 밑에 노드 3-1, 노드 3-2가 연결되어 밑에 있고 ~~~~       이 구조의 장점은   1) 주어진 상태에서 검색이 상당히 빠르다.      이러한 구조는 엄청난 단점이 존재한다.   1) 구조를 변경하기 어렵다.   2) 접근의 유연성이 떨어진다. -&gt; 따라서 임의의 검색에 어려움이 있다.     2. 망형 DBMS (Network DBMS) :  계층형 DBMS의 단점을 개선하기 위해 생겨난 구조로 1:1, 1:N, N:M 관계가 존재하여 효과적이고 빠른 데이터 추출이 가능해졌다.    ex)  계층형 DBMS 구조에서 같은 층의 노드끼리도 연결이 되어 있거나, 노드 3-2가 노드 2-1과 연결되어 있을 뿐 아니라 노드 2-2 와도 연결 될 수 있는 구조이다.   이 뿐만 아니라 이전에 설명한 1:1, 1:N, N:M 구조도 모두 가능      하지만 단점이 아직 존재하는데.   계층형 DBMS와 마찬가지로 매우 복잡한 내부 포인터를 사용하고 있어 프로그래머가 이 모든 구조를 이해해야만이 프로그램의 작성이 가능하다. (1:1, 1:N, N:M 등 여러 관계가 가능하다 보니 계층형 구조보다 더 복잡함)        3. 관계형 DBMS(Relational DBMS) RDBMS :  데이터베이스를 테이블(table)이라고 불리는 최소 단위로 구성   테이블은 하나 이상의 열로 구성 되어있음!!     RDBMS는 모든 데이터는 테이블에 저장되므로 테이블이라는 구조가 가장 기본적이고 중요한 구성이다!!       왜 테이블로 데이터를 저장하려 했을까?? -&gt; 데이터를 효율적으로 저장할 수 있는 구조이기 때문이다.   데이터를 저장할때 여러 테이블을 나누어 저장하여 불필요한 공간 낭비 줄일 수 있고, 데이터 저장의 효율성을 높이기 때문이다.     위의 장점 뿐 아니라 RDBMS는 다른 유형의 DBMS에 비해 변화에 순응할 수 있으며, 유지보수에도 편리한 특징을 가지고 있다.   또한 이전에 설명한 DB와 DBMS의 특징인 무결성을 잘 보장해 주기 때문에 동시에 데이터에 접근하는 응용프로그램 사용시 RDBMS를 사용하는 것이 좋을 가능성이 크다.      물론 장점만 있는것은 아니다..   단점 으로느 시스템 자원을 많이 차지해서 시스템 속도가 전반적으로 느려진다.     속도가 정말 중요한 사회에서 너무 큰 단점 아닌가??   다행이도 하드웨어의 발전으로 인해 이 단점을 매꾸어 줄 정도로 하드웨어 성능으로 속도를 많이 보완 하였다.      다른 유형은 DBMS와 다르게 RDBMS의 장점을 많이 나타냈고, 단점 또한 그렇게 심하게 표현하지 않은것으로 보아 우리가 배울 MySQL이 RDBMS 이다..      이제 DB, DBMS에 대해 어느정도 알겠는데.. 그런데 도대체 SQL이 뭐지 ?   SQL(Structed Query Language) :  Language에서 알 수 있듯 언어이다.   이전에 MySQL이 RDBMS 중 하나라고 설명하였다.   즉 SQL이 RDBMS에 쓰이는 언어임을 유추해 볼 수 있을 것이다.   다시 SQL은 관계형 데이터베이스에서 사용되는 언어이다.   즉 RDBMS를 배우기 위해 SQL을 알아야 한다.       여기서 헷갈리는 점이 SQL은 RDBMS에 쓰이는 언어이고   MySQL은 RDMBS 중 하나이면 MySQL은 SQL 중 하나가 아니네??   -&gt; 맞다.. MySQL은 RDBMS 제품 중 하나의 이름일 뿐이다..   MySQL은 RDBMS이므로 MySQL에서 SQL을 사용하겠네… 라고 이해 하면 된다.      SQL의 특징   1. DBMS 제작 회사와 독립적  이전에 RDBMS 제품이 MySQL, MariaDB, Oracle등 다양하다고 하였다. 그런데 RDBMS에서 사용된는 언어인 SQL이 여러 제작 회사에 따라 다르다면 어휴… 회사 제품(RDBMS)마다 적합한 SQL을 공부해야하니 생각만해도 끔찍하다..   다행이도 SQL은 표준 SQL이 존재하고 각 제작회사들은 이 표준 SQL에 맞춰서 RDBMS를 만든다. (물론 그.. 제품마다 다른 명령어(언어) 등이 존재하긴 한다.)     2. 다른 시스템으로 이식성이 좋음  SQL은 서버, 개인, 휴대용 장비에 운영되는 DBMS마다 상호 호환성이 뛰어나기 때문에 다른 시스템으로의 이식성이 좋다.     3. 표준이 계속 발전  SQL 표준이 계속적으로 개선되고 발전되고 있다.   ex) SQL-86, SQL-92, SQL:1999, SQL:2019 등등    4. 대화식 언어이다.  주피터 노트북으로 파이썬 언어를 작성해 보았으면 알 것이다.   기존 프로그래밍 언어처럼 코드 작성하고 컴파일, 디버깅 실행 과정 거쳐서 결과를 확인할 수 있는것과 달리 바로바로 코드 한줄 한줄 바로 결과를 확인할 수 있다는 장점이 있다.   SQL도 이러한 장점이 있는 바로 질의하고 결과를 얻는 대화식 언어이다.    5. 분산형 클라이언트 / 서버 구조  SQL은 분산형 구조인 클라이언트 / 서버 구조를 지원한다.   클라이언트 / 서버 구조란 클라이언트에서 질의를 하면 서버에서 질의를 받아서 처리하고 그에 대한 대답을 클라언트에게 전달하는 구조이다.      주의 !!!   이전에 설명하듯 표준 SQL이 존재하지만 제조사별로 각자의 RDBMS에서 SQL이 동일하지 않은 경우가 있다.       마지막으로 앞으로 배울 MySQL의 특징에 대해 알아보자.  MySQL :  Oracle사에서 제작한 RDBMS로 오픈 소스로 제공된다. (무료라는 말 ㅎㅎ) -&gt; 이게 장점 중 하나임    MySQL의 또다른 장점으로는 특히 대용량 데이터베이스 운영하기 위한 기술들이 많이 포함되어 있다는 것이다.   Reference    우재남, 이것이 MySQL이다, 한빛미디어, 2020, 1~17pg  ","categories": ["MySQL"],
        "tags": ["SQL","DBMS","RDBMS"],
        "url": "/mysql/MySQL_start/",
        "teaser": null
      },{
        "title": "순수 자바로만 작성하는 예제_회원 도메인 개발",
        "excerpt":"Spring이 왜 생기게 되었는지 알기위해  순수한 자바코드로  예제를 작성해보며 Spring의 필요성을 느껴보고자 한다.       사용할 IDE : IntelliJ     프로젝트 생성 : start.spring.io에서  Project : Gradle Project   Spring Boot : 2.5.4  Language : Java  Packaging : Jar  Dependencies : 선택 X     아니 순수 자바코드로만 작성한다 해놓고 왜 스프링 부트 스타터로 프로젝트 생성 ??   -&gt; 단순히 프로젝트 환경설정을 편리하게 설정하기 위해서 임, Dependencies 아무것도 설정 안했으니 Spring boot가 core 쪽 library만을 가지고 project 만든다.      예제는 특정 상황을 가정할 것이다.   비즈니스 요구사항이 주어질 것이고 그 요구사항에 맞게 설계를 할 것이다.  처음에는 순수 자바코드로 작성할 것임 !!     요구 사항 :  회원 :     회원가입을하고 해당 회원을 조회할 수 있음    회원은 2가지 등급이 존재  (1) 일반 등급, (2) VIP 등급     회원 데이터는 자체 DB를 구축할 수도 있고 외부 시스템과 연동할 수도 있음 -&gt; 미확정인 상태임 !!!   주문과 할인 정책 :     회원가입을 한 회원은 상품을 주문할 수 있음    회원은 등급에 따라서 할인 정책을 적용받을 수 있음     할인 정책은 모든 VIP등급의 회원들에게 1000원을 할인해 주는 고정 금액 할인을 적용해 달라는 요구가 있음 (나중에 변경될 수 있음)     할인 정책은 변경가능성이 높기 때문에 (아직 기본 할인 정책을 회사에서 정하지 못함), 오픈 직전까지 이 고민을 미루려고 함    혹은 할인을 적용 안할수도 있음      ### 요구 사항에서 약간 골치아픈 문제가 2개이다.       회원 데이터에 대한 부분이 아직 미확정인 상태     할인정책이 변경가능성이 크고 적용 안할 가능성 또한 있음       이러한 문제점이 있다고 해서 정책이 확실히 결정되기 까지 해당 부분 개발을 하지않고 기다릴 수는 없다. &lt;br. 그럼 어떻게 해결 해야할까??      이전에 객체 지향 설계 방법의 장점을 기억할 것이다.   역할과 구현을 나누면 (인터페이스와 구현 객체 생각!!) -&gt; 유연하고 변경이 용이해짐   즉 인터페이스를 만들고 구현체를 얼마든지 갈아끼울 수 있도록 설계하면 됨        설계를 시작해보자   먼저 도메인을 설계 해보자.   회원 도메인 설계   회원 도메인 요구 사항     회원가입 할 수 있고 회원가입한 회원을 조회할 수 있음     회원은 일반과 VIP 두 가지 등급 존재     회원 데이터는 자체 DB를 구축 할 수 잇고 외부 시스템과 연동할 수도 있다. (미확정인 상태)     회원 도메인 협력 관계     여기서 클라이언트, 회원 서비스, 회원 저장소 3개는 역할   회원 데이터를 어떻게 저장하지 아직 확실히 정하지 않았으니   일단 먼저 DB를 구축하기 전에 기본적인 메모리 회원 저장소를 구현하고   차 후에 DB 회원 저장소, 외부 시스템 연동 회원 저장소를 구현 하려 한다.  즉 회원 저장소 역할의 구현으로 메모리 회원 저장소, DB 회원 저장소, 외부 시스템 회원 저장소 3가지를 구현하고자 한다.      회원 클래스 다이어그램     회원 도메인 협력 관게를 클래스로 나타내보면 회원 클래스 다이어그램과 같다.   각 역할들을 interface로, 역할들에 대한 구체적인 구현을 인터페이스에 상속받은 클래스로 구현하였다.     간단히 정리하자면   인터페이스 : 역할   상속받은 다른 클래스 : 구현     인터페이스는 메서드 선언만 하고   상속 받은 다른 클래스는 implements 상속으로 메서드 정의 (메서드 오버라이딩)     MemoryMemberRepository 클래스 경우 일단 간단한 메모리 저장하는 역할을 하는 클래스를 정의 하였고   DbMembeerRepository 클래스 경우 자체 DB 구축 에 대해서 정의할 클래스이다. (DB 부분은 차후에 정의할 것)       이렇게 역활과 구현을 분리해 두면 유연하고 변경이 용이해 지기 때문에 이전에 비즈니스 요구사항 중 회원 데이터 부분이 아직 미확정 이라고 하였는데 나중에 변경이 일어나도 유연하게 대처가 가능해진다.      회원 객체 다이어 그램       클래스 다이어그램에서 정의한 클래스를 이용해 객체를 만들어 객체간의 참조 구조를 작성해보면 위와 같다.      회원 서비스 경우에는 new MemberServiceImpl(); 을 통해    메모리 회원 저장소경우에는 new MemoryMemberRepository();를 통해    객체를 생성하고자 한다.       회원 도메인 구조를 기준으로 코드로 작성해보도록 하자.     코드 작성에 앞서 패키지 이름은 spring_basic이다.   코드 윗부분에 패키지, 클래스 명을 보면 파일 구조를 파악할 수 있을 것이다.     마지막 부분에 전체적인 파일 구조를 정리하도록 하겠다.     Gradle 전체설정  build.gradle  plugins { \tid 'org.springframework.boot' version '2.5.4' \tid 'io.spring.dependency-management' version '1.0.11.RELEASE' \tid 'java' }  group = 'hello' version = '0.0.1-SNAPSHOT' sourceCompatibility = '11'  repositories { \tmavenCentral() }  dependencies { \timplementation 'org.springframework.boot:spring-boot-starter' \ttestImplementation 'org.springframework.boot:spring-boot-starter-test' }  test { \tuseJUnitPlatform() }   회원 엔티티에 대해 작성해 보자     회원 등급   package hello.spring_basic.member;  public enum Grade { //Enum으로  회원의 등급 설정     BASIC,     VIP }  //Enum class는 열거형이라 불리며 서로 연관된 상수들의 집합을 의미 //(기존 상수를 정의하던 final static string과 같이 문자열이나 숫자들을 나타낸는 기본자료형의 값을 enum 이용해서 나타낼 수 있음)   회원 엔티티   package hello.spring_basic.member;  public class Member { //회원 entity에 대한 클래스를 만듬     private Long id;     private String name;     private Grade grade;      public Member(Long id, String name, Grade grade) {         this.id = id;         this.name = name;         this.grade = grade;     }      public Long getId() {         return id;     }      public void setId(Long id) {         this.id = id;     }      public String getName() {         return name;     }      public void setName(String name) {         this.name = name;     }      public Grade getGrade() {         return grade;     }      public void setGrade(Grade grade) {         this.grade = grade;     } }    회윈 저장소에 대해 작성해 보자   회원 저장소 인터페이스  package hello.spring_basic.member;  public interface MemberRepository {  //인터페이스     void save (Member member); // 회원을 저장하는 메서드      Member findById(Long memberId); //회원의 아이디로 회원을 찾는 메서드 }   메모리 회원 저장소 구현체  package hello.spring_basic.member;  import java.util.HashMap; import java.util.Map;  public class MemoryMemberRepository implements MemberRepository {     //implements : 부모 객체는 선언만 하며 정의(내용)은 자식에서 오버라이딩 해서 사      private static Map&lt;Long, Member&gt; store = new HashMap&lt;&gt;(); // 데이터 저장하기 위해 해시맵에 데이터 저장      // HashMap은 사실 동시성 문제가 발생할 수 있으므로 그런 경우에는 ConcurrentHashMap 사용하면 된다.       @Override     public void save(Member member) {         store.put(member.getId(), member);     } //회원 저장하는 메서드 정의      @Override     public Member findById(Long memberId) {         return store.get(memberId);     } //회원 ID로 회원 찾는 메서드 정의          //인터페이스에서 선언한 메서드를 구체적으로 메서드 정의 -&gt; 구현 }     DB가 아직 확정이 되지 않았음. 하지만 그렇다고 개발을 안할수는 없음.   -&gt; 개발은 진행하되 단순한 메모리 회원 저장소(단순히 해시맵에 저장하여 구현)를 구현해서 개발 진행할 것      회원 서비스에 대해 작성해 보자.   회원 서비스 인터페이스   package hello.spring_basic.member;  public interface MemberService {      void join (Member member); //회원 가입 메서드 선언      Member findMember(Long memberId); // 회원 조회 메서드 선언 }    회원 서비스 구현체   package hello.spring_basic.member;  public class MemberServiceImpl implements MemberService {      private final MemberRepository memberRepository = new MemoryMemberRepository(); // 회원 가입 메서드 정의      @Override     public void join(Member member) {         memberRepository.save(member);         /*         save메서드 호출시 다형성에 의해 인터페이스인 MemberRepository클래스가 아닌 MemoryMemberRepository 클래스에 있는 save함수를 호출한다.         */     }      @Override     public Member findMember(Long memberId) {         return memberRepository.findById(memberId);     } // 회원 조회 메서드 정의          // 인터페이스에서 선언한 메서드를 구체적으로 메서드 정의 -&gt; 구현 }        자 이제 회원 도메인 개발을 해 보았으니 제대로 작동하는지 테스트를 해보자.       회원 도메인 실행과 테스트를 해보자.   회원 도메인 - 회원 가입 main  main 함수를 만들어 직접 회원을 만들어 회원가입 시키고 회원가입이 되었는지 확인해보자.     package hello.spring_basic;  import hello.spring_basic.member.Grade; import hello.spring_basic.member.Member; import hello.spring_basic.member.MemberService; import hello.spring_basic.member.MemberServiceImpl;  public class MemberApp {      public static void main(String[] args) {         MemberService memberService = new MemberServiceImpl(); // MemberService의 객체 memberservice 생성 (MemberServiceImpl 구현 가지는)         Member member = new Member(1L, \"memberA\", Grade.VIP);// 새로운 Member의 객체 member 생성         //이름은 memberA, 등급은 VIP          memberService.join(member); // 새로운 member를 등록 (회원가입)          Member findMember = memberService.findMember(1L);//위 사람이 제대로 등록(회원 가입) 되었는지 확인해보자.          System.out.println(\"new member = \" + member.getName());         System.out.println(\"find Member = \" + findMember.getName()); //회원가입이 잘 되었다면 member.getName()과 findMember.getName()이 같은 출력을 내놓아야야          //똑같은 \"memberA\"를 출력함     } }    main 함수를 실행시켜보면        위 그림과 같이 문제없이 잘 실행이 된다.      하지만 이러한 방법으로 테스트 하는 것은 좋지 않은 방법이다.   (애플리케이션 로직으로 위의 방식으로 테스트 하는 방법)      -&gt; JUnit 테스트를 이용한다  JUnit은 자바 프로그래밍 언어용 유닛 테스트 프레임워크로   @Test 메서드가 호출되면 독립적인 테스트가 가능하다. -&gt; 어노테이션으로 편리하게 테스트 가능        회원 도메인 - 회원 가입 테스트   package hello.spring_basic.member;  import org.assertj.core.api.Assertions; import org.junit.jupiter.api.Test;  public class MemberServiceTest {      MemberService memberService = new MemberServiceImpl();      @Test     void join() {         //given : 이런 이런 환경 주어졌을때         Member member = new Member(1L, \"memberA\", Grade.VIP);          //when : 이렇게 했을때         memberService.join(member);         Member findMember = memberService.findMember(1L);          //then : 이렇게 된다. -&gt; 검증         Assertions.assertThat(member).isEqualTo(findMember);          //정리하면 새로운 member가 주어졌을때         // 그 새로운 멤버를 회원가입(등록) 했을때         // member와 findMember가 같아야 한다.     } }   test 코드를 작성하는 팁으로 대부분 위에서 적어둔 given, when, then 방식이 잘 맞아 떨어진다고 한다. (모두 그런것은 아님)       MemberServiceTest 클래스를 실행시켜보면     위 그림에서 아무 문제없다는 결과를 내 놓는다.       지금까지 회원 도메인을 설계하여 실행해보고 테스트 또한 해보았는데 아무 문제없이 실행되었던 것 같다.   실행이 잘 되었다고 설계에 있어서 문제점은 없었을까?     회원 도메인 설계의 문제점 :  MemberServiceImpl 클래스를 보면     public class MemberServiceImpl implements MemberService {      private final MemberRepository memberRepository = new MemoryMemberRepository();       ~~~  위 코드를 보면   memberRepository는 interface인 MemebrRepository에 의존하고 있다.   그런데 memberRepository = new MemoryMemberRepository(); 이 코드를 보면   실제 할당하는 부분이 구현체에 의존하고 있음을 알 수 있다. (MemoryMemberRepository는 구현체)     따라서 MemberServiceImpl 클래스는 추상화와 구체화 모두에 의존하고 있다.   -&gt; DIP를 위반하고 있다는 의미이다. 즉 OCP 원칙을 지키지 못한 상황이다.   -&gt; 이 문제를 잘 기억하고 있다가 나중에 어떻게 해결하는지 알아보도록 하자.       Reference :  김영한 강사님 ㅅ프링 핵심 원리 - 기본편  강의 중  ","categories": ["Spring"],
        "tags": ["순수 자바 코드로 개발","회원 도메인","실행과 테스트"],
        "url": "/spring/spring_basic(2)/",
        "teaser": null
      },{
        "title": "단일층 신경망과 사이킷런으로 로지스틱 회귀 수행",
        "excerpt":"이전에 로지스틱 회귀를 직접 구현해 보았다.   로지스틱 회귀이 단일 신경층 망(single layer neural network) 동일하다고 한다.   신경망??? 단일층 ??? 이부분에 대해 좀더 자세히 알아보고,   또한 이 단일 신경층 망 즉 로지스틱 회귀를 구현하는 것이 귀찮기 때문에 사이킷 런으로 간편하게 로지스틱 회귀를 수행해 보자       신경망(Neural Network) :       위 그림을 보면 일반적인 신경망의 구조로 가장 왼쪽에 입력층(input layer), 가장 오른쪽이 출력층(output layer), 그리고 가운데 층들을 은닉층(hidden layer)라 부른다. 또한 작은 원으로 표시된 활성화 함수는 은닉층과 출력층의 한부분에 속한다.      그럼면 이전에 로지스틱 회귀는 단일층 신경망과 같다고 하였는데 단일층 신경망에 대해 알아보자.     단일층 신경망(Single Layer Neural Network) :  단일층 신경망은 일반적인 신경망의 구조에서 은닉층이 없는 신경망 즉 입력층과 출력층만 가지는 신경망을 의미한다.   로지스틱 회귀는 이러한 특징을 가지는 단일층 신경망이다.          지금부터 단일층 신경망을 구현해보고자 한다.   로지스틱 회귀가 단일층 신경망이라며 그러면 이전에 구현한 로지스틱 회귀가 단일층 신경망 구현한것 아님 ???   맞는데 다시 구현하려는 이유가 몇가지 유용한 기능 추가하기 위해서이다.  대표적으로 선형 회귀나 로지스틱 회귀 모두 경사 하강법을 사용했는데 이 방법은 손실함수의 결괏값을 최소화 하는 방향으로 가중치, 절편을 업데이트 하엿다.   선형 회귀 경우 손실 함수로 제곱 오차 손실 함수를,   로지스틱 회귀 경우 손실 함수로 로지스틱 손실 함수를 사용했었다.     만약 손실 함수의 결괏값이 줄어들지 않는다면 어떠한 문제가 있다는 것인데 그 결괏값이 줄어들고 있는지 확인하기 위한 기능을 추가할 것이다.   그럼 코드로 구현해 보자.   # 손실 함수의 결괏값 저장하는 기능을 추가하자  # 먼저 이전에 구현한 로지스틱 회귀 LogisticNeuron 클래스를 그대로 복사 후 클래스 이름을 SingleLayer로 바꾸자 # 여기에 수정 및 새로운 기능을 추가할 것이다.  # 기존 LogisticNeuron 클래스의 # __init__() 메서드에 self.losses 리스트를 만들어서 손실 함수의 결괏값을 저장할 것임  # 각 샘플마다 손실 함수를 계산하고 그 결괏값을 모두 더한 후 샘플 개수로 나눈 평균값을 구할 것임 # 그 평균값을 self.losses에 저장할 것임 # 그리고 self.activation() 메서드로 계산한 a를 np.log()계산을 위해 np.clip()을 적용할 것이다. # 이게 무슨말 ?? # a가 만약 0에 가까워지게 되면 np.log() 값은 음의 무한대로 가게 되고 a가 1에 가까워 지면 np.log() 값은 # 0에 수렴한다. 따라서 손실값이 무한해지면 정확한 계산히 힘들어지기 때문에 a의 값의 범위를 조절하고 싶다. # 이때 np.clip()을 이용하면 된다. # 여기에선 np.clip(a, 1e - 10, 1 - 1e - 10)을 적용하여 a의 값이 # -1 x 10^(-10) ~ 1 - 1 x 10^(10) 사이가 되도록 조절한다. # np.clip()은 주어진 범위 밖의 값을 잘라 내어 이러한 기능을 구현한다.   import numpy as np from math import *  class SingleLayer:      def __init__(self):     self.w = None     self.b = None      self.losses = [] # 손실 함수의 결괏값을 저장할 리스트    def forpass(self, x):      z = np.sum(x * self.w) + self.b     return z    def backprop(self, x, err):      w_grad = x * err     b_grad = 1 * err       return w_grad, b_grad      def activation(self, z):     z = np.clip(z, -100, None) # 안전한 np.exp() 계산을 위해 클리핑한다.     a = 1 / (1 + np.exp(-z))      return a    def fit(self, x, y, epochs = 100):     self.w = np.ones(x.shape[1])      self.b = 0      for i in range (epochs):       loss = 0       indexes = np.random.permutation(np.arange(len(x))) # indexes를 섞음        # ** np.random.permutation()을 써서 왜 indexes를 굳이 섞지??? 이부분에 대해서는 아래에 설명하겠다.        for i in indexes:         z = self.forpass(x[i])         a = self.activation(z)          err = -(y[i] - a)          w_grad, b_grad = self.backprop(x[i], err)           self.w -= w_grad           self.b -= b_grad           a = np.clip(a, 1e-10, 1 - 1e-10) # 안전한 로그 계산을 위해 클리핑한 후 손실을 누적함          loss += -(y[i] * np.log(a) + (1 - y[i]) * np.log(1 - a)) # 에포크 마다 평균 손실을 구함              self.losses.append(loss/len(y)) # 구한 손실을 losses에 저장    def predict(self, x):     z = [self.forpass(x_i) for x_i in x]     return np.array(z) &gt; 0 # 계단 함수 적용      def score(self, x, y):     return np.mean(self.predict(x) == y)  # 위에 score() 메서드를 추가하고 predict() 메서드를 기존의 LogisticNeuron 클래스에서 수정을 하였다.  # 시그모이드 함수의 출력값이 0 ~ 1 사이 이므로 이것을 확률값으로 보고 # 양성 클래스를 판단하는 기준이 0.5 이상이다. # z가 0보다 크게 되면 시그모이드 함수의 출력값이 0.5보다 커지고 # z가 0보다 작으면 시그모이드 함수의 출력값은 0.5보다 작다.  # 따라서 predict() 메서드에 굳이 시그모이드 함수를 사용하지 않고 z값이 0보다 큰지 작은지만 판단하면 된다.  # 그래서 predict() 메서드를 굳이 로지스틱 함수 적용 안하고 z 값 크기로 비교하여 결과 반환함.   위 SingleLayer 클래스를 구현할 때 왜 np.random.permutation()을 사용하여 indexes를 굳이 섞는지 궁금해 햐였다   이 부분을 설명하기 위해서 여러가지 경사하강법에 대해 먼저 알아 보아야 한다.      여러가지 경사 하강법 :  지금까지 사용해왔던 경사 하강법을 생각해보자..       def fit(self, x, y, epochs = 100):      self.w = np.ones(x.shape[1]) #가중치를 초기화 한다. np.ones()함수를 이용해 1로 초기화      self.b = 0 #절편을 0으로 초기화       for i in range (epochs): # epochs만큼 반복        for x_i, y_i in zip(x, y):          z = self.forpass(x_i) # 선형함수식에 대입하여 z 구함          a = self.activation(z) # z를 활성화 함수에 대입하여 a 구함          err = -(y_i - a) # 오차를 계산함          w_grad, b_grad = self.backprop(x_i, err) # 역방향 계산으로 가중치 gradient와 절편 gradient 구함          self.w -= w_grad  # 가중치를 갱신한다.         self.b -= b_grad # 절편을 갱신한다.  위 코드는 LogisticNeuron 클래스의 fit() 메서드 이다.  경사하강법을 통해 가중치와 절편을 갱신하는데 x, y 샘플에서 z와 a를 갱신할때 x_i, y_i 이렇게 하나의 샘플만 뽑아서 하나의 샘플 데이터 1개에 대해서만 gradient를 구하여 갱신하고 있다.   즉 전체 샘플 수 만큼 만복해서 계산하지만 1개의 샘플 데이터를 뽑아서 gradient 구함   확률적 경사 하강법(Stochastic Gradient Descent) :  위의 fit()메서드 즉 지금까지 사용해왔던 경사 하강법인 샘플 데이터 1개에 대한 gradient 계산으로 가중치와 절편을 갱신을 하고. 이러한 경사 하강법을 확률적 경사하강법 이라고 한다.   사실 엄밀한 확률적 경사 하강법은 아니다. 왜냐하면 엄밀한 확률적 경사하강법은 gradient 계산을 위해 샘플 데이터 1개를 뽑을때 위의 방법처럼 순서대로 1개씩 뽑는게 아니라 무작위로(랜덤으로) 뽑아야 한다. -&gt; 확률적    즉 np.random.permutaiton()을 사용하는 이유가 무작위로 샘플을 1개씩 뽑기 위함이다.   -&gt; 엄밀한 확률적 경사하강법 적용 위해   이 부분은 뒤에서 구체적으로 설명할 것이다.        1개 샘플을 중복되지 않게 무작위로 선택 후 gradient를 계산한다.     배치 경사 하강법 (Batch Gradient Descent) :  전체 훈련 세트를 사용하여 한 번에 gradient를 계산하는 방식      전체 샘플을 모두 선택하여 gradient 계산을 한다 (epoch 마다)    미니 배치 경사 하강법(Mini-Batch Gradient Descent) :  배치의 크기를 작게 하여 (훈련 세트를 여러번 나눔) 처리하는 방식      전체 샘플 중 몇개의 샘플을 중복되지 않도록 무작위로 선택하여 gradient를 계산함.    여러가지 경사 하강법들의 장단점에 대해 알아보자      확률적 경사 하강법 :  장점 : 샘플 데이터 1개마다 gradient 계산하므로 계산 비용이 적게 든다.  단점 : 가중치, 절편이 최적값에 수렴하는 과정이 불안함.     images_reference : https://valuefactory.tistory.com/460       배치 경사 하강법 :  장점 : 전체 훈련 데이터 세트를 사용하여 한 번에 gradient 계산하므로 가중치, 절편이 최적값에 수렴하는 과정이 안정적임  단점 : 계산비용이 많이듬     images_reference : https://valuefactory.tistory.com/460       미니 배치 경사 하강법 :  확률적 경사 하강법과 배치 경사 하강법을 절충해서 만든 경사 하강법임        images_reference : https://valuefactory.tistory.com/460       자 이제 SingleLayer 클래스를 구현할 때 왜 np.random.permutation()을 사용하여 indexes를 굳이 왜 섞는지에 대한 의문으로 다시 돌아오자     -&gt; 엄격한 확률적 경사 하강법 적용 (샘플을 무작위로(랜덤하게) 뽑아서 gradient 계산)   매 epoch마다 후련 세트의 샘플 순서를 섞어 사용하자!!  위에서 살펴본 모든 경사하강법은 매 epoch마다 훈련 세트의 샘플 순서를 섞어서 가중치, 절편의 최적값을 계산해야 한다.   왜 ??   훈련 세트의 샘플 순서를 섞으면 최적의 값을 찾는 과정이 다양해지기 떄문에 손실 함수의 값이 줄어들고 그로 인하여 최적의 값을 제대로 찾을 수 있다.      위 그림을 보면 1번쨰 epoch에서 사용된 훈련 세트의 샘플 순서는 1, 2, 4   2번째 사용된 훈련 세트의 샘플 순서는 3, 1, 2이다.     이런식으로 훈련 세트의 샘플 순서를 섞는 방법은 넘파이 배열의 인덱스를 섞고 인덱스 순서대로 샘플을 뽑는 것이다.   이러한 방법이 훈련 세트 자체를 섞는 것보다 효울적이고 빠르다. (훈련 세트를 나두면 되니까)   이 방법은 np.random.permutation()함수를 사용하여 index를 섞는다.       즉 이전 까지는 그냥 샘플 순서대로 1개씩 뽑아서 gradient 계산하여 가중치와 절편을 갱신하였다.   하지만 이 방법이 가중치와 절편의 최적값을 제대로 찾을 수 었었다.   따라서 랜덤하게 샘플을 1개씩 뽑아서 gradient를 계산하면 최적의 가중치와 절편을 찾는 탐색과정이 다양해 지므로 더 좋은 결과를 내놓기때문에 이 방법을 사용할 것이다. (엄밀한 확률적 경사 하강법)     단일층 신경망 클래스 SingleLayer 클래스가 완성 되었으니 이전에 사용했던 유방암 데이터 세트에 적용해보도록 하자   # 단일층 신경망 훈련하기  # 단일층 신경망을 훈련하고 정확도를 출력 해볼 것이다. # 이전 LogisticRegression 클래스에서 하엿듯이 SingleLayer 객체를 만들고 훈련세트 x_train, y_train로 신경망 훈련하자 # 이후 score() 메서드로 정확도 출력해보자  from sklearn.datasets import load_breast_cancer cancer = load_breast_cancer()  x = cancer.data y = cancer.target  from sklearn.model_selection import train_test_split  x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42)  layer = SingleLayer() # 단일층 신경망 객체(모델) 생성 layer.fit(x_train, y_train) # 모델 훈련 layer.score(x_test, y_test) # 정확도 측정    0.9035087719298246   이전 LogisticRegression 클래스보다 정확도가 훨씬 높아졌다.  그 이유는 경사하강법에서 샘플 데이터를 순서대로 뽑아서 gradient 계산이 아닌 무작위 순서로 뽑아서 계산 -&gt; 손실함수의 값 줄임  즉 엄격한 확률 경사 하강법 적용을 하니 정확도가 높아졌음을 알 수 있다.   # 진짜 손실 함수의 누적값이 작아졌는지 한번 확인해 보자  import matplotlib.pyplot as plt  plt.plot(layer.losses) # 에포크당 손실 함수 누적값을 담아놓은 리스트인 lyaer.losses를 그래프로 그려보자 plt.xlabel('epoch') plt.ylabel('loss') plt.show()  #그래프 그려보니까 로지스틱 손실 함수의 값이 에포크가 진행할수록 감소한다. (물론 어느 횟수 이상부터는 크게 감소하지 않고 왔다갔다함)      정리해보면 로지스틱 회귀 알고리즘을 확장하면 가장 기초적인 신경망 알고리즘으로 보면 된다.  (이전에 구현한 LogisticRegression 클래스에서 좀더 수정, 추가하여 SingleLayerRegression 클래스 만듬)   SingleLayerRegression 클래스를 기초적인 단일층 신경망 알고리즘으로 보면 된다.     단일층 신경망을 구현하기 위해선 로지스틱 회귀 알고리즘을 구현해야 한다.   그런데 단일층 신경망이 필요할때 이것을 직접 구현하기란 정말 귀찮은 일이다.   이러한 귀찮은 일을 사이킷런에서 해결해준다.  사이킷런에서 이런 알고리즘을 미리 구현해 놓았기 때문이다.      SGDclassifier :  SGDClassifier 클래스는 사이킷런에서 제공하는 경사 하강법이 구현된 클래스이다.  그럼 SGDClassifier 클래스를 이용해 로지스틱 회귀 문제를 간단히 해결해 볼것이다   (SGDClassifier 클래스를 이용하면 로지스틱 회귀 문제 뿐만 아니라 여러 가지 문제에 경사 하강법 적용할 수 있다.)      # 사이킷런으로 경사 하강법을 적용해보자  # 로지스틱 손실 함수를 먼저 지정해보자  from sklearn.linear_model import SGDClassifier sgd = SGDClassifier(loss = 'log', max_iter = 100, tol = 1e-3, random_state = 42)  # SGDClassifier 클래스에 로지스틱 회귀 적용 위해 loss 매개변수에 손실 함수로 log를 지정 # max_iter는 최대 반복 횟수를 의미한다. # 만약 tol에 지정한 값만큼 로지스틱 손실 함수의 값이 감소되지 않으면 반복 중단한다. # (먄약 tol값 지정 안할시 max_iter 늘리라는 경고가 발생함) # random_state = 42로 지정하여 난수 초깃값을 42로 설정하여 반복 실행시 동일한 난수값 나오게 한다.    # 사이킷런으로 훈련하고 평가해보자  # SGDClassifier 클래스에는 이전에 직접 구현한 모델을 훈련시키는 fit() 메서드와 정확도를 측정하는 score() 메서드가 준비되어 있다. sgd.fit(x_train, y_train) sgd.score(x_test, y_test)   0.8333333333333334   # 마지막으로 사이킷런으로 특정 결과를 예측해보자  # SGDClassifier 클래스에는 이전에 직접 구현한 예측을 하는 predict() 메서드 또한 준비가 되어있다.  # !! 단 주의할 점은 사이킷런은 입력 데이터로 2차원 배열만 받아들인다.!!!!! # 만약 샘플 하나만 넣어야하는 경우에도 2차원 배열로 만들어서 넣어야 한다는 의미!!  # 배열 슬라이싱 이용해서 테스트 세트에서 10개의 샘플만 뽑아 예측해봄 sgd.predict(x_test[0:10])    array([0, 1, 0, 0, 0, 0, 1, 0, 0, 0])   자 사이킷런에서 제공하는 클래스로 로지스틱 회귀를 직접 구현하지 않고도 이렇게 간단히 사용할 수 있다.  앞으로 사이킷런을 이용해서 이러한 방법으로 빨리 사용하는 경우가 대부분일 것이다.   그렇다고 지금까지 직접 구현해본 것이 아무 의미 없었던 일이 아니다.  내가 사용하고자 하는 어떠한 것이 어떠한 원리로 동작하는지를 안다면 더욱 그것을 적합한 상황에 잘 사용할 것이라 생각하기 때문이다.      Reference    박해선, 딥러닝 입문, 이지스퍼블리싱, 2019, 105~115pg  ","categories": ["Deep_Learning"],
        "tags": ["신경망","단일층 신경망","확률적 경사 하강법","배치 경사 하강법","미니 배치 경사 하강법","사이킷런","SGDclassifier"],
        "url": "/deep_learning/Single_Layer_Neural_Network/",
        "teaser": null
      },{
        "title": "검증 세트 나누기, 전처리 과정",
        "excerpt":"자 지금까지 선형회귀, 로지스틱 회귀, 단일층 신경망에 대해 배웠다.   이것들은 딥러닝을 위한 핵심 알고리즘이다.   따라서 지금부터는 훈련 노하우에 대해 알아볼 것이다.    훈련 노하우 :  모델을 안정적으로 훈련하기 위해 필요한 기법들     검증 세트를 나누기, 전처리   이전에 훈련 세트와 테스트 세트로 나누어서 테스트 세트를 score() 메서드에 전달하여 모델의 성능을 알아 보았다.   지금 부터 이 테스트 세트의 사용 방법에 대해 조금 더 알아보려고 한다.   어떤점에 대해 더 알아본다는 거지?? 말 그대로 테스트 세트는 모델의 성능에 대해 알면 된거 아닌가?     -&gt; 만약 테스트 세트로 모델의 성능을 측정 후 모델의 성능이 낮다면 테스트 세트에 잘 맞게끔 모델을 고쳐나갈 것이다.  하지만 테스트 세트의 데이터에만 너무 잘 맞는 모델이 만들어진다면 실제 데이터들에게 좋은 성능을 내지 못할 수 있다. (실제로 못한다.)     -&gt; 따라서 지금부터 하고자 하는 목표는 특정 데이터 세트에만 치우친 (대표적으로 테스트 세트에 치우치는) 모델을 만들지 않는 것이다.      테스트 세트로 모델을 튜닝  이전에 사이킷런의 SGDClassifier 클래스를 이용하여서 로지스틱 회귀 문제에 경사 하강법을 적용하였다.   이때 매개변수인 loss의 값을 log로 지정하여 로지스틱 손실함수를 손실함수로 지정하였다.     로지스틱 회귀로 모델 훈련하고 평가   from sklearn.datasets import load_breast_cancer # 사이킷런에서 제공하는 유방암 데이터 가져오기 from sklearn.model_selection import train_test_split   cancer = load_breast_cancer()  x = cancer.data y = cancer.target  x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42) # 훈련세트와 테스트 세트로 나눈다.    from sklearn.linear_model import SGDClassifier   sgd = SGDClassifier(loss = 'log', random_state = 42) # 이전에 설명하였듯이 로지스틱 손실함수를 손실함수로 지정하기 위해 매개변수인 loss의 값을 log로 지정한다. sgd.fit(x_train_all, y_train_all) sgd.score(x_test, y_test)  # 테스트 세트에서 정확도가 83%정도 나왓다.  # 뭔가 결과가 아쉽기 때문에 다른 손실 함수를 사용하려고 한다. -&gt; 매개변수 loss에 log가 아닌 다른 것으로 지정해줘야 한다는 의미! # 하지만 loss와 같은 매개변수들의 값은 가중치나 절편처럼 알아서 학습되지 않기 때문에 직접 선택을 해야한다!!! # -&gt; 이러한 값을 하이퍼파라미터(hyperparameter) 라고 부른다.   0.8333333333333334   매개변수 loss 값을 다른 값으로 바꾸어 손실 함수를 바꾸어보자   어떤 손실 함수로 바꿀까???       SGDClassifier 클래스의 loss 매개변수를 log에서 hinge로 바꾸면 선형 서포트 벡터 머신(Support Vector Machine, SVM) 문제를 푸는 모델이 만들어 진다.   갑자기 SVM ????? -&gt; 훈련 데이터의 클래스를 구분하는 경계선을 찾는 작업 정도로만 알고 나중에 더 자세히 알아보자     # 매개변수 loss 값을 log -&gt; hinge로 바꾸어 손실함수를 로지스틱 손실함수에서 선형 서포트 벡터 머신 문제를 푸는 모델 (그때에 쓰는 손실함수가 있겠지 정도로 알자)로 바꾸자  from sklearn.linear_model import SGDClassifier  sgd = SGDClassifier(loss = 'hinge', random_state = 42) sgd.fit(x_train_all, y_train_all) sgd.score(x_test, y_test)  # 테스트 세트에서 정확도가 94% 정도로 이전 로지스틱 손실함수를 사용한 경우보다 훨씬 높아졌다.   0.9385964912280702   자 위처럼 만약 모델의 성능 결과가 만족스럽지 않다면 loss 매개변수의 값을 바꾸었듯이   SGDClassifier 클래스의 다른 매개변수들을 바꾸어 보면 된다   이러한 과정을 -&gt;  모델을 튜닝한다  라고 부른다.   즉 모델을 튜닝하면 성능을 높일수도 있다.      방금 성능을 높인다가 아니라 높일수도 있다고 하였다.  실제로 모델을 튜닝하는 방법으로는 실전에서 좋은 성능을 내기 어려운 경우가 많다.   (모델을 튜닝하여 테스트 세트에 대한 성능은 높여도 실전에서 좋은 성능을 내기 어렵다는 의미이다 !!!)   -&gt; 왜 ???       테스트 세트로 모델을 튜닝하면 실제에서 좋은 성능 기대하기 어려움  테스트 세트의 목적은 실전에 투입된 모델의 성능을 측정하는 것이다.!!!!   하지만 테스트 세트로 모델을 튜닝하면  테슽트 세트에 대해서만 좋은 성능을 보여주는 모델이 된다!!!     이전에 모든 데이터로 훈련을 하면 어떤 데이터로 모델이 잘 훈련 되었는지 알 수 없기에 훈련 세트와 테스트 세트로 나눈다는 설명에서 든 예시와 비슷한 예를 들어 보면   특정 시험문제에 대한 답안을 외우게하면 그 시험에 익숙해진 사람은 같은 시험지를 주면 잘 풀것이다.   하지만 특정 시험문제가 아닌 다른 문제를 낸다면 과연 그 사람은 문제를 잘 풀까?   -&gt; 잘 풀지 못할 가능성이 크다. 왜냐하면 특정 시험 문제에 대해서만 잘 알기 때문이다     테스트 세트로 튜닝을 한 모델도 위의 예시와 똑같다.   테스트 세트에 대해서만 좋은 성능을 내도록 모델을 계속해서 튜닝하면 테스트 세트에 대해서만 잘 알게되고 실전에서는 같은 성능을 기대하기 어렵다. (오히려 튜닝을 할수록 떨어지는 경우도 생긴다.)   이러한 현상을  테스트 세트의 정보가 모델에 새어 나갔다  라는 표현을 한다.        테스트 세트로 모델을 튜닝하면 테스트 세트의 정보가 모델에 새어 나가게 되어 모델의 일반화 성능(generalization performance)가 왜곡된다.       따라서 테스트 세트는 모델 튜닝을 모두 마친 후 실전에 투입하기 전에 딱 한번 성능 평가를 하기위해 사용 해야한다.      그러면 어떻게 해결 하지 ???   -&gt; 모델을 튜닝할때 테스트 세트를 사용하지 않으면 되지..     아니 그러면 모델을 튜닝하려면 현재 모델의 성능을 알아야 하는데 이전처럼 어떻게 성능 점수를 평가할건데??   모델 튜닝을 위한 세트를 따로 준비하면 되지!!       검증 세트(Validation Set)를 준비한다.  모델을 튜닝하는 요도의 세트를 검증 세트라고 하며 훈련 세트에서 조금 떼어서 만들면 된다.   예를들어 이전에 전체 데이터에서 훈련 세트를 80% 테스트 세트를 20%로 나누었다면   훈련세트에서 일부를 떼어 훈련 세트를 60% 검증 세트를 20% 훈련 세트를 20%로 나누면 된다.      이제 전체 데이터 세트를 훈련 세트, 검증 세트, 테스트 세트로 나누어 SGDClassifier 클래스로 만든 모델을 훈련해볼 것이다.   # 데이터 세트를 준비한다  from sklearn.datasets import load_breast_cancer from sklearn.model_selection import train_test_split  cancer = load_breast_cancer()  x = cancer.data y = cancer.target  x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42)   # 검증 세트를 분할하기  x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify = y_train_all, test_size = 0.2, random_state = 42)  # 훈련, 검증, 테스트 세트를 각각 6 : 2 : 2로 나누기로 하였었다. 하지만 실제 분할 적용은 처음부터 6 : 2 : 2로 나누는 것이 아니라 # 전체 데이터 세트를 훈련 세트와 테스트 세트로 8 : 2로 나누고 훈련 세트를 다시 훈련세트와 검증세트로 8 : 2로 나눈다  # 그럼 엄밀히 6 : 2 : 2가 아니겠지 -&gt; 8에서 8 : 2로 나누면 전체 10(훈련, 검증, 테스트 세트 전부)으로 볼때 6.4 : 1.6으로 나눠지기 때문에 # 사실 정확히 훈련, 검증, 테스트 세트가 각각 6.4 : 1.6 : 2로 나뉘어 진다.  print(len(x_train), len(x_val), len(x_test))  # 여기서 볼 수 있듯 훈련, 검증, 테스트 세트가 각각 6.4 : 1.6 : 2 비로 나눠지는 것을 알 수 있다.   364 91 114   # 검증 세트로 모델을 평가해보자 from sklearn.linear_model import SGDClassifier  sgd = SGDClassifier(loss = 'log', random_state = 42) sgd.fit(x_train, y_train) sgd.score(x_val, y_val)  # ??? 이전의 성능보다 훨씬 낮아졌다 왜그럴까? # -&gt; 당연하다 이전에 비해 훈련세트를 일부를 검증세트로 나누게 되면서 훈련세트의 크기가 줄어기 때문이다   0.6923076923076923   우리가 사용한 위스콘신 유방암 데이터 세트의 샘플 개수는 적은편이기 때문에 검증 세트의 비율이나 random_state 매개변수의 값을 조금만 조절하더라도 성능 차이가 크게 변한다.       데이터 양이 너무 적으면 검증세트를 나누게 되면 훈련 세트의 크기가 너무 작아지기 때문에 이 경우에는 검증 세트를 나누지 않고 교차 검증(cross validation) 이라는 방식을 사용한다.   교차 검증에 대해서는 차후에 알아보자     하지만 최근에는 대량의 훈련 데이터를 모으기가 수월해졌기 때문에 검증 세트로 나누는 경우가 많다.     일반적으로 훈련, 검증, 테스트 세트의 비율을   데이터가 10만개 정도 일때 -&gt; 8 : 1 : 1     딥러닝 경우에는 더 많은 데이터를 사용하는 경우가 많은데   데이터가 100만개 이상일 경우 -&gt; 98 : 1 : 1     일반적으로 검증, 테스트 세트의 샘플 수가 1만개 이상 확보가 된다면 나머지 샘플은 훈련 세트에 할당하는 것이 좋다고 한다.      다시 위의 예제로 돌아가면 뭐 성능은 많이 낮아졌지만 일단 검증 세트가 잘 준비 된것으로 볼 수 있다.     데이터 전처리와 특성의 스케일   지금까지 예제를 보면 알 수 있듯이 사이킷런과 같은 머신러닝 패키지에 준비되어 있는 데이터는 대부분 실습을 우한 것이기 때문에 이미 데이터 자체가 잘 가공되어 있다.(바로 훈련, 검증, 테스트 세트로 사용될 수 있을 정도로 잘 가공 되어 있다는 의미)      하지만 실전에서 머신러닝, 딥러닝 분야에서는 데이터를 전처리(가공)하는 과정이 시간이 매우 오래 걸린다고 한다.   실전에서 수집된 데이터는 누락된 값이 있을수도, 데이터의 형태가 균일하지 않을수도 있다.   이러한 데이터를 사용하면 제대로 된 결과를 얻을 수 없다.  -&gt; 데이터를 적절히 가공하는 데이터 전처리(data preprocessing) 과정 필요   특성의 스케일은 알고리즘에 영향을 준다.   잘 정리된 데이터도 전처리를 해야하는 경우가 존재한다   엥 굳이 왜 ?? 어떤 경우에?  -&gt; 특성의 스케일(scale)이 다른 경우이다.     특성의 스케일이 뭔데??   어떤 특성이 가지고 있는 값의 범위를 말한다.      그래 데이터의 값의 범위가 다른 경우에 왜 전처리를 해야하지?   예를 들어보자 사과 1, 2, 3 데이터가 존재한다 해보자.   각각 순서대로 당도가 4, 8, 2   무게가 540, 700, 480 이라고 하자   위 데이터는 형태도 균일하고 누락된 값도 없다.  하지만 사과의 당도 범위가 1 ~ 10   사과의 무게 범위가 500 ~ 1000이다.  -&gt; 이 경우 두 특성의 스케일 차이가 크다 라고 한다.       특정 알고리즘은 스케일에 매우 민감하다. 따라서 모델의 성능에 영항을 미칠 수 있다  이전에 설명한 신경망 알고리즘 그리고 앞으로 사용할 신경망 알고리즘들 모두 경사하강법을 사용할 것이다.  그런데 경사하강법은 스케일에 아주 민감한 알고리즘이다.   따라서 특성의 스케일을 맞추는 등의 전처리가 필요하다.   특성이 스케일을 맞추는 전처리를 하는 것을 -&gt; 스케일을 조정한다라고 표현을 한다.     그럼 예제를 통해 특성의 스케일을 조정하면 어떤 점이 좋아질지 알아보자     # 먼저 스케일을 조절하지 않고 모델을 훈련해보자  import matplotlib.pyplot as plt  print(cancer.feature_names[[2, 3]]) # 유방암 데이터의 mean perimeter와 mean area 특성의 스케일을 알아보자  plt.boxplot(x_train[:, 2:4]) plt.xlabel(\"feature\") plt.ylabel(\"value\") plt.show() # boxplot을 그려 두 특성이 스케일을 확인해보자 # 그래프를 보면 두 특성의 스케일 차이가 큰 것을 알 수있다. # mean perimeter는 value가 100 ~ 200 위치 # mean area는 value가 200 ~ 2000 사이에 위치한다.  # -&gt; 스케일이 다른 두 특성에 경사하강법을 적용해보자   ['mean perimeter' 'mean area']      # 가중치를 기록할 변수와 학습률 파라미터 추가해보자  import numpy as np  class SingleLayer:      # init() 메서드에서 인스턴스 변수 w_history를 만들고 학습률 파라미터 learning_rate를 추가한다    # learning_rate는 하이퍼파라미터 이고 변수 이름 그대로 '학습률' 이라고 한다.   # 이 값으로 가중치의 업데이트 양을 조절할 것임      def __init__(self, learning_rate = 0.1): # 학습률 파라미터 learning_rate 추가     self.w = None     self.b = None     self.losses = []     self.w_history = [] # SingleLayer 클래스에 인스턴스 변수를 추가하여서 epoch마다 가중치의 값을 저장하면서 가중치의 변화를 확인 해보자     self.lr = learning_rate      self.losses = []     def forpass(self, x):      z = np.sum(x * self.w) + self.b     return z    def backprop(self, x, err):      w_grad = x * err     b_grad = 1 * err       return w_grad, b_grad      def activation(self, z):     z = np.clip(z, -100, None)      a = 1 / (1 + np.exp(-z))      return a    # 가중치 기록하고 업데이트 양을 조절하자    #fit 메서드에서 가중치가 바뀔 때 w_history 리스트에 가중치를 기록하자   def fit(self, x, y, epochs = 100):     self.w = np.ones(x.shape[1])      self.b = 0          self.w_history.append(self.w.copy()) # 가중치를 기록한다.     # 넘파이 배열을 리스트에 추가하면 실제 값이 복사되는 것이 아니라 배열을 참조함     # 따라서 가중치 변수에 self.w 값이 바뀔때마다 그 값을 복사하여 w_history 리스트에 추가해야한다.            np.random.seed(42)      for i in range (epochs):       loss = 0       indexes = np.random.permutation(np.arange(len(x)))         for i in indexes:         z = self.forpass(x[i])         a = self.activation(z)          err = -(y[i] - a)          w_grad, b_grad = self.backprop(x[i], err)           self.w -= self.lr * w_grad # 학습률을 적용하여 가중치를 갱신해보자         # -&gt; w_grad에 학습률 self.lr을 곱하여 가중치 업데이트 양 조절함.          self.b -= b_grad           self.w_history.append(self.w.copy()) # 가중치 기록          a = np.clip(a, 1e-10, 1 - 1e-10)           loss += -(y[i] * np.log(a) + (1 - y[i]) * np.log(1 - a))               self.losses.append(loss/len(y))     def predict(self, x):     z = [self.forpass(x_i) for x_i in x]     return np.array(z) &gt; 0      def score(self, x, y):     return np.mean(self.predict(x) == y)     학습률이라는 개념을 알아보자  init() 메서드에서 인스턴스 변수 w_history를 만들고 학습률 파라미터 learning_rate를 추가한다      learning_rate는 하이퍼파라미터 이고 변수 이름 그대로 학습률 이라고 한다.   이 값으로 가중치의 업데이트 양을 조절할 것임   일반적으로 손실함수는 복잡한 굴곡을 가진 다차원 공간의 초평면(hyperplane)이다.   만약 가중치를 큰 폭으로 업데이트 하여 손실 함수가 최소가 될 수 있는 지점인 전역 최솟값을 지나쳐 버리게 되면   최적의 해(최적의 가중치와 절편)을 구할 수 없게 된다.   따라서 전역 최솟값을 놓치지 않도록 가중치의 업데이트 양을 조절할 필요가 있다.  학습률에 따라 손실 함수의 값이 어떻게 변하는지 아래 그림을 통해 알아보자        적절한 학습률 :  학습률이 적절해야 가중치의 변화가 안정적이므로 전역 최솟값에 잘 도달함   높은 학습률 :  학습률이 너무 높으면 가중치의 변화가 크므로 전역 최솟값을 지나칠 수 있음        손실 함수의 표면을 천천히 이동하며 전역 최솟값을 찾는다 라는 표현을 한다.   각 상황마다 적절한 학습률은 다르지만 보통 0.001, 0.01 등의 로그 스케일로 학습률을 지정하여 테스트한다.       # 모델을 훈련하고 평가 해보자  layer1 = SingleLayer() layer1.fit(x_train, y_train) layer1.score(x_val, y_val)  # 스케일을 조정하지 않은 훈련세트를 이용하여 모델을 훈련 # 이때의 성능을 확인해보니 약 91% 정도임을 확인할 수 있다   0.9120879120879121   # layer1 객체의 인스턴스 변수 w_history에는 100번의 epoch 동안 변경된 가중치가 모두 기록되어 있음 # 이때 3, 4번째 요소는(w[2], w[3]) 각각 mean perimeter 와 mean area 특성에 대한 가중치이다. # 이 요소로 그래프를 그려보면 아래와 같다  w2 = [] w3 = []  for w in layer1.w_history:   w2.append(w[2])   w3.append(w[3])  plt.plot(w2, w3) plt.plot(w2[-1], w3[-1], 'ro') # 최종으로 결정된 가중치는 점으로 표시  plt.xlabel('w[2]') plt.ylabel('w[3]')  plt.show()        위 그래프를 보자 mean perimeter에 비해 mean area 스케일이 크므로 w3 값이 학습 과정에서 큰 폭으로 변화하고 있음을 확인할 수 있다.      w2 경우 0부터 시작하여 조금씩 최적값에 가까워 진다.     이 그래프의 현상을 w3에 대한 gradient가 크기 때문에   w3축을 따라 가중치가 크게 요동치고 있다 라고 말한다   즉 가중치의 최적값에 도달하는 동안 w3 값이 크게 요동치므로 모델이 불안정하게 수렴한다는 것을 알 수 있다.       위 현상을 어떻게 하면 줄일 수 있을까?  이 부분에 대해 설명하기 위해 지금까지 설명을 해왓다.     -&gt; 스케일을 조정하면 된다.   스케일을 조정해 모델을 훈련해보자   스케일을 조정하는 방법은 많다.   그 중 신경망에서 자주 사용하는 방법 중 하나로 표준화를 사용할 것이다.      표준화(standardization) :  특성값에서 평균을 빼고 표준 편차로 나눈 값으로 표준화를 하면 평균이 0, 분산이 1인 특성이 만들어 진다.   $z = \\frac{x - \\mu}{s}$  $\\mu$ : 평균, s : 표준편차      사이킷런에서는 이러한 표준화를 위한 StandardScaler 클래스가 준비되어 있다.   하지만 학습을 위해 직접 표준화를 구현해 보자     # 넘파이로 표준화를 구현해보자  # 넘파이의 mean() 함수로 평균을, std() 함수로 표준편차를 구할 수 있다.  train_mean = np.mean(x_train, axis = 0) train_std = np.std(x_train, axis = 0) x_train_scaled = (x_train - train_mean) / train_std  # 평균과 표준편차를 구할 때 # axis 매개변수를 0으로 지정하면 2차원 배열의 열을 기준으로 통계치를 계산하여 하나의 행 벡터로 변환을 해준다. # 이후 훈련 세트 x_train에서 평균을 빼고 표준 편차로 나누면된다   # 모델 훈련을 해보자  # 이제 스케일을 조정한 데이터 세트로 단일층 신경망을 다시 훈련시키고 가중치를 그래프로 그려보자  layer2 = SingleLayer() layer2.fit(x_train_scaled, y_train) w2 = [] w3 = []  for w in layer2.w_history:   w2.append(w[2])   w3.append(w[3])  plt.plot(w2, w3) plt.plot(w2[-1], w3[-1], 'ro')  plt.xlabel('w[2]') plt.ylabel('w[3]') plt.show()  # 그래프를 보면 이전에 스케일 조정을 하기전 그래프와 매우 큰 차이가 있음을 확인할 수 있다. # w2와 w3의 변화 비율이 비슷하기 때문에 대각선 방향으로 가중치가 이동되었음을 확인할 수 있다.  # 두 특성 스케일을 비슷하게 맞추었으므로 최적값에 빠르게 근접하고 있음을 알 수 있다.  # 이렇듯 경사 하강법에서는 서로 다른 특성의 스케일을 맞추는 것이 매우 중요함을 알 수 있다.      # 모델 성능을 평가해보자  layer2.score(x_val, y_val)  # ????? 아니 스케일 조정하기전에는 성능이 (정확도가) 91% 정도 엿는데 머지?? 스케일 조정 후 성능을 보면 정확도 37% 정도로 아주 많이 떨어졌다 &lt;br&gt; # 무슨일이지 ??  # 모델은 훈련 세트와 검증 세트의 스케일이 비슷할 것으로 기대한다 # 하지만 검증 세트의 스케일을 바꾸지 않았기 때문에 성능이 매우 떨어진 것   0.37362637362637363   # 다시 검증 세트도 표준화 전처리를 적용해보자  val_mean = np.mean(x_val, axis = 0) val_std = np.std(x_val, axis = 0) x_val_scaled = (x_val - val_mean) / val_std  layer2.score(x_val_scaled, y_val)  # 검증 세트에 대한 정확도가 약 96% 정도로 스케일 조정 전 성능에 비해서도 좋아진 것을 알 수 있다.   0.967032967032967   자 지금까지 보면 스케일 조정을 잘 하여 모델의 성능을 높였기에 괜찮게 데이터를 전처리 했다고 생각할 수 있다.   하지만 정말 조심해야할 교묘한 ?? 함정이 숨어 있는데 그 함정에 대해 알아보자   스케일을 조정한 다음에 실수하기 쉬운 함정에 대해 알아보자   이전에 언급했지만 함정 중에 하나는 훈련 세트와 검증 세트가 다른 비율로 스케일이 조정된 경우이다.      # 원본 훈련 세트와 검증 세트로 산점도를 그려보자  # 훈련 세트와 검증 세트 50개씩만 뽑아서 확인해 보자  plt.plot(x_train[:50, 0], x_train[:50, 1], 'bo') # 훈련 세트는 파란색 plt.plot(x_val[:50, 0], x_val[:50, 1], 'ro') # 검증 세트는 빨간색  plt.xlabel('feature 1') plt.ylabel('feature 2')  plt.legend(['train set', 'val. set']) plt.show()      # 전처리한 훈련 세트와 검증 세트로 산점도를 그려보자  plt.plot(x_train_scaled[:50, 0], x_train_scaled[:50, 1], 'bo') # 훈련 세트는 파란색 plt.plot(x_val_scaled[:50, 0], x_val_scaled[:50, 1], 'ro') # 검증 세트는 빨간색  plt.xlabel('feature 1') plt.ylabel('feature 2')  plt.legend(['train set', 'val. set']) plt.show()       전처리 전과 후의 산점도를 비교해 보자   미세하지만 훈련 세트와 검증 세트가 각각 다른 비율로 변환되었음을 알 수 있다.    무슨 의미이냐면 전처리 전 훈련 세트와 검증 세트의 점과 점 사이의 거리가 변환된 이후에 그대로 유지되지 않는다는 의미이다.    데이터를 제대로 전처리 하였다면 훈련 세트와 검증 세트의 거리가 그대로 유지가 되었어야 한다.    -&gt; 점과 점 사이의 거리가 달라진 이유는 훈련 세트와 검증 세트를 각각 달느 비율로 전처리 했다는 의미이다.   올바르게 검증 세트를 전처리 해보자  검증 세트의 스케일이 훈련 세트의 스케일과 다른 비율로 조정 되면 모델에 적용된 알고리즘들이 검증 세트의 샘플 데이터를 잘못 인식한다.   따라서 검증 세트를 훈련 세트와 같은 비율로 전처리 해야 한다.      이 방법 대로 테스트 세트와 모델을 실전에 투입하여 새로운 샘플을 처리할 때도 마찬가지이다.   하지만 문제점이 하나 있다.   실전에는 샘플 하나에 대한 예측값을 만들기 때문에 전처리를 위해 평균이나 표준 편차를 계산할 수도 없다.    그럼 어떻게 해결해야 할까 ?      훈련 세트의 평균, 표준 편차를 사용하여 검증 세트를 반환하면 된다.   x_val_scaled = (x_val - train_mean) / train_std # 검증 세트를 표준화 하는데 훈련 세트의 평균과 표준편차를 이용  plt.plot(x_train_scaled[:50, 0], x_train_scaled[:50, 1], 'bo') # 훈련 세트는 파란색 plt.plot(x_val_scaled[:50, 0], x_val_scaled[:50, 1], 'ro') # 검증 세트는 빨간색  plt.xlabel('feature 1') plt.ylabel('feature 2')  plt.legend(['train set', 'val. set']) plt.show()  # 이제는 전처리 전 데이터의 산점도와 전처리 후 (스케일 조정 이후) 산점도가 같아졌다. # 즉 검증 세트와 훈련 세트가 동일한 비율로 변환되었음을 알 수 있다.      # 모델을 평가해 보자  layer2.score(x_val_scaled, y_val)  # 머야 검증 세트를 전처리하기 전이나 후나 정확도가 똑같은데 ???? # 검증 세트 전처리 할 필요가 없다는 말???  # 아니다 우리가 사용한 예제의 데이터는 (위스콘신 유방암 데이터 세트) 데이터가 크지 않기 때문에 # 검증 세트를 전처리하기 전과 후의 성능이 동일하다  # 만약 데이터 크기가 크다면 검증 세트를 전처리하기 전과 후의 성능이 크게 차이가 날 수 있다.   0.967032967032967   자 지금까지 검증 세트를 나누는 이유, 그리고 데이터 전처리에 대한 훈련 노하우를 알아 보았다.. 이 다음에는 훈련 세트, 검증 세트와 깊은 연관이 있으면서도 머신러닝, 딥러닝에서 매우 중요한 개념인 과소적합, 과대적합에 대해 알아보려고 한다.       Reference    박해선, 딥러닝 입문, 이지스퍼블리싱, 2019, 116 ~ 130pg  ","categories": ["Deep_Learning"],
        "tags": ["검증 세트","특성의 스케일","표준화"],
        "url": "/deep_learning/Training_Know_How(1)/",
        "teaser": null
      },{
        "title": "과대 적합, 과소 적합",
        "excerpt":"과대 적합(overfitting), 과소 적합(underfitting) 개념에 대해 알아보고자 한다.     훈련 세트와 검증 세트는 모델의 과대 적합과 과소 적합 이라는 문제와 매우 깊게 연관 되어 있다.       학습 곡선을 통해 과대적합과 과소적합에 대해 알아보자   과대 적합(Overfitting) :  모델이 훈련 세트에서는 좋은 성능을 내지만 검증 세트에서는 낮은 성능을 내는 경우     과소 적합(Underfitting) :  훈련 세트와 검증 세트의 성능에는 차이가 크지 않지만 모두 낮은 성능을 내는 경우     훈련 세트의 크기와 과대 적합과 과소 적합 분석을 해보자  훈련 세트의 크기에 따라 과대 적합과 과소 적합이 어떻게 나타나는지 그래프를 통해 알아보자        위와 같은 그래프를 학습 곡선(Learning curve) 이라 부른다.     첫 번재 학습 곡선은 과대 적합의 전형적인 모습으로 훈련 세트와 검증 세트에서 측정한 성능간의 간격이 큰 경우이다.   따라서 과대 적합된 모델을 분산이 크다(high variance) 라고 말한다.    과대 적합의 주요 원인 중 하나는 훈련 세트에 충분한 다양한 패턴의 샘플이 없는 경우이다.   다양한 패턴의 샘플이 없는것이 왜 과대 적합을 일으키지 ??     훈련 세트에 다양한 패턴이 없다면 검증 세트에 제대로 적응하지 못할 것이기 때문이다.   이런 경우에는 더 많은 훈련 샘플을 추가하여 검증 세트의 성능을 향상 시킬 수 있다.   만약 훈련 샘플을 더이상 모을 수 없는 경우라면 모델이 훈련 세트에 집착하지 않도록 가중치를 제한할 수 있다.    이 방법을 모델의 복잡도를 낮춘다 라고 표현을 한다.   (모델의 복잡도를 낮추는 방법은 추후에 알아보자)      두 번째 학습 곡선은 전형적인 과소 적합의 모습으로 훈련 세트와 검증 세트에서 측정한 성능의 간격은 훈련 세트의 크기가 커질수록 점점 더 가까워 지지만 훈련세트, 검증세트 모두 정확도가 떨어진다(성능이 떨어진다)   따라서 과소적합된 모델을 편향이 크다(high bias)      과소 적합의 주요 원인 중 하나는 모델이 충분히 복잡하지 않아 훈련 데이터에 있는 패턴을 모두 잡아내지 못하는 현상이다.     위 원인으로 인한 과소 적합을 해결하는 대표적인 방법은 복잡도가 더 높은 모델을 사용하거나 가중치의 규제를 완화하는 방법이다.       세 번째 학습 곡선은 과대적합과 과소적합 사이에서 절충점을 찾은 것이다.      에포크와 손실 함수의 그래프로 과대 적합과 과소 적합을 분석해보자   이전에 배운 에포크에 대한 손실 함수의 그래프를 사용하여 과대 적합과 과소 적합울 분석하기도 한다.   따라서 에포크에 대한 손실 함수의 그래프를 학습 곡선이라고 부르는 경우가 종종 있다.        위 그래프는 에포크와 손실 함수에 대한 그래프와 에포크와 정확도에 대한 그래프 이다  이 그래프 들을 통해 과대 적합과 과소 적합에 대해 알아볼 것이다.     왼쪽 그래프를 보면 훈련 세트의 손실은 에포크가 진행될 수록 감소하지만 검증 세트의 손실은 에포크의 횟수가 최적점을 지나면 오히려 상승하는 것을 확인할 수 있다      에포크가 늘면 늘수록 손실은 줄어야 하는것 아닌가???   -&gt; 최적점 이후에도 계속해서 훈련 세트로 모델을 학습시키면 모델이 훈련 세트의 샘플에 대해 더 밀착하여 학습하기 때문에 훈련 세트에만 너무 맞는 모델이 되어버리기 때문이다.  즉 최적점 이후부터 계속 학습을 하면 모델이 과대 적합하기 시작한다는 뜻이다.     반대로 최적점 이전에는 훈련 세트와 검증 세트의 손실이 비슷한 간격을 유지하면서 함께 줄어드는 것을 볼 수 있는데 아 영역에서 학습을 중단하면 (최적점 전에 학습을 중단) 과소 적합된 모델이 만들어 진다.      오른쪽 그래프는 세로축에 손실 대신 정확도를 사용했으니 왼쪽 그래프가 뒤집혀진 결과와 같다.      모델 복잡도와 손실 함수의 그래프로 과대 적합과 과소 적합을 분석해보자       위 그래프 처럼 학습 곡선 그래프를 가로 추겡 에포크 대신 모델 복잡도를 넣어 그래프를 표현하기도 한다.   모델 복잡도가 뭐지 ??    모델 목잡도 :  모델이 가진 학습 가능한 가중치 개수를 말한다. 층의 개수나 유닛의 개수가 많아지면 복잡도가 높은 모델이 된다.      모델이 복잡해지면 좋을 것 같은데 꼭 그렇지 많은 않다. 아니 너무 복잡해지면 오히려 좋지 않다.   예를 들어서 모델이 훈련 세트에만 잘 맞는 형태로 만들어 지면 훈련 세트에서만 좋은 성능을 만들기 때문에 좋은 성능을 내기 때문이다 -&gt; 이러한 경우가 과대적합이다.      자 지금까지 다양한 학습 곡선을 통해 과대 적합과 과소 적합에 대해 알아 보았는데   정리해보면 좋은 성능을 내는 모델을 만들기 위해 여러 조건이 필요함을 알 수 있다.  특히 에포크 횟수에 따라 최적점을 기준으로 오히려 에포크 횟수가 더 커지면 과대 적합, 에포크 횟수가 더 적으면 과소 적합이 되었던 것을 알게 되었다.       그럼 적절한 에포크 횟수에 대해 알아보자   적절한 편향 - 분산 트레이드오프를 선택하자  편향 - 분산 트레이드오프가 뭐야 ??   이것을 설명하기 이전에 과소 적합된 모델은 편향 되었다라고 하고 과대 적합된 모델은 분산이 크다 라고 하였다.     편향 - 분산 트레이드오프(bias-variance tradeoff) :  과소 적합된 모델(편향)과 과대 적합된 모델(분산) 사이의 관계    트레이드 오프라는 말이 들어가게 된 이유는 하나를 얻기 위해 다른 하나를 희생해야 하기 때문이다.   편향 - 분산 트레이드오프란 편향을 줄이면(훈련 세트의 성능을 높이면) 분산이 커지고(검증 세트와 성능 차이가 커지고) 반대로 분산을 줄이면(검증 세트와 성능 차이를 줄이면) 편향이 커지는(훈련 세트의 성능이 낮아진다는) 것을 말한다.      따라서 분산이나 편향이 너무 커지지 않도록 적절한 중간 지점을 찾아야 한다.   이러한 행위를 적절한 편향 - 분산 트레이드오프를 선택했다      이제부터 경사하강법의 에포크 횟수에 대한 모델의 손실을 그래프로 그려 ‘적절한 편향-분산 트레이드오프’를 선택해 보자.       # 검증 손실을 기록하기 위한 변수 추가하기  # 훈련 세트의 손실을 기록했듯이 검증 세트에 대한 손실을 기록한 다음 기록한 값으로 그래프를 그려볼 것이다. # 이를 위해 SingleLayer 클래스의 __init__() 메서드에 self.val_losses 인스턴스 변수를 추가해보자  # 가중치를 기록할 변수와 학습률 파라미터 추가해보자  import numpy as np  class SingleLayer:      def __init__(self, learning_rate = 0.1):     self.w = None     self.b = None     self.losses = []     self.val_losses = [] # self.val_losses 변수 추가 !!     self.w_history = []       self.lr = learning_rate      self.losses = []     def forpass(self, x):      z = np.sum(x * self.w) + self.b     return z    def backprop(self, x, err):      w_grad = x * err     b_grad = 1 * err       return w_grad, b_grad      def activation(self, z):     z = np.clip(z, -100, None)      a = 1 / (1 + np.exp(-z))      return a    def fit(self, x, y, epochs = 100, x_val = None, y_val = None): # x_val, y_val 매개변수 추가     self.w = np.ones(x.shape[1])      self.b = 0          self.w_history.append(self.w.copy())         np.random.seed(42)      for i in range (epochs):       loss = 0       indexes = np.random.permutation(np.arange(len(x)))         for i in indexes:         z = self.forpass(x[i])         a = self.activation(z)          err = -(y[i] - a)          w_grad, b_grad = self.backprop(x[i], err)           self.w -= self.lr * w_grad          self.b -= b_grad           self.w_history.append(self.w.copy())           a = np.clip(a, 1e-10, 1 - 1e-10)           loss += -(y[i] * np.log(a) + (1 - y[i]) * np.log(1 - a))               self.losses.append(loss/len(y))         self.update_val_loss(x_val, y_val) # 검증 세트에 대한 손실을 계산    def predict(self, x):     z = [self.forpass(x_i) for x_i in x]     return np.array(z) &gt; 0      def score(self, x, y):     return np.mean(self.predict(x) == y)    # 검증 손실 계산하자   def update_val_loss(self, x_val, y_val):     if x_val is None:       return      val_loss = 0      for i in range(len(x_val)):       z = self.forpass(x_val[i]) #  정방향 계산       a = self.activation(z) # 활성화 함수 적용       a = np.clip(a, 1e-10, 1 - 1e-10)        val_loss += -(y_val[i] * np.log(a) + (1 - y_val[i]) * np.log(1 - a))      self.val_losses.append(val_loss / len(y_val))        # 이 계산은 fit() 메서드에서 훈련 세트의 손실을 계산하는 방식과 동일     # 검정 세트 샘플을 정방향으로 계산하고 활성화 함수를 통과시켜 출력값 계산한다     # 이 값을 이용해 로지스틱 손실 함수의 값을 계산 위해 val_losses 리스트에 추가함     # 검증 세트에 대한 손실 함수 값을 계산위해 fit() 메서드에서 epoch 1번 마다 update_val_loss() 메서드 호출    # 모델을 훈련해 보자  # 데이터 세트를 준비한다  from sklearn.datasets import load_breast_cancer from sklearn.model_selection import train_test_split  cancer = load_breast_cancer()  x = cancer.data y = cancer.target  x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42)  x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify = y_train_all, test_size = 0.2, random_state = 42)  train_mean = np.mean(x_train, axis = 0) train_std = np.std(x_train, axis = 0) x_train_scaled = (x_train - train_mean) / train_std  val_mean = np.mean(x_val, axis = 0) val_std = np.std(x_val, axis = 0) x_val_scaled = (x_val - val_mean) / val_std  layer3 = SingleLayer() layer3.fit(x_train_scaled, y_train, x_val = x_val_scaled, y_val = y_val)   # 손실값으로 그래프를 그려 에포크 횟수를 지정하자  # fit() 메서드를 수정하여 에포크마다 훈련 세트와 검증 세트의 손실값을 인스턴스 변수 self.val_losses에 저장하도록 만들었다. # 이 값을 이용해 그래프를 그려보자 import matplotlib.pyplot as plt  plt.ylim(0, 0.3) plt.plot(layer3.losses) plt.plot(layer3.val_losses)  plt.ylabel('loss') plt.xlabel('epoch')  plt.legend(['train_lss', 'val_loss'])  plt.show()  # 그래프를 보면 검증 손실이 대략 epoch 20번째 이후에 훈련 세트보다 높아지는 것을 알 수 있다. # 즉 epoch가 진행됨에 따라 가중치는 훈련 세트에 잘 맞게 되지만 검증 세트에는 잘 맞지 않게 되는 것이다. # 그 절충점이 epoch 20번째 쯤으로 보인다.      # 그럼 적절한 절충점인 epoch 횟수에서 훈련을 종료하고 싶기 때문에 # 훈련을 조기 종료 하도록 해보자  # 이렇게 훈련을 일찍 끝내는 방법을 조기 종료(early stopping) 이라고 부른다.  layer4 = SingleLayer() layer4.fit(x_train_scaled, y_train, epochs = 20) layer4.score(x_val_scaled, y_val)  # 이전 스케일 조정 한 이후에 정확도가 0.967 정도엿는데 그에 비해 정확도가 확실히 올랐음을 확인할 수 있다. # 그 이유는 과대 적합되기 이전에 훈련을 멈추었기 떄문에 가능했다.   0.978021978021978   과대 적합, 과소 적합에 대해 알아 보았다.   이후에는 이전에 설명한 과대 적합을 해결하는 대표적인 방법 중 하나인 가중치 규제 방법에 대해 좀더 자세히 알아 보고자 한다.      Reference    박해선, 딥러닝 입문, 이지스퍼블리싱, 2019, 131 ~ 136pg  ","categories": ["Deep_Learning"],
        "tags": ["과대 적합","과소 적합","학습 곡선","편향-분산 트레이드오프","조기 종료"],
        "url": "/deep_learning/Training_Know_How(2)/",
        "teaser": null
      },{
        "title": "L1 규제, L2 규제",
        "excerpt":"이전에 과대 적합을 해결하는 대표적인 방법 중 하나로 가중치 규제(regularization)을 언급하였다.       가중치 규제 :  가중치 값이 커지지 않도록 제한하는 방법      가중치 값이 커지지 않게하면 왜 과대 적합을 해결할까??     가중치 규제를 하면 모델의 일반화 성능이 올라가게 되기 떄문이다   좀 더 구체적으로 알아보자.      위 그래프 중 두 선(빨강, 파란 선) 모두 점을 적당히 잘 나타내고 있다.      그런데 두 선 중 어떤 선을 나타내는 모델이 더 성능이 좋을까??   이 경우 경사가 급한 그래프보다는 경사가 완만한 선(파란선)을 나타내는 모델이 성능이 더 좋다고 평가한다.   그 이유는 경사가 높은 선 보다 경사가 낮은 선이 보라색 박스로 표시한 샘플 데이터를 더 잘 표현하기 때문이다.          그럼 위 그래프와 같이 점에 대해 거의 완벽히 표현하는 선, 즉 샘플 데이터에 딱 맞는 그래프는 어떤지 생각해보자     당연히 샘플 데이터에 딱 맞는 그래프는 성능도 최고 아닌가?      그렇면 보라색 박스의 데이터가 샘플 데이터에 추가했다 생각해보자..   이전 샘플 데이터에 너무 딱 맞는 선을 모델이 나타내고 있기 떄문에 새로운 데이터를 제대로 표현하지 못하고 있다.      -&gt;즉 모델이 몇 개의 데이터에 너무 집착해버리면 새로운 데이터에 적응을 못하여 좋은 성능을 가질 수 없다.   -&gt; 이것을  모델이 일반화되지 않았다  라고 말한다.       이런 경우에는 어떻게 해결해야 할까??  -&gt; 규제를 사용하여 가중치를 제한하면 모델이 몇 개의 데이터에 집착하지 않게 되므로 일반화 성능을 높일 수 있다.      앞으로 대표적인 규제 기법인 L1 규제, L2 규제에 대해 알아보고 두 기법을 이전에 구현한 SingleLayer 클래스에 적용해보려고 한다.   또한 규제를 적용하면 손실 함수의 그래프가 어떻게 변하는지도 알아보자.     L1 규제 :  손실 함수에 가중치의 절댓값인 L1 노름(norm)을 추가한다.  L1 norm을 나타내면 아래와 같다    $||w||1 = \\sum{i = 1}^{n} |w_i|$    L1 norm인 n : 가중치 갯수를 의미 -&gt; L1 규제를 가중치의 절댓값을 손실 함수에 더한 것으로 이해해도 괜찮음       이제 이 L1 규제를 로지스틱 손실 함수에 적용 해보자  먼저 로지스틱 손실 함수는    L = -(ylog(a) + (1 - y)log(1 - a))  이전에 말했듯 손실 함수에 가중치의 절댓값인 L1 norm을 추가하면 L1 규제가 만들어 진다고 했다.   그런데 단순히 L1 norm을 더하지 말고 규제의 양을 조절하는 파라미터 $\\alpha$를 곱한 후 더하자    L = -(ylog(a) + (1 - y)log(1 - a)) +$\\alpha \\sum_{i = 1}^{n} |w_i|$      $\\alpha$는 L1 규제의 양을 조절하는 하이퍼파라미터 이다.     예를 들어 보자 $\\alpha$의 값이 크다면 전체 손실 함수의 값이 커지지 않도록 w 값의 합이 작아져야 한다   -&gt; 이것을 규제가 강해졌다 (가중치가 작아 졌기 때문에) 라고 한다.   반대로 $\\alpha$의 값이 작다면  -&gt; 이것을 규제가 약해졌다 (w의 합이 커져도 손실 함수의 값이 큰 폭으로 커지지 않기 때문에)        이제는 경사 하강법으로 가중치를 업데이트하기 위해서 L1 규제를 적용한 로지스틱 손실 함수를 미분해보자   L1 규제의 미분  이전에 로지스틱 손실 함수를 가중치에 대해 미분해보았으니 계산과정은 생략 하겠다   다만 |w|를 미분하면 w 값의 부호 즉 w가 양수일시 +1, 음수일시 -1이 남기 때문에 w 값을 미분한 결과인 w의 부호라는 의미로 -&gt; sign(w)라고 표현 할 것이다.  $\\frac{\\delta}{\\delta w}L = -(y - a)x + \\alpha sign(w)$  이 식은 가중치 벡터 w에 대한 미분으로 확장하여 식을 전개하였다       또한 이 식을 가중치 업데이트 식에 적용하고   L1 규제에 학습률도 적용해 보자 -&gt; L1 규제를 적용한 손실 함수의 도함수에 학습률을 곱하면 됨   $w = w - \\eta \\frac{\\delta L}{\\delta w} = w + \\eta((y - a)x - \\alpha sign(w))$  여기서 $\\eta$는 학습률을 나타낸다    위 수식을 보면 L1 규제를 추가한 로지스틱 손실 함수르 경사 하강법으로 최적화 하는것을 생각해 보면 규제 하이퍼파라미터 $\\alpha$와 가중치의 부호를 곱해서 갱신할 gradient에 더해주면 된다.    파이썬으로 구현하려면  w_grad += alpha * np.sign(w)  여기서 변수 alpha가 규제 하이퍼파라미터이고, np.sign() 함수는 배열 요소의 부호를 반환한다.       그런데 위 식을 유도해오면서 궁금한 점이 있다..   절편에 대한 규제는 왜 안하지 ????     절편을 잘 생각해보자 절편이 변할때 모델은 어떤 방향으로 이동할지 변할 뿐 모델의 복잡도에는 영향을 주지 않기 떄문이다.       역시 사이킷런에서는 L1 규제를 쉽게 구현할 수 있게 지원해준다.   SGDClassifier 클래스에서 penalty 매개변수 값을 l1으로 지정하면 L1 규제를 적용할 수 있다.   그리고 규제의 강도를 제어하는 하이퍼파라미터 $\\alpha$를 위한 alpha 매개변수 또한 제공한다.       라쏘(Lasso) 모델 :  회귀 모델에 L1 규제를 추가한 모델을 라쏘 모델이라고 한다.     회귀 모델에도 같은 원리를 적용하여 손실 함수(제곱 오차)에 L1 규제를 적용할 수 있다.   이러한 모델을 라쏘 모델이라고 부른다.   라쏘 모델은 가중치를 줄이는 것을 넘어 일부 가중치를 0으로도 만들 수 있다.     가중치가 0인 특성은 어떤 의미를 가질까?   -&gt; 모델에서 사용할 수 없다는 것과 같은 의미를 가진다      즉 일부 가중치를 0으로 만들수 있다는 의미는 모델에서 특성을 선택할지 말지 정할 수 있는 효과를 얻는다.       당연하게도 사이킷런에서는 라쏘 모델도 지원한다.   sklearn.linear_model.Lasso 클래스에서 라쏘 모델을 제공한다.       미분 결과에서 L1 규제는 규제 하이퍼파라미터 $\\alpha$에 많이 의존함을 알 수 있다.   -&gt; 가중치의 크기에 따라 규제의 양이 변하지 않으므로 규제 효과가 좋다고 할 수는 없다.      이러한 문제점을 해결할 방안이 없을까??   -&gt; L1 규제 보다 규제 효과가 좋은 L2 규제에 대해 알아보자.     L2 규제 :  L2 규제는 손실 함수에 가중치에 대한 L2 노름(norm)의 제곱을 더한다.  L2 norm은 아래와 같이 정의된다.    $||w||2 = \\sqrt{\\sum{i = 1}^{n} |w_i|^2}$      손실 함수에 L2 norm의 제곱을 더하면 L2 규제가 된다.    L = -(ylog(a) + (1 - y)log(1 - a)) +$\\frac{1}{2} \\alpha \\sum_{i = 1}^{n} |w_i|^2$    여기서 $\\alpha$는 L1 규제와 마찬가지로 규제의 양을 조절하기 위한 하이퍼파라미터이다.   $frac{1}{2}$는 나중에 L2 규제를 미분하였을때 결과가 보기 좋게 하기 위해서 추가하였다.      L2 규제의 미분  뭐 L1 규제 미분하듯이 가중치에 대해 미분해 보면      $\\frac{\\delta}{\\delta w}L = -(y - a)x + \\alpha w$    L2 규제를 미분하면 위와 같다. 단순히 로지스틱 손실함수를 가중치에 대해 미분한 것에 간단히 가중치 w만 남음을 알 수 있다.      이 결과를 가중치 갱신 업데이트 식에 대입해보자   $w = w - \\eta \\frac{\\delta L}{\\delta w} = w + \\eta((y - a)x - \\alpha w)$  여기서 $\\eta$는 L1 규제와 같이 학습률을 나타낸다      L2 규제를 경사 하강법 알고리즘에 적용하는 방법 또한 gradient에 $\\alpha$와 가중치의 곱을 더하면 된다.   파이썬으로 구현해 보면    w_grad += alpha * w      자 이러한 L2 규제가 L1 규제보다 어떠한 점이 더 효과적인가??       L2 규제는 gradient 계산에 있어서 가중치의 값 자체가 포함된다.   하지만 L1 규제는 가중치의 부호만 사용된다.   따라서 L2 규제가 L1 규제보다 좀더 효과적이다.      아니 그런데 L2 규제는 가중치를 완전히 0으로 만들지 않잖아 그러면 원하는 특성을 제외하는 즉 모델에서 특성을 선택할지 안할지를 정할 수 없잖아.. 그럼 L1 규제 (라쏘 모델) 에 비해 이점은 안좋은거 아닌가??   -&gt; 가중치를 완전히 0으로 만들 수 있으면 특성을 제외하는 즉 선택할 수 있는 효과는 보지만 대신 모델의 복잡도가 떨어지게 된다.      즉 장단점이 있는거다. 여러가지를 따져 봤을때 L2 규제를 널리 사용한다.      릿지(Ridge) 모델 :  회귀 모델에 L2 규제를 적용한 것을 릿지 모델이라고 한다.       당연하게도 L2 릿지 모델 또한 사이킷런에서 제공한다.   sklearn.linear_model.Ridge 클래스로 제공을 한다.   SGDClassifier 클래스에서는 매개 변수인 penalty를 l2로 지정하여 L2 규제를 추가할 수 있다.   두 클래스 모두 규제의 강도는 매개 변수 alpha로 제어한다.     로지스틱 회귀에 규제를 적용해보자   자 이젠 이전에 만든 SingleLayer 클래스에 L1 규제와 L2 규제를 적용해보자.   실무에서는 L1 규제보단 L2 규제를 주로 사용한다고 하는데 왜 그런지 이번 예제를 통해 두 규제의 차이를 느껴보자.     # gradient 업데이트 수식에 패널티 항을 반영해 보자  import numpy as np  class SingleLayer:      # L1 규제와 L2 규제의 강도를 조절하는 매개변수 l1, l2를 __init__() 메서드에 추가한다.      def __init__(self, learning_rate = 0.1, l1 = 0, l2 = 0): # l1과 l2의 기본값은 0이고 이때는 규제 적용 하지 않음     self.w = None      self.b = None     self.losses = []     self.val_losses = []     self.w_history = []       self.lr = learning_rate     self.l1 = l1     self.l2 = l2    def forpass(self, x):      z = np.sum(x * self.w) + self.b     return z    def backprop(self, x, err):      w_grad = x * err     b_grad = 1 * err       return w_grad, b_grad      def activation(self, z):     z = np.clip(z, -100, None)      a = 1 / (1 + np.exp(-z))      return a    def fit(self, x, y, epochs = 100, x_val = None, y_val = None):     self.w = np.ones(x.shape[1])      self.b = 0          self.w_history.append(self.w.copy())         np.random.seed(42)      for i in range (epochs):       loss = 0       indexes = np.random.permutation(np.arange(len(x)))         for i in indexes:         z = self.forpass(x[i])         a = self.activation(z)          err = -(y[i] - a)          w_grad, b_grad = self.backprop(x[i], err)           # 가중치 gradient에서 패널티 항의 미분값을 더한다         # 이때 L1 규제와 L2 규제를 따로 적용하지 않고 하나의 식으로 작성했다.         # (L1 규제, L2 규제 동시에 수행 가능)         w_grad += self.l1 * np.sign(self.w) + self.l2 * self.w           self.w -= self.lr * w_grad          self.b -= b_grad           self.w_history.append(self.w.copy())           a = np.clip(a, 1e-10, 1 - 1e-10)           loss += -(y[i] * np.log(a) + (1 - y[i]) * np.log(1 - a))               self.losses.append(loss/len(y) + self.reg_loss()) # self.reg_loss() 추가        self.update_val_loss(x_val, y_val)    def predict(self, x):     z = [self.forpass(x_i) for x_i in x]     return np.array(z) &gt;= 0    # 검증 세트의 손실을 계산하는 update_val_loss() 메서드에서 reg_loss()를 호출하도록 수정하자   def update_val_loss(self, x_val, y_val):     if x_val is None:       return      val_loss = 0      for i in range(len(x_val)):       z = self.forpass(x_val[i])       a = self.activation(z)       a = np.clip(a, 1e-10, 1 - 1e-10)        val_loss += -(y_val[i] * np.log(a) + (1 - y_val[i]) * np.log(1 - a))      self.val_losses.append(val_loss / len(y_val) + self.reg_loss()) # -&gt; reg_loss() 호출하도록 수정    def score(self, x, y):     return np.mean(self.predict(x) == y)    # 로지스틱 손실 함수 계산에 패널티 항을 추가해보자   # 로지스틱 손실 함수를 계산할 때 패널티 항에 대한 값을 더해야함.   # 이를 위해서 reg_loss() 메서드를 SingleLayer 클래스에 추가함.    # 이 함수는 훈련 세트의 로지스틱 손실 함수의 값과 검증 세트의 로지스틱 손실 함수의 값을 계산할 때 모두 호출됨   def reg_loss(self):     return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w ** 2)   # 이제 먼제 L1 규제를 추가하여 로지스틱 회귀 모델을 훈련해보자  # cancer 데이터 세트에 L1 규제를 적용하고자 한다.  from sklearn.datasets import load_breast_cancer from sklearn.model_selection import train_test_split  import matplotlib.pyplot as plt  cancer = load_breast_cancer()  x = cancer.data y = cancer.target  x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42)  x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify = y_train_all, test_size = 0.2, random_state = 42)  train_mean = np.mean(x_train, axis = 0) train_std = np.std(x_train, axis = 0) x_train_scaled = (x_train - train_mean) / train_std  val_mean = np.mean(x_val, axis = 0) val_std = np.std(x_val, axis = 0) x_val_scaled = (x_val - val_mean) / val_std  x_val_scaled = (x_val - train_mean) / train_std  # L1 규제의 강도에 따라 모델의 학습 곡선과 가중치가 어떻게 바뀌는지 알기 위해 # 규제 강도를 0.0001, 0.001, 0.01 세 가지에 대해 확인해 보자  l1_list = [0.0001, 0.001, 0.01]  for l1 in l1_list:   lyr = SingleLayer(l1 = l1)   lyr.fit(x_train_scaled, y_train, x_val = x_val_scaled, y_val = y_val)    plt.plot(lyr.losses)   plt.plot(lyr.val_losses)      plt.title(\"Learning Curve (l1={})\".format(l1))   plt.ylabel('loss')   plt.xlabel('epoch')   plt.legend(['train_loss', 'val_loss'])   plt.ylim(0, 0.3)   plt.show()    plt.plot(lyr.w, 'bo')   plt.title('Weight (l1 = {})'.format(l1))   plt.ylabel('value')   plt.xlabel('weight')   plt.ylim(-4, 4)   plt.show()                     각 그래프들을 보면 꺾은선 그래프는 학습 곡선 그래프이고 산점도는 가중치에 대한 그래프 이다.     학습 곡선 그래프를 보면 규제가 더 커질수록 훈련 세트의 손실과 검증 세트의 손실 모두 높아지는 것을 확인 가능하다.   즉 과소 적합 현상이 나타난다.       가중치 그래프를 보면 규제 강도 l1 값이 커질수록 가중치의 값이 0에 가까워지는 것을 확인할 수 있다.   그래프를 보면 적절한 l1 하이퍼파라미터 값은 0.001로 보인다.   따라서 이 값을 이용하여 모델의 성능 확인해 보겠다.     layer5 = SingleLayer(l1 = 0.001) layer5.fit(x_train_scaled, y_train, epochs = 20) layer5.score(x_val_scaled, y_val)  # 결과를 확인해보니 규제를 적용하지 않고 검증 세트로 성능을 평가했던 결과와 똑같은 정확도를 보인다. # 그럼 굳이 왜 L1 규제를 했지?? # 사실 이번에 적용한 데이터 세트의 크기가 작기 때문에 L1 규제의 효과가 크게 나타나지 않은 것이다.   0.978021978021978   # 이제는 L2 규제를 적용해 보자  # cancer 데이터 세트에 L2 규제를 적용해 보자  l2_list = [0.0001, 0.001, 0.01]  for l2 in l2_list:   lyr = SingleLayer(l2 = l2)   lyr.fit(x_train_scaled, y_train, x_val = x_val_scaled, y_val = y_val)    plt.plot(lyr.losses)   plt.plot(lyr.val_losses)      plt.title(\"Learning Curve (l2={})\".format(l2))   plt.ylabel('loss')   plt.xlabel('epoch')   plt.legend(['train_loss', 'val_loss'])   plt.ylim(0, 0.3)   plt.show()    plt.plot(lyr.w, 'bo')   plt.title('Weight (l2 = {})'.format(l2))   plt.ylabel('value')   plt.xlabel('weight')   plt.ylim(-4, 4)   plt.show()                     두 그래프를 보면 L2 규제 또한 L1 규제와 비슷한 양상을 보이는 것을 알 수 있다.       그런데 마지막 학습 곡선 그래프를 보자 (L2 = 0.01)  L2 규제는 규제 강도가 강해져도 L1 규제에 비해 과소 적합이 심해지지는 않는 것으로 보인다.     또한 가중치 그래프를 보아도 가중치가 0에 매우 가깝게 줄어들지는 않는다는 것도 확인할 수 있다.     # L2 규제를 적용한 모델은 50 epoch 횟수만큼 훈련하고 성능을 확인해 보자 # 이 때는 l2 = 0.01 의 규제 강도에 대해 적용해 보겠다.  layer6 = SingleLayer(l2 = 0.01) layer6.fit(x_train_scaled, y_train, epochs = 50) layer6.score(x_val_scaled, y_val)  # 성능을 보니 정확도가 L1 규제와 같다.. # -&gt; L1 규제를 한 모델이나 L2 규제를 한 모델이나 성능이 큰 차이가 없다. # 즉 두 모델 모두 검증 샘플에 대해 예측한 샘플이 똑같다.(정확하게 예측한 샘플 수가 동일)   0.978021978021978   np.sum(layer6.predict(x_val_scaled) == y_val)  # 총 91개 샘플 중 89개를 맞춘 것이다.   89   위 결과를 보면 L1 규제를 쓰나 L2 규제를 쓰나 같은 결과가 나왔다.   하지만 L1 규제를 썼을때 보다 L2 규제를 썼을때 epoch가 크게 늘어났다.   L1 규제는 20번의 epoch 동안 훈련 했지만 L2 규제의 경우 50번의 epoch 동안 훈련을 했다.     그 이유는 L2 규제의 경우 가중치를 강하게 제한했기 때문에 알고리즘이 검증 세트의 손실값을 일정 수준으로 유지하면서 전역 최솟값을 찾는 과정을 오래 반복할 수 있었기 때문이다.      이전에 말했듯 사이킷런에서 L1 규제와 L2 규제를 지원한다고 하였다.   사이킷런을 이용해 L1, L2 규제를 사용해보자     # SGDClassifier에서 규제를 사용해 보자  # 매개변수 penalt에 l1 이나 l2를 매개변수 값으로 전달하고  # 매개변수 alpha를 통해 규제의 강도를 정하면 된다.  from sklearn.linear_model import SGDClassifier  # L2 규제로, 규제의 강도는 alpha = 0.001로 모델을 만들자 sgd = SGDClassifier(loss='log', penalty='l2', alpha=0.001, random_state=42) sgd.fit(x_train_scaled, y_train) sgd.score(x_val_scaled, y_val)  # 이 경우에 당연히 위의 결과와 같다.   0.978021978021978   사이킷런에서는 SGDClassifier 클래스 말고도 L1, L2 규제를 제공하는 모델이 많다.  ex) LogisticRegression, SVC, LinearSVC 클래스 등등   이 클래스들은 매개변수 penalty 대신 주손실 함수의 크기를 조절하기 위해 하이퍼파라미터 C를 제공한다.   (SGDClassifier 클래스에서 매개변수 alpha를 사용하여 규제를 제어하는 것과 유사)  -&gt; 이때 C는 alpha와 반대의 역할을 한다.     매개변수 C가 커지면 규제가 줄고 C가 작으면 규제가 강해지는 것이다.      지금까지 L1, L2 규제에 대해 알아보았다.   다음에는 훈련 노하우 중 교차 검증에 대해 알아볼 것이다. 이 검증 방법은 전체 데이터 세트의 샘플 수가 적을때 사용할 수 있는 방법니다.       Reference    박해선, 딥러닝 입문, 이지스퍼블리싱, 2019, 137 ~ 148pg  ","categories": ["Deep_Learning"],
        "tags": ["L1 규제","L1 규제의 미분","라쏘 모델","L2 규제","L2 규제의 미분","릿지 모델","가중치 업데이트 식","penalty"],
        "url": "/deep_learning/Training_Know_How(3)/",
        "teaser": null
      },{
        "title": "MySQL을 배우기 전 알아야할 용어",
        "excerpt":"이번에는 MySQL을 본격적으로 배우기 전에 꼭 알아야할 용어들을 정리해보려고 한다.      데이터 :  정보는 있으나 아직 체게화 되지 못한 상태로 하나하나의 단편적인 정보      테이블 :  데이터를 입력하기 위해 표 형태로 표현한 것      데이터베이스(DB) :  테이블이 저장되는 저장소이다.   각 데이터베이스는 서로 다른 고유한 이름을 가져야만 한다.      DBMS(DataBase Management System) :  DB를 관리하는 시스템 혹은 소프트웨어      열(column = field) :  어떠한 의미를 지니는 정보의 한 조각으로 각 테이블은 열로 구성된다.   DBMS에서 처리의 최소 단이 이다. 열은 대표적인 예로는 이름, 주소 등등 이 있다.       열 이름 :  각 열을 구분하기 위한 이름   열 이름은 각 테이블 내에서는 중복되지 않고 고유해야 한다.      데이터 형식 :  정확히는 열의 데이터 형식을 말하는데  예를 들어 이름 경우 문자 형식, 가격인 경우 숫자 형식 이어야 한다.  데이터 형식은 테입ㄹ을 생성할 때 열의 이름과 함께 지정해줘야 한다.        : 행(row = record) :  실질적인 데이터를 말한다.   예를들어 jo/010-**-**/창원시 ~~ / 이 하나의 행으로 행 데이터라고 부른다.          기본 키(Primary Key) 열 :  기본 키 열은 각 행을 구분하는 유일한 열이다.   기본 키의 특징으로는 절대 중복되어서는 안되고 비어있어서도 안된다.   또한 각 테이블에는 기본 키가 하나만 지정되어 있어야만 한다.     왜 이러한 특징을 가져아 할까?   예를 들어 이해를 해보면 회원 테이블이 있다고 가정하자   회원 테이블의 열은 이름, 주소, 아이디 등이 있다고 하자   기본 키 열을 이름 열로 지정한다고 해보자 만약 동명인이 있다면 각 행을 구분하는 유일한 열이 될 수 없다   만약 기본 키 열을 주소로 지정한다고 해도 같은 지역에 산다고 한다면 위와 같은 문제가 발생한다.   그렇다면 같은 아이디를 만들 수 없다면 아이디 열을 기본 키 열로 지정한다면 각 행을 구분하는 유일한 열이 될 수 있을 것이다.   따라서 이 경우 아이디 열을 기본 키 열로 지정하는 것이 적합하다.      외래 키(Foreign Key) 필드:  두 테이블의 관계를 맺어주는 키이다.   외래 키는 한 테이블의 열 중 다른 테이블의 행을 식별할 수 있는 키를 말한다.   예를 들어 상품 테이블과 주문 테이블이 있다고 가정하자   상품 테이블의 열은 상품 번호, 상품명, 가격 등이 있고  주문 테이블의 열은 주문 번호, 주문 날짜, 상품 번호 가 있다고 하자  주문 테이블의 열 중 상품 번호는 상품 테이블에서도 존재하는 열이고 거기다가 상품 테이블에서 각 행마다 상품 번호는 다르다.   따라서 주문 테이블의 상품 번호 열은 상품 테이블의 행을 식별할 수 있기 때문에 외래키 키 열(필드)이 될 수 있다.        SQL(Structured Query Language):  DBMS에 무슨 작업을 하고 싶을때 DBMS가 알아들을 수 있는 언어로 전달을 해야한다.   이때 DBMS에게 전달하는 언어가 SQL이다.      Reference    우재남, 이것이 MySQL이다, 한빛미디어, 2020, 50~54pg   ","categories": ["MySQL"],
        "tags": ["용어"],
        "url": "/mysql/MySQL_word/",
        "teaser": null
      },{
        "title": "순수 자바로만 작성하는 예제_주문 할인 도메인 개발",
        "excerpt":"이전에는 회원 도메인 설계를 했다면 이제는 주문 할인 도메인 설계를 해보려 한다.   주문 할인 도메인 설계  주문 할인 정책     회원은 상품을 주문할 수 있음     회원의 등급에 따라 할인 정책을 적용할 수 있음     할인 정책은 모든 VIP 등급의 경우에는 1000원을 할인해주는 고정 금액 할인을 적용하려 한다. (하지만 변경 될 수도 있다.)     할인 정책은 변경 가능성이 높다. 왜냐하면 회사에서 기본 할인 정책을 하직 정하지 못했기 때문이다. 오픈 직전까지 고민을 미루려고 하고, 최악의 경우에는 할인을 적용하지 않을 수도 있다.         주문 도메인 협력, 역할, 책임 관계             주문 생성 : 클라이언트가 주문 서비스에 주문 생성을 요청     회원 조회 : 할인을 위해서 회원 등급이 필요하기 때문에 주문 서비슨는 회원 저장소에서 회원을 조회하여 해당 회원의 등급을 알아야 한다.     할인 적용 : 주문 서비스는 해당 회원의 등급을 확인한 후 할인 여부를 할인 정책에 위임한다.     주문 결과 반환 : 주문 서비스는 할인 결과를 포함한 전체 주문에 대한 결과를 클라이언트에게 반환한다.       참고로 실제 주문 데이터는 DB에 저장할 것이다. 하지만 여기 예제에서는 생략하고 단순하게 주문 결과를 반환하는 정도로 구현할 것이다.       주문 도메인 전체  주문 할인 도메인 뿐만 아니라 이전에 구현했던 회원 도메인까지 다 합친 주문 도메인 전체에 대해 나타내면            위 처럼 설계를 하면 역할과 구현을 분리했기 때문에 자유롭게 구현 객체를 조립할 수 있다.  따라서 아직 정확히 결정되지 않은 회원 저장소, 할인 정책 또한 유연하게 변경할 수 있다.        주문 도메인 클래스 다이어그램  주문 도메인 클래스 다이어그램을 나타내보면          2 가지 객체 다이어그램을 생각해 볼 것이다.    주문 도메인 객체 다이어그램1  먼저 첫 번째는 회원 정보를 메모리 회원 저장소에 저장하고, 할인 정책을 정액 할인 정책을 이용하는 경우이다         주문 서비스 구현체는 new OrderServiceImpl();을 통해  메모리 회원 저장소는 new MemoryMemerRepository();를 통해  정액 할인 정책은 new FixDiscountPolicy();를 통해  객체를 생성하고자 한다.       회원 정보를 메모리 회원 저장소에서 조회하고 정액 할인 정책을 지원해도 주문 서비스를 변경하지 않아도 된다.   역할들의 협력 관계를 그대로 재사용할 수 있다.   만약 메모리를 DB로 바꾼다해도, 정액 할인을 정률 할인으로 바꾼다고 해도 주문 서비스 구현체에도 영향이 없다   -&gt; 역할과 구현을 분리했기에 가능한 것이다.      주문 도메인 객체 다이어그램2  주문 도메인 객체 다이어그램1에서 메모리를 DB로, 정액 할인을 정률 할인으로 바꾼 경우이다.       이 부분은 아직 정확히 구현은 하지 않고 나중으로 미루겠다.      회원을 메모리가 아닌 실제 DB에서 조회하고 정률 할인 정책을 지원해도 주문 서비스를 변경하지 않아도 된다는 것을 이 객체 다이어그램을 통해 알 수 있다.  즉 협력 관계를 그대로 사용할 수 있다.    이전에 설명했지만 역할과 구현을 분리했기에 가능한 것이다.      주문 할인 구조를 기준으로 코드로 작성해보도록 하자.     주문과 할인 도메인 개발   할인 정책 인터페이스  package hello.spring_basic.discount;  import hello.spring_basic.member.Member;  public interface DiscountPolicy {      /**      * @return 할인 대상 금액      */     int discount(Member member, int price); //할인 기능 함수 선언  }   정액 할인 정책 구현책   package hello.spring_basic.discount;  import hello.spring_basic.member.Grade; import hello.spring_basic.member.Member;  public class FixDiscountPolicy implements DiscountPolicy{      private int discountFixAmount = 1000; // 1000원 할인      @Override     public int discount(Member member, int price) {         if (member.getGrade() == Grade.VIP) { // 현재 회원이 VIP 등급이면             return discountFixAmount; // discountFixAmount 리턴 (즉 1000원 리턴)         }          else { // 현재 회원이 VIP가 아니라면             return 0; // 0을 리턴해라         }     } }        주문 엔티티   package hello.spring_basic.order;  public class Order {     private Long memberId; // 회원 아이디      private String itemName; // 물건 이름     private int itemPrice; // 물건 가격     private int discountPrice; // 할인 가격      public Order(Long memberId, String itemName, int itemPrice, int discountPrice) {         this.memberId = memberId;         this.itemName = itemName;         this.itemPrice = itemPrice;         this.discountPrice = discountPrice; //Order 위해 필요한 정보들     }      public int calculatePrice() {         return itemPrice - discountPrice; //정액 할인 정책에 맞게끔 할인 적용     }      public Long getMemberId() {         return memberId;     }      public void setMemberId(Long memberId) {         this.memberId = memberId;     }      public String getItemName() {         return itemName;     }      public void setItemName(String itemName) {         this.itemName = itemName;     }      public int getItemPrice() {         return itemPrice;     }      public void setItemPrice(int itemPrice) {         this.itemPrice = itemPrice;     }      public int getDiscountPrice() {         return discountPrice;     }      public void setDiscountPrice(int discountPrice) {         this.discountPrice = discountPrice;     }      @Override     public String toString() {         return \"Order{\" +                 \"memberId=\" + memberId +                 \", itemName='\" + itemName + '\\'' +                 \", itemPrice=\" + itemPrice +                 \", discountPrice=\" + discountPrice +                 '}';     }     /*     toString함수 특징은 객체 자체를 출력하면 toString()이 호출이 됨.      ex)     order라는 객체가 있다면     System.out.println(order); -&gt; order 내의 toString()함수 호출      */ }        주문 서비스 인터페이스  package hello.spring_basic.order;  public interface OrderService {     Order createOrder(Long memberId, String itemName, int itemPrice); // createOrder 선언 }       주문 서비스 구현체  package hello.spring_basic.order;  import hello.spring_basic.discount.DiscountPolicy; import hello.spring_basic.discount.FixDiscountPolicy; import hello.spring_basic.member.Member; import hello.spring_basic.member.MemberRepository; import hello.spring_basic.member.MemoryMemberRepository;  public class OrderServiceImpl implements OrderService {      //OrderService는 2개가 필요     private final MemberRepository memberRepository = new MemoryMemberRepository(); // memberRepository에서 회원 찾아야 하므로     private final DiscountPolicy discountPolicy = new FixDiscountPolicy(); // discountPolicy에서 할인 정책되로 적용 해야하므로      @Override     public Order createOrder(Long memberId, String itemName, int itemPrice) {          Member member = memberRepository.findById(memberId); // member를 일단 찾자..          int discountPrice = discountPolicy.discount(member, itemPrice);         //OrderService 입장에선 할인에 대해서느 잘 모르겠으니 discountPolicy 에게 그 일을 맡기고 결과만 받는 다고 생각         //-&gt; 설계가 잘 된 (SRP (단일책임원칙) 잘 지킨 것)         //만약 할인에 대해 변경할 사항이 있으면 할인에 대한 부분만 고치면 되고 주문에 관련된 부분은 고칠 필요가 없기 때문에          return new Order(memberId, itemName, itemPrice, discountPrice); //Order를 만들어 반환.          /*         정리하면 주문 생성요청이 오면 회원정보를 먼저 조회를 하고 할인 정책에 회원을 넘기고         결과들을 이용해 주문을 만들어 반환한다.          MemoryMemberRepository()와 FixDiscountPolicy()을 구현체로 생성함          */     } }        자 이제 주문 할인 도메인 개발을 해 보았으니 제대로 작동하는지 테스트를 해보자.       주문 할인 도메인 실행과 테스트를 해보자.   주문과 할인 도메인 생성과 테스트      회원 도메인 테스트 할때 순서처럼 main 함수를 만들어 해당 멤버가 vip일때 할인 정책을 적용하고 실제로 잘 적용 받는지 확인해 보자     주문과 할인 정책 실행  package hello.spring_basic;  import hello.spring_basic.member.Grade; import hello.spring_basic.member.Member; import hello.spring_basic.member.MemberService; import hello.spring_basic.member.MemberServiceImpl; import hello.spring_basic.order.Order; import hello.spring_basic.order.OrderService; import hello.spring_basic.order.OrderServiceImpl;  public class OrderApp {     public static void main(String[] args) {         MemberService memberService = new MemberServiceImpl(); //memberservice 만들고         OrderService orderService = new OrderServiceImpl(); //orderservice 만듬          Long memberId = 1l; //멤버 아이디 생성         Member member = new Member(memberId, \"memberA\", Grade.VIP); // Member 객체 생성 (vip 회원 만듬)         memberService.join(member); //memberService를.join 통해 메모리 객체에 넣어둠 -&gt; 그래야 주문에서 찾아 쓸 수 있으니          Order order = orderService.createOrder(memberId, \"iteA\", 10000); //orderService.createOrder를 통해 order 생성          System.out.println(\"order =\" + order); //order.toString()으로 정의한 내용들이 출력 (order클래스를 보면 toString()함수 정의해놨음)         //order라는 객체 자체를 출력했으므로 order내의 toString()함수가 호출 됨     } }   main 함수를 실행시켜보면        위 그림과 같이 문제없이 잘 실행이 된다.      이전에 이야기 했듯이 이러한 방법으로 테스트 하는 것은 좋지 않은 방법이다.   (애플리케이션 로직으로 위의 방식으로 테스트 하는 방법)      -&gt; JUnit 테스트를 이용한다      주문과 할인 정책 테스트   package hello.spring_basic.order;  import hello.spring_basic.member.Grade; import hello.spring_basic.member.Member; import hello.spring_basic.member.MemberService; import hello.spring_basic.member.MemberServiceImpl; import org.assertj.core.api.Assertions; import org.junit.jupiter.api.Test;  public class OrderServiceTest {     MemberService memberService = new MemberServiceImpl();     OrderService orderService = new OrderServiceImpl();      @Test     void createOrder() {         Long memberId = 1L;         Member member = new Member(memberId, \"memberA\", Grade.VIP);         memberService.join(member);          Order order = orderService.createOrder(memberId, \"itemA\", 10000);         Assertions.assertThat(order.getDiscountPrice()).isEqualTo(1000); //VIP경우 1000원 할인해주기로 했으니 그게 되는지 확인해보자.     } }      OrderServiceTest 클래스를 실행시켜보면     위 그림에서 아무 문제없다는 결과를 내 놓는다.         지금까지 “주문 도메인 전체”에 대해 만들었다.   이후에는 할인정책을 바꾸었을때 객체지향적으로 잘 개발됬을지 (변경 용이, 클라이언트에 영향 안받을지) 확인해보자       Reference :  김영한 강사님 스프링 핵심 원리 - 기본편  강의 중  ","categories": ["Spring"],
        "tags": ["순수 자바 코드로 개발","주문 할인 도메인","실행과 테스트"],
        "url": "/spring/spring_basic(3)/",
        "teaser": null
      },{
        "title": "SQL 기본",
        "excerpt":"이번에는 기본적인 SQL 문장인 SELECT, INSERT, UPDATE, DELETE에 대해 알아볼 것이다.      실습을 통해 진행할 것인데  샘플 데이터베이스로 emplyees라는 이름을 가진 데이터베이스를 사용할 것이다      SELECT  : SELECT는 데이터베이스 내의 테이블에서 원하는 정보를 추출하는 명령이다.    SELECT문이 매우 간단해 보이지만 다양한 옵션이 존재한다. 하지만 많이 사용되는 형태로 구조를 요약해보면     SELECT select_expr     [FROM table-references]     [WHERE where_condition]     [GROUP BY {col_name | expr | position}]     [HAVING where_condition]     [ORDER BY {col_name | expr | position}]       위의 내용도 복잡해 보인다면 좀더 자주 사용하고 간단한 형태로 구조를 나타내면     SELECT 열 이름 FROM 테이블 이름 WHERE 조건       간단히 SELECT 구문은 이러한 형태임을 알 수 있고 지금부터는 하나하나 옵션을 붙여가며 SELECT에 대해 알아보자.      USE 구문  SELECT문 뿐만 아니라 다른 명령어를 사용하기 전에 사용할 데이터베이스를 지정해야 한다.   따라서 해당 데이터베이스를 지정하거나 변경해야할 경우 USE 구문을 사용한다.      현재 사용하는 데이터베이스를 지정하거나 변경하는 구문은 아래와 같다.   USE 데이터베이스_이름;      만약 employees라는 이름을 가진 데이터베이스를 사용하기 위해 쿼리 창에 아래와 같이 입력하면 된다.   USE employees;       만약 이렇게 데이터베이스를 지정해둔다면 다시 USE문을 사용한다던지 다른 DB를 사용하겠다는 명시를 하지 않는다면 모든 SQL문은 employees라는 이름을 가진 데이터베이스에서 수행된다.   SELECT와 FROM   USE employees; SELECT * FROM titles;    -&gt; employees 데이터베이스를 선택한 후 -&gt; titles라는 테이블에서 모든 열의 내용을 가져와라     *이 나온 위치는 해당 테이블의 열 이름이 나오는 위치이다.  그런데 열 이름대신 *가 나오면 모든 열을 의미한다.     FROM 다음에는 테이블/뷰의 항목이다.      사실 원칙적으로는 테이블의 전체 이름은   “데이터베이스이름.테이블이름” 형식으로 표현된다.  따라서 위의 SELECT 구문을 정확히 작성하면     SELECT * FROM emplyees.titles;    가 된다.      그러나 데이터베이스 이름을 생략해도 이전에 USE를 이용하여 선택된 데이터베이스 이름이 자동으로 붙게 된다.      titles 테이블의 모든 열을 가져오니 결과가 아래와 같다      데이터가 무수히 많지만 일부분만 보인 것이다.      그럼 이제는 전체 열이 아닌 특정 열만 가져와보자   사원 테이블의 이름만 가져와 보쟈    SELECT first_name FROM employees;    titles 테이블의 first_name 열만을 가져오면 아래와 같다.         여러개의 열을 가져오고 싶다면 콤마(,)로 구분하면 되고  열 이름의 순서는 마음대로 바꿔도 된다.  결과 또한 명령어에서 작성한 열 이름 순서대로 나온다.     SELECT first_name, last_name, gender FROM employees;         결과를 보니 first_name, last_name, gender 열이 작성한 순서대로 나왔음을 확인할 수 있다.   ","categories": ["MySQL"],
        "tags": ["SELECT","INSERT","UPDATE","DELETE"],
        "url": "/mysql/MySQL_basic/",
        "teaser": null
      },{
        "title": "순수 자바로만 작성하는 예제_새로운 할인 정책 개발",
        "excerpt":"자 이제는 기획자가 할인 정책을 이전에 구현했던 방식인 정액 할인이 아닌 정률 할인으로 변경을 원한는 상황이라고 가정하자    회원이 VIP인 경우 10% 할인을 해주자.      갑자기 할인 정책이 바뀌어서 난감하지만 역할과 구현을 분리를 잘 하여 개발하였다면 변경에 용이할 것이다.   개발을 하면서 지금까지 정말 객체지향 설계 원칙을 잘 준수했다면 큰 문제가 없을 것인데 과연 잘 준수하였는지 확인해보자      자 정률 할인을 구현하기 위해 정률 할인에 대해 구현해보자   정률 할인 정책 RateDiscountPolicy 클래스 다이어그램  RateDiscountPolicy 클래스 다이어그램을 추가해보자. 아래와 같다.        RateDiscountPolicy(정률 할인 정책) 관련 코드   package hello.spring_basic.discount;  import hello.spring_basic.member.Grade; import hello.spring_basic.member.Member;  public class RateDiscountPolicy implements DiscountPolicy { // 이전에 작성한 인터페이스인 DiscountPolicy 상속      private int discountPercent = 10; // 10 % 할인 할 것이니      @Override     public int discount(Member member, int price) {         if (member.getGrade() == Grade.VIP) {             return price * discountPercent / 100; // 해당 회원이 VIP라면 10% 할인              // return price * (discountPercnet / 100) 하면 discountPercnet가 100이 아닌 이상 전부 결과가 0이 됨             // discountPercnt / 100 결과가 0.~~ 인 경우 int 형으로 0이 되기 때문 !! 조심         }          else {             return 0; // 회원이 VIP 아닐 시 할인 적용 X         }     } }    지금 작성한 메서드인 discount가 잘 구현되었는지 걱정이 된다…  이 부분이 잘 구현되었는지 테스트 해보자.       RateDiscountPolicy 잘 작성하였는지 테스트   package hello.spring_basic.discount;  import hello.spring_basic.member.Grade; import hello.spring_basic.member.Member; import org.assertj.core.api.Assertions; import org.junit.jupiter.api.DisplayName; import org.junit.jupiter.api.Test;  import static org.assertj.core.api.Assertions.*; import static org.junit.jupiter.api.Assertions.*;  class RateDiscountPolicyTest { // VIP 회원이 10% 할인이 잘 되는지 테스트 해보자      RateDiscountPolicy discountPolicy = new RateDiscountPolicy();      @Test     @DisplayName(\"VIP는 10% 할인이 적용되어야 한다.\")     void vip_o() {         //given         Member member = new Member(1L, \"memberVIP\", Grade.VIP); // 회원이 VIP임          //when         int discount = discountPolicy.discount(member, 10000); //가격이 10000원일때 할인되는 가격          //then         assertThat(discount).isEqualTo(1000); // 10000원의 10% 할인가격은 1000원 되어야하므로                                               // discount가 1000원이 되는지 확인해봐야한다.     }      // 테스트에서 중요한 점은 성공테스트뿐만 아니라 실패테스트도 만들어 봐야한다.     @Test     @DisplayName(\"VIP가 아니면 할인이 적용되지 않아야 한다.\")     void vip_x() {         //given         Member member = new Member(2L, \"memberBASIC\", Grade.BASIC); // 회원이 VIP가 아닌 일반 회원임          //when         int discount = discountPolicy.discount(member, 10000); // 가격이 10000원일때 할인되는 가격          //then         assertThat(discount).isEqualTo(1000); // 여기서 같지 않아야한다. 회원이 VIP가 아니기 때문에 할인된 가격이 0원이 되야하므로     } }     먼저 성공하는 경우 즉 할인이 제대로 되어야 하는 상황에 테스트를 해본 결과를 확인해보자.   즉 회원이 VIP인 경우 할인이 잘 적용되었는지 확인해본다.   vip_o() 메서드에 해당       vip_o() 실행 결과 제대로 할인이 잘 된 것을 알 수 있다.     그리고 실패하는 경우 즉 할인이 제대로 되지 않는 상황에 테스트를 해본 결과를 확인해 보자.   즉 회원이 VIP가 아닌 BASIC인 경우 할인이 적용이 되었는지 확인해 본다.   vip_x() 메서드에 해당        vip_x() 실행 결과 제대로 할인이 되지 않은 것을 알 수 있다.  회원이 VIP가 아니면 할인이 되면 안되니 예상한 결과대로 잘 나온것을 확인할 수 있다.     vip_x() 메서드를 에러가 나지 않도록 다시 바꾸면    // 테스트에서 중요한 점은 성공테스트뿐만 아니라 실패테스트도 만들어 봐야한다.     @Test     @DisplayName(\"VIP가 아니면 할인이 적용되지 않아야 한다.\")     void vip_x() {         //given         Member member = new Member(2L, \"memberBASIC\", Grade.BASIC); // 회원이 VIP가 아닌 일반 회원임          //when         int discount = discountPolicy.discount(member, 10000); // 가격이 10000원일때 할인되는 가격          //then         assertThat(discount).isEqualTo(0); // 회원이 VIP가 아니기 떄문에 할인 가격이 0원 되야함.     }    다시 vip_x() 부분을 실행시켜 보면      문제 없이 잘 실행 되는것을 확인할 수 있다.     지금까지 바뀐 할인정책을 추가하고 테스트까지 완료하였다.  앞으로는 바뀐 할인정책을 적용해보도록 해자    인터페이스에만 의존하도록 코드 변경    public class OrderServiceImpl implements OrderService {      //OrderService는 2개가 필요     private final MemberRepository memberRepository = new MemoryMemberRepository(); // memberRepository에서 회원 찾아야 하므로     //private final DiscountPolicy discountPolicy = new FixDiscountPolicy(); // discountPolicy에서 할인 정책되로 적용 해야하므로     private final DiscountPolicy discountPolicy = new RateDiscountPolicy(); // 정액 할인에서 정률 할인으로 바꿈    할인 정책을 변경하기 위해 클라이언트인 OrderServiceImpl에 있는 코드를 변경하면 된다.   문제점 발견  지금까지 코드에는 문제점이 있다. (이전에 한번 언급한적 있음)   도대체 어떤 문제일까??      자 지금까지 코드를 작성하면서           역할과 구현을 충실하게 분리했나 ?? -&gt; 했지..   ex) 역할 : DiscountPolicy, 구현 : FixDiscountPolicy, RateDiscountPolicy              다형성도 잘 활용하고, 인터페이스와 구현 객체를 분리했나 ?? -&gt; 했지               DIP, OCP 같은 객체 지향 설계 원칙을 충실히 준수했나 ??   -&gt; 한거..같은데?? -&gt;  사실 제대로 지키지 않았다.           아니 어디서 객체 지향 설계 원칙을 안지켰지??   이전에도 언급한 적 있지만 DIP, OCP를 지키지 못하엿다.      먼저 DIP를 지키지 못하였다.   주문 서비스 클라이언트 OrderServiceImpl을 보면 DiscountPolicy 인터페이스에 의존하면서 DIP를 잘 지켰는데 ??       클래스의 의존관계를 분석해 보자  추상(인터페이스) 뿐만 아니라 구체(구현) 클래스에도 의존하고 있는것을 확인할 수 있다. 아래를 보자      추상(인터페이스) 의존 : DiscountPolicy   구체(구현) 클래스 : FixDiscountPolicy, RateDiscountPolicy     정액 할인 정책을 구현한 상황일때   클라이언트인 OrderServiceImpl이 DiscountPolicy(인터페이스) 에만 의존하는 줄 알았는데   실제로는 FixDiscountPolicy(구현)에도 의존하는 것을 알 수 있다.       클래스 다이어그램을 통해 의존관계를 보자.   기대했던 의존관계로는 아래와 같다.     이 관계를 보면 클라이언트인 OrderServiceImpl은 단순히 인터페이스인 DiscountPolicy에만 의존한다고 생각했음      실제 의존관계는 아래와 같다.     이 관계를 보면 클라이언트인 OrderServiceImpl이 단순히 인터페이스인 DiscountPolicy 뿐만 아니라 구체 클래스인 FixDiscountPolicy에도 의존하고 있음을 볼 수 있다.     실제 작성한 코드를 보면 이러한 의존관계를 가지고 있고 따라서 DIP 위반을 하고있는 코드이다.   private final DiscountPolicy discountPolicy = new FixDiscountPolicy();  이 코드를 보면 알 수 있다.       그리고  OCP 또한 지키지 못하였다.  변경하지 않고 확장할 수 있다며..   -&gt; 지금 코드는 기능을 확장해서 변경하면 클라이언트 코드에 영향을 준다 따라서 OCP를 위반한다.      어떠한 경우에 ??   정액 할인 정책에서 정률 할인 정책으로 바뀐 경우 클래스 다이어그램을 통해 의존관계를 보자.         정액 할인에서 정률 할인으로 할인정책을 바꾸었기 때문에   FixDiscountPolicy를 RateDiscountPolicy로 변경하였고 OrderServiceImpl의 소스코드 또한 함께 변경해야한다…   즉 OCP를 위반하게 되었다.   이전에 예를 든 것을 그대로 이용하면 차를 바꾸었더니 운전자가 운전하는 방법을 새로 배워야하는 상황인 것이다      실제 작성한 코드 일부를 보면   public class OrderServiceImpl implements OrderService {      //OrderService는 2개가 필요     private final MemberRepository memberRepository = new MemoryMemberRepository(); // memberRepository에서 회원 찾아야 하므로     //private final DiscountPolicy discountPolicy = new FixDiscountPolicy(); // discountPolicy에서 할인 정책되로 적용 해야하므로     private final DiscountPolicy discountPolicy = new RateDiscountPolicy(); // 정액 할인에서 정률 할인으로 바꿈    FixDiscountPolicy를 RateDiscountPolicy로 변경하니 OrderServiceImpl 또한 변경하게 된 것이다.   -&gt; 즉 이 코드르 보면 변화로 인해 기존의 코드가 변경되었으므로 OCP를 위반하였음을 알 수 있다.       하.. 이거 어떻게 해결하지 ??   인터페이스에만 의존하면서 새로운 기능을 어떻게 추가할 수 있지 ? 즉 DIP를 어떻게 지키지…  기능을 변경하였을떄 기존의 코드를 변경하지 않고 어떻게 변경하지 ?? 즉 OCP를 어떻게 지키지?       어떻게 위와 같은 문제를 해결할 것인가?  자 지금까지 어떠한 문제가 있었는지 다시한번 정리해 보자.      DIP 위반 :   클라이언트 코드인 OrderServiceImpl은 인터페이스인 DiscountPolicy 뿐만아니라 구체 클래스도 함께 의존하는 문제가 있다.       OCP 위반 :   따라서 구체 클래스를 변경할 때 클라이언트 코드도 변경해야 했다.      DIP 위반으로 인해 OCP 위반이 되었음을 알 수 있다.      그럼 DIP를 위반하지 않도록 변경하면 될 것이다.   어떻게 ??   -&gt; DIP를 위반하지 않도록 인터페이스에만 의존하게 의존관계를 변경하면 될 것이다.      인터페이스에만 의존하도록 설계를 변경      이런 의존 관계를 가지게 설계를 변경해야 한다.   이 부분처럼 하기 위해 코드를 변경해 보자    인터페이스에만 의존하도록 코드 변경   public class OrderServiceImpl implements OrderService {      //OrderService는 2개가 필요     private final MemberRepository memberRepository = new MemoryMemberRepository(); // memberRepository에서 회원 찾아야 하므로     //private final DiscountPolicy discountPolicy = new FixDiscountPolicy(); // discountPolicy에서 할인 정책되로 적용 해야하므로     //private final DiscountPolicy discountPolicy = new RateDiscountPolicy(); // 정액 할인에서 정률 할인으로 바꿈     private DiscountPolicy discountPolicy; // 인터페이스에만 의존하도록 변경 (구체 클래스에 의존 하지 않음)   위의 코드를 보면   이전 private final DiscountPolicy discountPolicy = new RateDiscountPolicy(); 코드를  private DiscountPolicy discountPolicy; 로 변경함으로써  인터페이스에만 의존하도록 바꾸었다.      당연하게도 구현체가 없으므로 코드가 실행이 안된다…  OrderServiceTest 클래스르 실행시켜보면 아래와 같다.      NPE(Null Pointer Exception)이 발생했다.   왜 NPE가 발생했을까?   OrderServiceTest 클래스 코드 일부를 보자    public class OrderServiceTest {     MemberService memberService = new MemberServiceImpl();     OrderService orderService = new OrderServiceImpl();      @Test     void createOrder() {         Long memberId = 1L;         Member member = new Member(memberId, \"memberA\", Grade.VIP);         memberService.join(member);          Order order = orderService.createOrder(memberId, \"itemA\", 10000);         Assertions.assertThat(order.getDiscountPrice()).isEqualTo(1000); //VIP경우 1000원 할인해주기로 했으니 그게 되는지 확인해보자.     } }  Order order = orderService.createOrder(memberId, “itemA”, 10000); 에서   orderService의 createOrder() 함수를 실행시키면     OrderServiceImpl 클래스 코드 일부를 보면    public class OrderServiceImpl implements OrderService {      //OrderService는 2개가 필요     private final MemberRepository memberRepository = new MemoryMemberRepository(); // memberRepository에서 회원 찾아야 하므로     // private final DiscountPolicy discountPolicy = new FixDiscountPolicy(); // discountPolicy에서 할인 정책되로 적용 해야하므로     // private final DiscountPolicy discountPolicy = new RateDiscountPolicy(); // 정액 할인에서 정률 할인으로 바꿈     private DiscountPolicy discountPolicy; // 인터페이스에만 의존하도록 변경 (구체 클래스에 의존 하지 않음)      @Override     public Order createOrder(Long memberId, String itemName, int itemPrice) {          Member member = memberRepository.findById(memberId); // member를 일단 찾자..          int discountPrice = discountPolicy.discount(member, itemPrice);         //OrderService 입장에선 할인에 대해서느 잘 모르겠으니 discountPolicy 에게 그 일을 맡기고 결과만 받는 다고 생각         //-&gt; 설계가 잘 된 (SRP (단일책임원칙) 잘 지킨 것)         //만약 할인에 대해 변경할 사항이 있으면 할인에 대한 부분만 고치면 되고 주문에 관련된 부분은 고칠 필요가 없기 때문에          return new Order(memberId, itemName, itemPrice, discountPrice); //Order를 만들어 반환.          /*         정리하면 주문 생성요청이 오면 회원정보를 먼저 조회를 하고 할인 정책에 회원을 넘기고         결과들을 이용해 주문을 만들어 반환한다.          */     } }    int discountPrice = discountPolicy.discount(member, itemPrice); 이 코드를 보면   discountPolicy는 아무 값도 할당이 되어있지 않다. -&gt; NULL   따라서 NULL.discount~~~ -&gt; 아무값도 없는 것에 멤버를 찾으니 NPE 에러를 일으킨다.      하… 그러면 도대체 어떻게 DIP를 지킬 수 있는거지 ???  여기까지 와보니 이해가 되지 않는다. 과연 DIP를 지킬 수 있는것인지..   구체적인 것이 있어야 뭔가 돌아가지 인터페이스로만 어떻게 돌아가냐….      해결방안  위 문제를 해결하기 위해서는 누군가가 클라이언트인 OrderServiceImpl에 DiscountPolicy의 구현 객체를 대신 생성하고 주입해주면 된다.       음 ?? 그럼 누군가가 도대체 누구고??   누군가가 있다면 어떻게 대신 구현 객체를 생성하고 주입해주지 ??   이 부분에 대해서는 다음에 알아 보도록 하겠다.       사실 정말 자바로 객체지향 원리 지키면서 짜는 것이 어렵다는 것이 여기부터에서도 느껴진다.   Spring이 이러한 귀찮음을 도와 주는건가 ?? 아직까지는 잘 모르겠지만 계속 공부하면 알 수 있을 것이다.     Reference :  김영한 강사님 스프링 핵심 원리 - 기본편  강의 중   ","categories": ["Spring"],
        "tags": ["순수 자바 코드로 개발","정률 할인 정책","정책 변경","실행과 테스트","DIP 위반","OCP 위반"],
        "url": "/spring/spring_basic(4)/",
        "teaser": null
      },{
        "title": "교차 검증",
        "excerpt":"이전에 전체 데이터 샘플수가 부족하여 검증 세트를 훈련 세트에서 분리하여 훈련 세트의 샘플 개수가 부족하여 모델을 충분히 훈련시키는데 문제가 된 경우가 있었다.   이러한 문제를 해결할 방법으로 교차 검증이 쓰인다.      교차 검증(Cross Validation) :  이전에는 전체 데이터 세트를 훈련 세트와 테스트 세트로 나눈 후 훈련세트를 다시 훈련세트와 검증세트로 나누었다   하지만 데이터가 부족한 경우에 나누어진 전체 데이터 세트를 훈련 세트와 테스트 세트로 나눈 후 나누어진 훈련 세트를 다시 작은 덩어리로 나눈다.   이런 작은 덩어리를 폴드라고 부른다.   그리고 나서 작은 덩어리를 1번씩 검증에 사용하고 나머지 덩어리를 훈련에 사용하는 검증 방법을 교차 검증이라고 한다.      그림으로 나타내면       위 방법은 폴드를 5개로 나눈 5-폴드 교차 검증이다.    교차 검증 과정     훈련 세트를 k개의 폴드로 나눈다.     첫 번쨰 폴드를 검증 세트로 사용하고, 나머지 폴드를 훈련 세트로 사용한다.     모델을 훈련하고 검증 세트로 평가한다.     차례대로 다음 폴드를 검증 세트로 사용하여 반복한다.     k개의 검증 세트로 k번 성능을 평가한 후 계산된 성능의 평균을 내어 최종 성능을 계산한다.       k-폴드 교차 검증 :  훈련 세트를 k개의 폴드로 나누는 교차 검증       교차 검증은 기존의 훈련 방법보다 더 많은 데이터로 훈련할 수 있기떄문에 훈련 데이터가 부족한 경우에 사용하는 방법이다.      이제는 k-폴드 교차 검증을 직접 구현해보자.   import numpy as np  # SingleLayer 클래스를 사용할 것이기 때문에 class SingleLayer:    def __init__(self, learning_rate = 0.1, l1 = 0, l2 = 0):      self.w = None      self.b = None     self.losses = []     self.val_losses = []     self.w_history = []       self.lr = learning_rate     self.l1 = l1     self.l2 = l2    def forpass(self, x):      z = np.sum(x * self.w) + self.b     return z    def backprop(self, x, err):      w_grad = x * err     b_grad = 1 * err       return w_grad, b_grad      def activation(self, z):     z = np.clip(z, -100, None)      a = 1 / (1 + np.exp(-z))      return a    def fit(self, x, y, epochs = 100, x_val = None, y_val = None):     self.w = np.ones(x.shape[1])      self.b = 0          self.w_history.append(self.w.copy())         np.random.seed(42)      for i in range (epochs):       loss = 0       indexes = np.random.permutation(np.arange(len(x)))         for i in indexes:         z = self.forpass(x[i])         a = self.activation(z)          err = -(y[i] - a)          w_grad, b_grad = self.backprop(x[i], err)           w_grad += self.l1 * np.sign(self.w) + self.l2 * self.w           self.w -= self.lr * w_grad          self.b -= b_grad           self.w_history.append(self.w.copy())           a = np.clip(a, 1e-10, 1 - 1e-10)           loss += -(y[i] * np.log(a) + (1 - y[i]) * np.log(1 - a))               self.losses.append(loss/len(y) + self.reg_loss())         self.update_val_loss(x_val, y_val)    def predict(self, x):     z = [self.forpass(x_i) for x_i in x]     return np.array(z) &gt;= 0    def update_val_loss(self, x_val, y_val):     if x_val is None:       return      val_loss = 0      for i in range(len(x_val)):       z = self.forpass(x_val[i])       a = self.activation(z)       a = np.clip(a, 1e-10, 1 - 1e-10)        val_loss += -(y_val[i] * np.log(a) + (1 - y_val[i]) * np.log(1 - a))      self.val_losses.append(val_loss / len(y_val) + self.reg_loss())    def score(self, x, y):     return np.mean(self.predict(x) == y)    def reg_loss(self):     return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w ** 2)   # 훈련 세트를 사용하기  from sklearn.datasets import load_breast_cancer from sklearn.model_selection import train_test_split  import matplotlib.pyplot as plt  cancer = load_breast_cancer()  x = cancer.data y = cancer.target  # 먼저 전체 데이터 세트를 8 : 2로 나누어 훈련 세트와 테스트 세트를 얻는다. x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42)  # 각 폴드의 검증 점수를 저장하기 위해 리스트를 하나 정의 validation_scores = []  # k-폴드 교차 검증을 구현해보자  k = 10 # 10개의 폴드 bins = len(x_train_all) // k # 훈련 세트를 k개로 나눔  # k-폴드 교차 검증을 위해 반복문 사용 for i in range(k):    start = i * bins   end = (i + 1) * bins # start와 end는 검증 폴드 샘플의 시작과 끝 인덱스를 의미    val_fold = x_train_all[start:end]    val_target = y_train_all[start:end]    train_index = list(range(0, start)) + list(range(end, len(x_train_all))) # 검증 폴드 샘플 이외의 부분이 훈련 폴드    train_fold = x_train_all[train_index]   train_target = y_train_all[train_index]    # 훈련 데이터의 표준화 전처리를 폴드를 나눈 후에 수행한다!!!   # =&gt; 만약 폴드를 나누기 전에 전체 훈련 데이터를 전처리하면 검증 폴드의 정보를 누설하게 되는 셈이기 때문    train_mean = np.mean(train_fold, axis = 0)   train_std = np.std(train_fold, axis = 0)    train_fold_scaled = (train_fold - train_mean) / train_std   val_fold_scaled = (val_fold - train_mean) / train_std    lyr = SingleLayer(l2 = 0.01)   lyr.fit(train_fold_scaled, train_target, epochs = 50)   score = lyr.score(val_fold_scaled, val_target)    validation_scores.append(score)   print(np.mean(validation_scores)) # validatoin_scores 값들의 평균값이 최종 검증 점수    0.9711111111111113   교차 검증도 당연하게도? 사이킷런에서 제공한다.  사이킷런의 model_selection 모듈에는 교차 검증을 위한 cross_validate() 함수가 있다.   지금까지 구현해놓은 SingleLayer 클래스와 cross_validate() 함수를 같이 사용하기 위해서는 SingleLayer 클래스에 몇 가지 기능을 추가해야 한다.    하지만 cross_validate() 함수를 사용하기 위해 추가해야하는 기능들이 현재 알기에는 어렵기 때문에 추후에 배우도록 하고   대신 SGDClassifier 클래스와 cross_validate() 함수를 같이 사용해서 구현해보자      # cross_validate() 함수로 교차 검증 점수를 계산해보자  from sklearn.linear_model import SGDClassifier from sklearn.model_selection import cross_validate  sgd = SGDClassifier(loss = 'log', penalty = 'l2', alpha = 0.001, random_state = 42)  # cross_validate() 함수의 매개변수 값으로 교차 검증을 하고 싶은 모델의 객체와 훈련 데이터, 타깃 뎅이터를 전달하고 # 매개변수 cv에 교차 검증을 수행할 폴드 수를 지정하면 된다. scores = cross_validate(sgd, x_train_all, y_train_all, cv = 10)  # cross_validate() 함수는 파이썬 딕셔너리를 반환하기 때문에 # 검증 점수는 scores['test score']에 저장 되어 있다. print(np.mean(scores['test_score']))  # 아니 cross_validate() 안쓰고 직접 구현한 이전 보다 왜 정확도가 이렇게 낮지? # 표준화 전처리를 아직 수행하지 않았기 때문이지..   0.850096618357488   훈련 세트를 표준화 전처리하기 전에 조심해야할 부분이 있다.   이전에 교차 검증을 직접 구현할 때에는 폴드를 나눈 후에 훈련 폴드의 통계치(평균, 표준편차)로 검증 폴드를 전처리 하였다.   그 이유는 폴드를 나누기 전에 전처리하면 검증 폴드의 정보를 전처리 단계에서 누설하게 되기 때문이다.     이처럼 cross_validate() 함수를 이용하여 교차 검증을 수행할때 전처리를 위해서 전체 데이터를 전처리 후에 cross_validate() 함수 매개변수 값으로 전달하면 검증 폴드의 정보를 전처리 단계에서 누설 하게된다.     따라서 이러한 방법이 아닌 새로운 방법을 찾아야 cro_validate() 함수를 사용하여 교차 검증을 수행할때  전처리 단계를 포함할 수 있다.      Pipeline 클래스 사용해서 교차 검증 수행하기  사이킷런에서는 검증 폴드가 전처리 단계에서 누설되지 않도록 전처리 단계와 모델 클래스를 하나로 연결해주는 클래스를 제공하는데 그 클래스가 Pipeline 클래스 이다.      # Pipeline 클래스와 SGDClassifier 클래스가 어떻게 작동하는지 알아보자.   from sklearn.pipeline import make_pipeline from sklearn.preprocessing import StandardScaler  # 먼저 표준화 전처리 단계(평균, 표준편차 계산)와 SGDClassifier 클래스 객체를  # Pipeline 클래스로 감싸 cross_validate() 함수에 전달 pipe = make_pipeline(StandardScaler(), sgd) # 파이프라인 객체 만듬 # 표준화 전처리 단계 : StandardScaler() # SGDClassifier 클래스 객체 : sgd # Pipeline 클래스 : make_pipeline  # 사이킷런에서 표준화 전처리를 수행하는 클래스는 preprocessing 모듈 밑에 있는 StandardScaler 클래스  scores = cross_validate(pipe, x_train_all, y_train_all, cv = 10, return_train_score = True)  # 위 방식으로 하면 # cross_validate() 함수는 훈련 세트를 훈련 폴드와 검증 폴드로 나누기만 하고 # 전처리 단계와 SGDClassifier 클래스 객체의 호출은 Pipeline 클래스 객체에서 이뤄진다 # 이렇게 하면 검증 폴드가 전처리 단계에 누설되지 않게 된다.  # cross_validate() 함수의 매개변수 return_train_score를 True로 설정하면 훈련 폴드의 점수도 얻을 수 있음.  print(np.mean(scores['test_score']))  # 전처리 하기전 보다 확실히 정확도가 높아졌다. (검증 폴드에 대한 정확도)   0.9694202898550724   print(np.mean(scores['train_score']))  # 훈련 폴드에 대한 정확도   0.9875478561631581   지금까지는 단일층 신경망을 만들고 여러 유용한 훈련 방법에 대해 알아 보았다.   다음부터는 여러개의 층이 있는 신경망 구조인 다층 신경망 알고리즘에 대해 알아볼 것이다      Reference    박해선, 딥러닝 입문, 이지스퍼블리싱, 2019, 149 ~ 155pg  ","categories": ["Deep_Learning"],
        "tags": ["교차 검증","폴드","k-폴드 교차 검증","cross_validate()","pipeline","표준화 전처리 단계","StandardScaler"],
        "url": "/deep_learning/Training_Know_How(4)/",
        "teaser": null
      },{
        "title": "벡터화, 배치 경사 하강법",
        "excerpt":"지금까지 단일 신경층망을 구현해보았는데 이제는 단일층이 아닌 2개의 층을 가진 신경망을 구현해보고자 한다.   그 전에 신경망 알고리즘을 벡터화 하는 것에 대해 알아보자.     신경망 알고리즘을 벡터화하여 한 번에 전체 샘플을 사용   이전에 사용한 데이터 세트 즉 사이킷런의 예제 데이터 세트는 2차원 배열로 저장되어있었다.   머신러닝에서는 훈련 데이터를 이와같이 2차원 배열로 표현하는 경우가 많다.   2차원 배열은 행은 샘플이고, 열은 특성으로 이루어져 있었고 이것을 행렬로 볼 수 있다.     이러한 행렬 개념을 신경망 알고리즘에 도입해 보려고 한다.     벡터화된 연산은 알고리즘의 성능을 올림  넘파이, 머신러닝, 딥러닝 패키지들은 다차원 배열의 계산을 빠르게 수행할 수 있다는 특징을 가지고 있다.   이 말은 곧 행렬 연산을 빠르게 수행할 수 있다는 말과 같다.   -&gt; 이러한 기능을 벡터화(vectorization)된 연산이라고 한다   이렇게 벡터화되 연산을 사용하면 알고리즘의 성능을 높일 수 있다.      그러면 이전에 구현한 SingleLayer 클래스에 어떻게 벡터화된 연산을 적용할 수 있을까??   -&gt; 배치 경사 하강법을 SingleLayer 클래스에 적용하면 벡터화된 연산을 사용할 수 있습니다.      배치 경사 하강법으로 성능을 올림  배치 경사 하강법이 무엇이지 ???   지금까지 사용한 경사 하강법 알고리즘들(선형 회귀, 로지스틱 회귀)은 알고리즘을 1번 반복할때 1개의 샘플을 사용하는 확률적 경사 하강법을 사용했다.   SingleLayer 클래스에도 확률적 경사 하강법을 사용했었다.   확률적 경사 하강법은 가중치를 1번 업데이트 할 때 1개의 샘플을 사용하므로 손실 함수의 전역 최솟값을 불안정하게 찾는다.   하지만 배치 경사 하강법은 가중치를 1번 업데이트할 때 전체 샘플을 사용하므로 손실 함수의 전역 최솟값을 안정적으로 찾는다.   단 배치 경사 하강법은 가중치를 1번 업데이트할 때 사용되는 데이터의 개수가 많으므로 알고리즘 1번 수행당 계산 비용이 많이 든다.   -&gt; 그래서 전체 데이터 세트의 크기가 너무 크면 배치 경사 하강법을 사용하지 못하는 경우가 있다.      이제부터 배치 경사 하강법을 사용하기 위해 벡터화된 연산의 기초에 대해 알아보려고 한다.     벡터 연산과 행렬 연산  벡터화된 연산을 제대로 사용하기 위해선 벡터 연산과 행렬 연산을 알아야 한다.   여기에서는 신경망에서 자주 사용되는 벡터 연산 중 하나인 점 곱(스칼라 곱)과 행렬 곱셈에 대해 알아볼 것이다     스칼라 곱(점 곱)  단일층 신경망을 그림으로 나타내면 아래와 같다.      단일층 신경망에서 z를 구했던 방법은 가중치($w_1, w_2$, …)와 입력 ($x_1, x_2$, …)을 각각 곱하여 더했다. 여기다 절편도 더한다.   이 계산을 이전에 만든 SingleLayer 클래스 안에 forpass()에서     z = np.sum(x * self.w) + self.b  로 구현하였다.   위 식에서 입력 가중치의 곱을 x * self.w로 간단하게 표현할 수 있는 이유는 넘파이의 원소별 곱셈 기능 덕분이다.   정확히는 아래와 같은 원리로 가중치와 입력의 곱에 대한 합을 한번에 계산한 것이다.    x = [x_1, x_2, ..., x_n] w = [w_1, w_2, ..., w_n]  x * w = [x_1 * w_1, x_2 * w_2, ..., x_n * w_n]    여기서 x(x_1, x_2, …)와 w(w_1, w_2, …)를 벡터라고 부른다   그리고 위의 두 벡터를 곱하여 합을 구하는 계산 (np.sum(x * welf.w)) 를 스칼라 곱(점 곱(dot product)) 라고 한다.     벡터 a, b에 대한 점 곱은 $a \\cdot b$로 표현한다.     아래 그림은 단일층 신경망에 점 곱을 적용하여 다시 그린 것이다.             점 곱을 행렬 곱셈으로 표현합니다.  점 곱을 행렬 곱셈으로 표현하면 행방향으로 놓인 첫 번째 벡터와 열 방향으로 놓인 두 번째 벡터의 원소를 각각 곱한 후 모두 더한는 것과 같다.   아래 식을 보면 행렬 곱셈 방식을 알 수 있다.   $XW = \\begin{bmatrix} x_1 &amp; x_2 &amp; x_3 \\end{bmatrix} \\begin{bmatrix} w_1 \\ w_2 \\ w_3 \\end{bmatrix} = w_1 \\times x_1 + w_2 \\times x_2 + w_3 \\times x_3$     $x_1$은 $w_1$, $x_2$는 $w_2$, $x_3$는 $w_3$와 곱하여 모두 더한다.     이저네 본 np.sum(x * self.w)의 계산과 정확하기 일치한다.   행렬의 곱셈을 계산하는 넘파이의 np.dot() 함수를 이용하면 np.sum(x * self.w)를 아래와 같이 나타낼 수도 있다.    z = np.dot(x, self.w) + self.b    위 행렬의 곱셈 원리를 훈련 데이터의 전체 샘플에 대해 적용하면 배치 경사 하강법을 구현할 수 있다.     전체 샘플에 대한 가중치 곱의 합을 행렬 곱셈으로 구함  이제 이전에 설명한 것을 이용하여 훈련 데이터의 전체 샘플에 대한 가중치 곱의 합을 행렬 곱셈으로 표현해 볼것이다.   훈련 데이터의 샘플은 각 샘플이 하나의 행으로 이루어져 있다.   따라서 행렬 곱셈을 적용하면 샘플의 특성과 가중치를 곱하여 더한 행렬을 얻을 수 있다.       행렬의 곱셈의 결과 행렬의 크기는 첫 번째 행렬의 행과 두 번쨰 행렬의 열이 된다.   식으로 보면  $(m, n) \\cdot (n, k)$ = (m, k)   즉 첫 번째 행렬의 행 크기 m과 두번쨰 행렬의 열 크기 k가 행렬의 곱셈의 결과인 행렬의 크기 (m, k)가 된다.       또한 행렬의 곱셈이 가능하려면 첫 번쨰 행렬의 열의 크기와 두번쨰 행렬의 행의 크기가 같아야 한다.   위의 식을 보면 첫 번째 행렬의 열의 크기와 두번째 행렬의 행의 크기가 둘다 n으로 같음을 알 수 있고 이 조건을 만족해야만 행렬의 곱셈이 가능하다.      첫번째 행렬 x, 두번째 행렬 w가 있다면 위 조건만 만족하면 크기가 어떻든 행렬의 곱셈이 가능하고   이전에 보았듯 행렬의 곱셈은 넘파이의 np.dot() 함수를 이용하면 간단히 계산이 된다.   아래 코드를 보자     np.dot(x, w)    이제부터 행렬 연산을 사용해서 SingleLayer 클래스에 배치 경사 하강법을 적용해 볼 것이다.      # SingleLayer 클래스에 배치 경사 하강법을 적용해보자  import numpy as np import matplotlib.pyplot as plt  from sklearn.datasets import load_breast_cancer # 위스콘신 유방암 데이터 이용  from sklearn.model_selection import train_test_split  cancer = load_breast_cancer()  x = cancer.data y = cancer.target  x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42)  x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify = y_train_all, test_size = 0.2, random_state = 42)  # cancer 데이터 세트의 특성 개수는 30개 이다. 그래도 시작하기전에 사용할 데이터의 크기를 확인하는 습관을 가지는 것이 좋다. print(x_train.shape, x_val.shape)  # 훈련 데이터 세트 샘플은 364개 이고, 특성 개수는 30개 임을 알 수 있다.    (364, 30) (91, 30)   위 예제의 정방향 계산을 행렬 곱셈으로 표현해 보자         넘파이를 사용하면 절편을 더하는 계산을 위해 (364, 1) 크기의 행렬을 따로 만들 필요가 없다.   행렬에 스칼라 값을 더하면 자동으로 행렬의 각 요소에 스칼라 값을 더해 주기 때문이다.   위 식을 보면 벡터와 스칼라의 덧셈 연산을 알 수 있을 것이다.       gradient 계산을 이해해보자  방금 정방향 계산을 구하는 방법을 알아보았는데 gradient를 갱신하기 위한 gradient를 어떻게 계산할 수 있을까?   gradient는 오차와 입력 데이터의 곱이므로 다음과 같은 행렬 곱셈으로 표현할 수 있다.       여기에서 $X^T$는 X를 전치하는 것이고 E는 오차들을 모은 것이다.   행렬을 전치하면 행과 열이 바뀌므로 샘플의 각 특성들을 오차에 곱할 수 있는 형태가 된다.   따라서 X를 전치하였다.     행렬 X는 크기가 (364, 30)에서 전치하면 (30, 364) 크기의 행렬이 된다.   행렬 계산은 (30, 364) $\\cdot$ (364, 1) = (30, 1)이 된다.      $g_1$은 모든 샘플의 첫 번째 특성 ($x_1^{(1)}$, $x_1^{(2)}$, …, $x_1^{(364)}$와 오차 ($e^{(1)}$, $e^{(2)}$, …, $e^{(364)}$)를 곱하여 더한 값이므로 이후 gradient 평균값을 계산할때 이 값을 다시 전체 샘플 수로 나눈다.     class SingleLayer:   def __init__(self, learning_rate = 0.1, l1 = 0, l2 = 0):     self.w = None     self.b = None     self.losses = []     self.val_losses = []     self.w_history = []     self.lr = learning_rate     self.l1 = l1     self.l2 = l2      # forpass() 메서드에 배치 경사 하강법을 적용해보자   def forpass(self, x):     z = np.dot(x, self.w) + self.b # 행렬 곱셈을 해주는 np.dot()이용하여 선형 출력 계산          return z    # backprop() 메서드에도 배치 경사 하강법 적용   def backprop(self, x, err):     m = len(x)      # 행렬 곱셈을 적용한 결과가 gradient의 합이기 때문에 전체 샘플 갯수로 나눠 평균 gradient 구함     w_grad = np.dot(x.T, err) / m # 가중치에 대한 평균 gradient 계산     b_grad = np.sum(err) / m # 절편에 대한 평균 gradient 계산      return w_grad, b_grad    def activation(self, z):     z = np.clip(z, -100, None)     a = 1 / (1 + np.exp(-z))      return a    # fit() 메서드를 수정해보자   # 이전에 구현한 SingleLayer 클래스의 fit() 메서드는   # 에포크를 위한 for문 하나와 훈련 세트를 순회하기 위한 for문 하나로 총 두개의 for문이 있었다.   # 배치 경사 하강법에서는 forpass() 메서드와 backprop() 메서드에서 전체 샘플을 한꺼번에 계산하므로   # 두 번째 for문이 삭제된다.   def fit(self, x, y, epochs = 100, x_val = None, y_val = None):     y = y.reshape(-1, 1)     y_val = y_val.reshape(-1, 1)      # 활성화 출력 a가 열 벡터이므로 이에 맞추어 타깃값을 (m, 1) 크기의 열 벡터로 변환해야 하므로     # y, y_val 형태를 이에 맞게 변환해줌      m = len(x)      self.w = np.ones((x.shape[1], 1))     self.b = 0     self.w_history.append(self.w.copy())      # epochs 만큼 반복     for i in range(epochs):       z = self.forpass(x) # 정방향 계산 수행              a = self.activation(z) # 활성화 함수 적용              err = -(y - a) # 오차 계산        w_grad, b_grad = self.backprop(x, err) # 오차를 역전파하여 gradient 계산        # gradient에서 패널티 항의 미분값을 더함       w_grad += (self.l1 * np.sign(self.w) + self.l2 * self.w) / m               # 가중치와 절편을 갱신하자       self.w -= self.lr * w_grad       self.b -= self.lr * b_grad        self.w_history.append(self.w.copy())        a = np.clip(a, 1e-10, 1-1e-10)        loss = np.sum(-(y * np.log(a) + (1 - y) * np.log(1 - a))) # 각 샘플의 손실을 더함 -&gt; np.sum()이용       self.losses.append((loss + self.reg_loss()) / m) # 전체 샘플의 갯수 m 으로 손실의 합을 나눔 -&gt; 평균 손실 구함        self.update_val_loss(x_val, y_val)        # 이전에 확률 경사 하강법으로 구현한 것과 비슷하지만 for문이 한 단계 삭제되었기 때문에 코드가 훨씬 간단해졌다.    def predict(self, x):     z = self.forpass(x)      return z &gt; 0    def score(self, x, y):     return np.mean(self.predict(x) == y.reshape(-1, 1))    def reg_loss(self):     return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w ** 2)    def update_val_loss(self, x_val, y_val):     z = self.forpass(x_val)     a = self.activation(z)     a = np.clip(a, 1e-10, 1-1e-10)      # 이전에 fit() 메서드에서 self.losses 구하는 방법과 같다.     val_loss = np.sum(-(y_val * np.log(a) + (1 - y_val) * np.log(1 - a)))     self.val_losses.append((val_loss + self.reg_loss()) / len(y_val))   # 훈련 데이터 표준화 전처리를 하자  # 안정적인 학습을 위해 표준화 전처리를 해야한다. # 사이킷런 StandardScaler 클래스를 사용해 데이터 세트의 특성을 평균이 0, 표준 편차가 1이 되도록 반환하자  # StandardScaler 클래스 이외에도 데이터 전처리 관련된 클래스들은 sklearn.preprocessing 모듈 아래 있다. # -&gt; 이러한 데이터 전처리 관련 클래스들을 변환기(transformer) 라고 한다.  import numpy as np import matplotlib.pyplot as plt from sklearn.preprocessing import StandardScaler  scaler = StandardScaler() # StandardScaler 클래스로 scaler 객체를 만듬 scaler.fit(x_train) # 그 객체(모델)을 fit() 메서드 통해 변환 규칙 익힘  # 훈련 세트와 검증 세트에 표준화를 적용 x_train_scaled = scaler.transform(x_train) x_val_scaled = scaler.transform(x_val)   # 이 데이터들을 SingleLayer 클래스 객체에 전달하여 배치 경사 하강법을 적용해 보자  single_layer = SingleLayer(l2 = 0.01) single_layer.fit(x_train_scaled, y_train, x_val = x_val_scaled, y_val = y_val, epochs = 10000)  single_layer.score(x_val_scaled, y_val)   0.978021978021978   score() 메서드에서 출력된 검증 세트의 점수는 저번에 확률적 경사 하강법으로 구현한 SingleLayer 모델과 이번에 배치 경사 하강법으로 구현한(전체 샘플을 사용하여 가중치 업데이트 한) SingleLayer 모델이 같다.     하지만 손실 함수의 변화는 다를 것이다.   훈련 손실과 검증 손실을 그래프로 출력하여 둘 차이를 비교해보자     plt.ylim(0, 0.3) plt.plot(single_layer.losses) plt.plot(single_layer.val_losses)  plt.ylabel('loss') plt.xlabel('epoch')  plt.legend(['train_loss', 'val_loss']) plt.show()  # 이전에 확률적 경사 하강법으로 구현한 SingleLayer 클래스의 모듈 경우 손실 그래프의 변동이 매우 심했다. # 왜냐하면 샘플을 선택하는 순서에 따라 에포크마다 계산된 손실값이 들쭉날쭉했기 때문이다.  # 하지만 이 그래프를 보면 알 수 있듯 배치 경사 하강법을 이용한 경우 전체 샘플을 사용하여 가중치를 업데이트하기 때문에 # 손실값이 안정적을 감소하는 것을 확인할 수 있다.      # 왜 안정적으로 감소하는지 더 자세히 알기 위해 가중치의 변화를 그래프로 나타내보면 알 수 있다. w2 = [] w3 = []  for w in single_layer.w_history:   w2.append(w[2])   w3.append(w[3])  plt.plot(w2, w3) plt.plot(w2[-1], w3[-1], 'ro')  plt.xlabel('w[2]') plt.ylabel('w[3]')  plt.show()  # 배치 경사 하강법을 적용하니 가중치를 찾는 경로가 다소 부드러운 곡선의 형태를 나타낸다 # 가중치의 변화가 연속적이므로 당연히 손실값도 안정적으로 수렴될 것이다      위 그래프를 보니 배치 경사 하강법이 무조건 확률적 경사 하강법 보다 좋다고만 생각할 수도 있다.   물론 여러 면에서 배치 경사 하강법이 좋지만 이전에 언급했듯 매번 전체 훈련 세트를 사용하기 떄문에   연산 비용이 많이 들고 최솟값에 수렴하느 시간도 많이 걸리게 된다는 단점이 존재한다.      이번에는 단일층 신경망에 배치 경사 하강법을 적용하였다.   다음에는 2개의 층을 가진 신경망을 만들어 볼 것이다.      Reference    박해선, 딥러닝 입문, 이지스퍼블리싱, 2019, 149 ~ 155pg   \\  ","categories": ["Deep_Learning"],
        "tags": ["벡터화","배치 경사 하강법","스칼라 곱","점 곱","행렬의 곱셈","np.sum()","np.dot()"],
        "url": "/deep_learning/Multi_Layer(1)/",
        "teaser": null
      },{
        "title": "관심사의 분리",
        "excerpt":"이전에 설계한 것을 DIP를 지키도록 하기 위해   private DiscountPolicy discountPolicy; 로 변경함으로써  인터페이스에만 의존하도록 바꾸었다.      하지만 구체적인 것이 있어야 뭔가 돌아가지 인터페이스로만 돌아가지 않았다.   그것을 해결할 방법으로 누군가가 클라이언트인 OrderServiceImpl에 DiscountPolicy의 구현 객체를 대신 생성하고 주입해주면 된다고 하였다.     그리고 나의 의문점은   음 ?? 그럼 누군가가 도대체 누구고??   누군가가 있다면 어떻게 대신 구현 객체를 생성하고 주입해주는지 모르겠다는 점이였다.      이것은 관심사의 분리로 가능하다.     관심사의 분리  도대체 관심사의 분리가 무엇인지 이해가 되지 않는다.   따라서 이전에 언급하였던 드라마로 예를 들어 보겠다.   드라마 “나의 아저씨”에서 실제 배역에 맞는 배우를 선택해야한다고 하자  누가 배우를 선택해야 할까??     나의 아저씨 드라마에서 “이지안”역을 누가할지 정하는 것은 배우가 정하는게 아니다!!!   그런데 이전에 구현한 코드를 보면 배우가 다른 배우를 정하는 것과 비슷하다.  마치 남자 주인공 “박동훈”역할(인터페이스)으로 선정된 이선균 배우(구현체)가 여자 주인공 “이지안”역할(인터페이스)으로 특정 배우(구현체)를 선택하는 것과 같은상황이다.       이렇게 되면 이선균 배우(구현체)가 연기도 해야하고, 담당 배우 또한 섭외해야하는 많은 책임을 가지게 된다.     이전 코드 OrderServiceImpl 클래스 일부를 다시보면    public class OrderServiceImpl implements OrderService {      //OrderService는 2개가 필요     private final MemberRepository memberRepository = new MemoryMemberRepository(); // memberRepository에서 회원 찾아야 하므로     private final DiscountPolicy discountPolicy = new FixDiscountPolicy(); // discountPolicy에서 할인 정책되로 적용 해야하므로       위 코드르 보면 OrderServiceImpl 에서  private final DiscountPolicy discountPolicy = new FixDiscountPolicy(); 코드를 확인할 수 있다.    OrderServiceImpl은 order service에 관련된 기능만 해야하는데   dsicountPolicy가 FixDiscountPolicy()가 되야한다라고 선택하고 있다.  즉 할인 정책까지 OrderServiceImpl에서 선택하는 많은 책임을 가지고 있다.     다시 정리하면 OrderServiceImpl이 order service에 관련된 기능 뿐만 아니라 “할인 정책에 대한 것이 정액 할인 정책이어야 한다.” 라는 구체적인 역할까지 직접 할인 정책에 대한 객체를 생성하고 구현체 까지 선택하고 있다.     즉 이선균 배우가 자신의 “박동훈” 역할에 대한 연기 뿐만 아니라 다른 배역을 섭외하는 역할까지 가지고 있는 상황과 유사한 것을 알 수 있다.     따라서 관심사를 분리해야 한다.    배우는 본인의 역할인 해당 배역에 대한 연기만 잘하도록 집중해야한다.  이선균 배우는 “이지안”역할에 어떤 배우가 오든 똑같이 연기를 할 수 있어야 한다.     그리고 배우를 섭외하는 역할은 별도의 드라마 기획 담당자들이 해야한다.   -&gt; 즉 드라마 기획자가 나올 시점!!!     드라마 기획자를 따로 만들어 배우를 뽑는 일을 시켜 배우와 드라마 기획자의 책임을 확실하게 분리해야 한다.      이전에 누군가가 클라이언트인 OrderServiceImpl에 DiscountPolicy의 구현 객체를 대신 생성하고 주입해주면 된다라고 하였는데   위의 예시에서 드라마 기획자가 누군가가 되는 것이다      드라마 예시처럼 애플리케이션 또한 실제 실행되는 객체들은 본인의 역할만 수행해야 하고 어떤 구현체들이 인터페이스에 할당될지는 드라마 기획자 처럼 누군가가 해줘야 한다.     그 누군가의 역할을 -&gt; AppConfig가 할 것이다.       AppConfig 등장  애플리케이션의 전체 동작 방식을 구성(config)하기 위해  구현 객체를 생성하고, 연결 하는 책임을 가진 별도의 설정 클래스를 만들 것이다.   그 설정 클래스가 AppConfig 이다.   AppConfig에 대한 코드를 보면   package hello.spring_basic;  import hello.spring_basic.discount.FixDiscountPolicy; import hello.spring_basic.member.MemberService; import hello.spring_basic.member.MemberServiceImpl; import hello.spring_basic.member.MemoryMemberRepository; import hello.spring_basic.order.OrderService; import hello.spring_basic.order.OrderServiceImpl;  // 애플리케이션에 전체 동장 방식을 구성하는 것을 AppConfig에서 하자 public class AppConfig {      public MemberService memberService() { //MemberService를 Appconfig에서 만듬         return new MemberServiceImpl(new MemoryMemberRepository());          // 누군가 AppConfig 통해 memberService() 불러다 쓸떄 MemberServiceImpl인 구현체의 객체가 생성되어 반환되는데         // 그떄 거기에 new MemoryMemberRepository() 들어감         // 즉 MemberServiceImpl의 생성자의 매개변수로 MemoryMemberRepository의 객체가 들어감     }      public OrderService orderService() { // 위와 마찬가지         return new OrderServiceImpl(new MemoryMemberRepository(), new FixDiscountPolicy());         // 누군가 AppConfig를 통해 orderService()를 조회하면 OrderServiceImpl 구현체의 객체가 생성되어 반환하는데         // OrderServiceImpl 클래스를 보면         // OrderServiceImpl의 생성자에 두 매개변수가 필요한         // MemberRepository 객체와, DiscountPolicy 객체 2개 모두 필요하므로         // OrderServiceImpl의 생성자의 매개변수로 MemoryMemberRepository의 객체와, FixDiscountPolicy 객체 2개 모두 들어감     } }      AppConfig는 애플리케이션의 실제 동작에 필요한 구현 객체를 생성한다.     MemberServiceImpl    MemoryMemberRepository    OrderServiceImpl    FixDiscountPolicy      AppConfig는 생성한 객체 인스턴스의 참조(레퍼런스)를 생성자를 통해서 주입(연결) 해준다. -&gt; 생성자 주입     MemberServiceImpl -&gt; MemoryMemberRepository    OrderServiceImpl -&gt; MemoryMemberRepository, FixDiscountPolicy       이제 MemberServiceImpl 클래스와 OrderServiceImpl 클래스 코드를 변경해 호자,     MemberServiceImpl - 생성자 주입  package hello.spring_basic.member;  public class MemberServiceImpl implements MemberService {      private final MemberRepository memberRepository;     // new MemoryMemberRepository() 지움     // memberRepository의 구현체 선택을 여기서 바로 하지 말자 -&gt; DIP 꺠트리기 때문     // 즉 인터페이스에만 의존하도록 변경 (구체 클래스에 의존 하지 않음)      // MemberServiceImpl의 생성자를 만듬 -&gt; 생성자를 통해 memberRepository의 구현체가 무엇이 들어갈지 선택     public MemberServiceImpl(MemberRepository memberRepository) {         this.memberRepository = memberRepository;     }      // 자 이렇게 코드를 고치고 나니 MemberServiceImpl에 MemoryMemberRepository에 대한 부분이 없다.     // 오로지 MemberRepository라는 인터페이스만 존재한다.     // 즉 추상화만 의존한다. -&gt; 드디어 DIP를 지켰다.     // 구체적인것에 대한것은 MemberServiceImpl은 전혀 모른다.     // 누군가가 memberRepository에 MemoryMemberRepository를 넣어줄지, DBMemberRepository를 넣어줄지 모른다.      // 구체적인 것에 대한것은 생성자를 통해 밖에서(AppConfig) 생성해서 넣어줌     // 즉 생성자를 통해 객체가 (new MemoryMemberRepository())가 생성되어 들어감     // -&gt; \"생성자 주입\" 이라고 함.      @Override     public void join(Member member) {         memberRepository.save(member);     }     /*     save메서드 호출시 다형성에 의해 인터페이스인 MemberRepository클래스가 아닌 MemoryMemberRepository 클래스에 있는 save함수를 호출한다.     */      @Override     public Member findMember(Long memberId) {         return memberRepository.findById(memberId);     } // 회원 조회 메서드 정의      // 인터페이스에서 선언한 메서드를 구체적으로 메서드 정의 -&gt; 구현 }   설계의 변경으로 인해 MemberServiceImpl은 더이상 MemoryMemberRepository를 의존하지 않음    단지 MemberRepository 인터페이스에만 의존      MemberServiceImpl 입장에서 생성자를 통해 어떤 구현 객체가 들어올지(주입될지)는 알 수 없음.  MemberServiceImpl의 생성자를 통해서 어떤 구현 객체를 주입할지는 오직 외부(AppConfig)에서 결정된다.      MemberServiceImpl은 앞으로 의존관계에 대한 고민들은 외부(AppConfig)에 맡기고 오직 실행에 대한 부분에만 집중하면 된다.      자 설계를 변경하였으니 변강한 대로 클래스 다이어그램으로 다시 나타내보자.   변경 후 클래스 다이어그램        객체의 생성과 연결은 AppConfig가 담당하고 있음을 알 수 있다.   DIP 확실하게 지키게됨 : MemberServiceImpl은 MemberRepository인 추상에만 의존하면 된다.   이제부턴 구체 클래스를 몰라도 된다.!!!      관심사의 분리 : 객체를 생성하고 연결하는 역할과 실행하는 역할이 명확히 분리 되었음을 알 수 있다.      이제는 변경 후 회원 객체 인스턴스 다이어그램을 나타내 보자  변경 후 회원 객체 인스턴스 다이어그램        appConfig 객체는 memoryMemberRepository 객체를 생성하고 그 참조값을 memberServiceImpl을 생성하면서 생성자로 전달한다.      클라이언트인 memberServiceImpl 입장에서 보면 의존관계를 마치 외부에서 주입해주는 것 같다고 하여 DI(Dependency Injection) 이라고 하며 의존관계 주입 또는 의존성 주입 이라고 한다.       이제는 OrderServiceImpl에 대해 설계를 변경해보자.     OrderServiceImpl - 생성자 주입  package hello.spring_basic.order;  import hello.spring_basic.discount.DiscountPolicy; import hello.spring_basic.discount.FixDiscountPolicy; import hello.spring_basic.discount.RateDiscountPolicy; import hello.spring_basic.member.Member; import hello.spring_basic.member.MemberRepository; import hello.spring_basic.member.MemoryMemberRepository;  public class OrderServiceImpl implements OrderService {      //OrderService는 2개가 필요     private final MemberRepository memberRepository;     // new MemoryMemberRepository(); 지움     // memberRepository의 구현체 선택을 여기서 바로 하지 말자 -&gt; DIP 꺠트리기 때문     // 즉 인터페이스에만 의존하도록 변경 (구체 클래스에 의존 하지 않음)      // private final DiscountPolicy discountPolicy = new FixDiscountPolicy(); // discountPolicy에서 할인 정책되로 적용 해야하므로     // private final DiscountPolicy discountPolicy = new RateDiscountPolicy(); // 정액 할인에서 정률 할인으로 바꿈     private DiscountPolicy discountPolicy;     // new FixDiscountPolicy(); 지움     // discountPolicy의 구현체 선택을 여기서 바로 하지 말자 -&gt; DIP 꺠트리기 때문     // 즉 인터페이스에만 의존하도록 변경 (구체 클래스에 의존 하지 않음)      // 생성자를 만들자     public OrderServiceImpl(MemberRepository memberRepository, DiscountPolicy discountPolicy) {         this.memberRepository = memberRepository;         this.discountPolicy = discountPolicy;          // 자 이렇게 코드를 고치고 나니 OrderServiceImpl에 MemoryMemberRepository와 FixDiscontPolicy에 대한 부분이 없다.         // 오로지 MemberRepository, DiscountPolicy라는 인터페이스만 존재한다.         // 즉 추상화만 의존한다. -&gt; 드디어 DIP를 지켰다.         // 구체적인것에 대한것은 OrderServiceImpl은 전혀 모른다.          // 구체적인 것에 대한 것은 생성자를 통해 밖에서(AppConfig) 생성해서 넣어줌         // 즉 생성자를 통해 객체가 (new MemoryMemberRepository(), new FixDiscountPolicy())가 생성되어 들어감         // -&gt; \"생성자 주입\" 이라고 함.     }      // OrderServiceImpl 클래스는 인터페이스에만 의존하고 있으므로     // 구체적인 클래스에 대해서 전혀 모름     // 누군가가 memberRepository에 MemoryMemberRepository를 넣어줄지, DBMemberRepository를 넣어줄지 모른다.     // discountPolicy에 FixDiscountPolicy를 넣어줄지 RateDiscountPolicy를 넣어줄지 모른다.     // 철저하게 DIP를 지키고 있음을 알 수 있다.      @Override     public Order createOrder(Long memberId, String itemName, int itemPrice) {          Member member = memberRepository.findById(memberId); // member를 일단 찾자..          int discountPrice = discountPolicy.discount(member, itemPrice);         //OrderService 입장에선 할인에 대해서느 잘 모르겠으니 discountPolicy 에게 그 일을 맡기고 결과만 받는 다고 생각         //-&gt; 설계가 잘 된 (SRP (단일책임원칙) 잘 지킨 것)         //만약 할인에 대해 변경할 사항이 있으면 할인에 대한 부분만 고치면 되고 주문에 관련된 부분은 고칠 필요가 없기 때문에          return new Order(memberId, itemName, itemPrice, discountPrice); //Order를 만들어 반환.          /*         정리하면 주문 생성요청이 오면 회원정보를 먼저 조회를 하고 할인 정책에 회원을 넘기고         결과들을 이용해 주문을 만들어 반환한다.          */     } }      설계 변경으로 OrderServiceImpl은 FixDiscountPolicy를 의존하지 않게되었다.   단지 DiscountPolicy 인터페이스에만 의존한다.     OrderServiceImpl 입장에서 생성자를 통해 어떤 구현 객체가 들어올지(주입될지) 알 수 없다.   OrderServiceImpl 생성자를 통해서 어떤 구현 객체를 주입할지는 오직 외부(AppConfig)에서 결정한다.      OrderServiceImpl은 앞으로 의존관계에 대한 고민들은 외부에 맡기고   실행에만 집중하면 됨      코드를 보면   OrderServiceImpl에는 MemoryMemberRepository와 FixDiscountPolicy 객체의 의존관계가 주입되었음을 확인할 수 있다.       자 이제 AppConfig를 실행시켜 보자  AppConfig 실행  AppConfig 실행하기에 앞서 사용 클래스들과 몇몇 오류들을 수정해야 한다.     사용 클래스 - MemberApp   package hello.spring_basic;  import hello.spring_basic.member.Grade; import hello.spring_basic.member.Member; import hello.spring_basic.member.MemberService; import hello.spring_basic.member.MemberServiceImpl; import hello.spring_basic.order.Order; import hello.spring_basic.order.OrderService; import hello.spring_basic.order.OrderServiceImpl;  public class OrderApp {     public static void main(String[] args) {          AppConfig appConfig = new AppConfig();          MemberService memberService = appConfig.memberService(); // memberService 필요시 appConfig에서 인터페이스 만듬         // memberService에는 MemberServiceImpl 객체인데 생성자로 MemoryMemberRepository()를 사용하는 것을 주입 (AppConfig에 있음)          OrderService orderService = appConfig.orderService(); // orderService 필요시 appConfig에서 인터페이스 만듬         // orderService에는 OrderServiceImpl 객체인데 생성자로 MemoryMemberRepository()와 FixDiscountPolicy()를 사용하는 것을 주입 (AppConfig에 있음)          // 기존에 main 메서드에서 직접 MemberServiceImpl, OrderServiceImpl을 생성함         // -&gt; DIP 어기기 떄문거          Long memberId = 1l; //멤버 아이디 생성         Member member = new Member(memberId, \"memberA\", Grade.VIP); // Member 객체 생성 (vip 회원 만듬)         memberService.join(member); //memberService를.join 통해 메모리 객체에 넣어둠 -&gt; 그래야 주문에서 찾아 쓸 수 있으니          Order order = orderService.createOrder(memberId, \"iteA\", 10000); //orderService.createOrder를 통해 order 생성          System.out.println(\"order =\" + order); //order.toString()으로 정의한 내용들이 출력 (order클래스를 보면 toString()함수 정의해놨음)         //order라는 객체 자체를 출력했으므로 order내의 toString()함수가 호출 됨     } }      또한 테스트 코드 오류를 수정하자   테스트 코드 오류 수정  먼저 MemberServiceTest 부터 보면     package hello.spring_basic.member;  import hello.spring_basic.AppConfig; import org.assertj.core.api.Assertions; import org.junit.jupiter.api.BeforeEach; import org.junit.jupiter.api.Test;  public class MemberServiceTest {      MemberService memberService;      @BeforeEach // 각 테스트 실행전 호출     // 테스트 실행 전에 appConfig 만들고 memberService를 할당함     // @Test가 두번 있으면 이 부분 두번 호출     public void beforeEach() {         AppConfig appConfig = new AppConfig();         memberService = appConfig.memberService();     }       // 기존에 직접 MemberServiceImpl을 생성하는 것을 지우자 -&gt; DIP 어기지 않기위해      @Test     void join() {         //given : 이런 이런 환경 주어졌을때         Member member = new Member(1L, \"memberA\", Grade.VIP);          //when : 이렇게 했을때         memberService.join(member);         Member findMember = memberService.findMember(1L);          //then : 이렇게 된다. -&gt; 검증         Assertions.assertThat(member).isEqualTo(findMember);          //정리하면 새로운 member가 주어졌을때         // 그 새로운 멤버를 회원가입(등록) 했을때         // member와 findMember가 같아야 한다.     } }         OrderServiceTest를 보면     package hello.spring_basic.order;  import hello.spring_basic.AppConfig; import hello.spring_basic.member.Grade; import hello.spring_basic.member.Member; import hello.spring_basic.member.MemberService; import hello.spring_basic.member.MemberServiceImpl; import org.assertj.core.api.Assertions; import org.junit.jupiter.api.BeforeEach; import org.junit.jupiter.api.Test;  public class OrderServiceTest {      MemberService memberService;     OrderService orderService;      @BeforeEach     public void beforeEach() {         AppConfig appConfig = new AppConfig();         memberService = appConfig.memberService();         orderService = appConfig.orderService();     }      // 기존에 직접 MemberServiceImpl, OrderServiceImpl을 생성하는 것을 지우자 -&gt; DIP 어기지 않기위해      @Test     void createOrder() {         Long memberId = 1L;         Member member = new Member(memberId, \"memberA\", Grade.VIP);         memberService.join(member);          Order order = orderService.createOrder(memberId, \"itemA\", 10000);         Assertions.assertThat(order.getDiscountPrice()).isEqualTo(1000); //VIP경우 1000원 할인해주기로 했으니 그게 되는지 확인해보자.     } }      자 이제 코드를 다 작성하였으니 test 폴더 (테스트 파일 모두)를 실행시켜보자        결과를 보니 아무런 에러 없이 잘 실행되는 것을 확인할 수 있다.      자 지금까지 내용을 정리해보자   정리     AppConfig를 통해서 관심사를 확실히 분해햐였다.     AppConfig는 구체 클래스를 선택한다. 따라서 애플리케이션이 어떻게 동작해야 할지 전체 구성을 책임진다.     MemberServiceImpl, OrderServiceImpl은 기능을 실행하는 책임만 지면 된다.      자 지금까지 AppConfig를 통해 관심사를 분리하여 DIP를 지킬 수 있게 되었다.   하지만 작성한 AppConfig 약간의 문제가 있다.   이 부분은 다음에 알아보겠다.     Reference :  김영한 강사님 스프링 핵심 원리 - 기본편  강의 중  ","categories": ["Spring"],
        "tags": ["DIP 위반","관심사의 분리","AppConfig","생성자 주입","DI","의존관계 주입","의존성 주입","BeforeEach"],
        "url": "/spring/spring_basic(5)/",
        "teaser": null
      }]
